{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bayesian inference for SARS-CoV-2 transmission modelling, using Stan Author: Bethan Cracknell Daniels Description The aim of this exemplar is to demonstrate how to design and fit a mathematical model of disease transmission to real data, in order to estimate key epidemiological parameters and inform public health responses. Specifically, we will model the emergence of the SARS-CoV-2 variant of concern Omicron in Gauteng, South Africa. To fit the model, we use Stan, a free, accessible and efficient Bayesian inference software. Adopting a Bayesian approach to model fitting allows us to account for uncertainty, which is especially important when modelling a new pathogen or variant. The transmission model uses compartments to track the populations movement between states, for instance from susceptible to infectious. By fitting a compartmental model to epidemiological surveillance data, we will recreate the transmission dynamics of Omicron and other circulating variants, and estimate key epidemiological parameters. Together these estimates are useful for guiding policy, especially in the early stages of an emerging variant or pathogen, when there are lots of unknowns. Useful external resources: Bayesian workflow for disease transmission modeling in Stan A students guide to Bayesian statistics is accompanied by a lecture course on youtube A brief introduction to Stan The Stan manual Statistical Rethinking - this a thorough course on Bayesian data analysis which uses Stan. The course consists of lectures, homework and can be completed alongside reading the textbook of the same title Requirements: Academic Required: - Experience using R, for instance the Graduate school course R programming . - Knowledge of Bayesian statistics, for instance, the textbook A students guide to Bayesian statistics by Ben Lambert is a great place to start. Chapter 16 also introduces Stan. - Download Rstan following these instructions. Beneficial: - Some familiarity with Stan. - Experience of infectious disease modelling. System Program Version R Any Learning outcomes Upon completion of this tutorial, students will be able to: design an infectious disease compartmental model to answer public health questions. compare methods of solving ODE using Stan. write a Stan model to fit an infectious disease model. interpret Stan model diagnostics and implement appropriate solutions. structure R code into files based on functionality. write tests in R to check code. Getting Started Try the code with Docker container: If you have Docker engine installed on your computer, please set Docker engine to use at least 6GB RAM, 4GB Swap, and 4 CPUs. Pull the container image in a command window (Windows) or a terminal window (Mac or Linux) by running docker pull jianlianggao/recode_idms:20220726 When the image is pulled, to run the image in a container instance, please run the following command docker run --rm -p 127.0.0.1:8787:8787 -e DISABLE_AUTH=true jianlianggao/recode_idms:20220726 Let the above command run in the terminal window and keep it open in the background, you can open 127.0.0.1:8787:8787 in your favourite web brower and you will have a RStudio (it is officially called posit now) interface to open and run tutorial code of chapter 1, chapter 2 or chapter 3 in R Markdown. You can modify the code in R Markdown but you do not have permissions to save the file. If you want to save changes you have made, please stop the container instance in the terminal window by pressing Control + C . Then start a new container instance by running docker run --rm -p 127.0.0.1:8787:8787 -v /tmp:/home/rstudio/data -e DISABLE_AUTH=true jianlianggao/recode_idms:20220703 Again, please keep the command window (or terminal window) opened in the background. View RStudio from your favourite web browser by visiting 127.0.0.1:8787 and now you should be able to save changes in the /home/rstudio/data folder, which is mapping to /tmp in your computer. You can copy the save files to other folder later on. For Windows users, the mount path format /tmp is different, you may need to replace it with d:/tmp for example. This has been tested yet. We will update when we have a chance to test it on a Windows computer. In RStudio in your web browser, please run config.R before running any other code. Project structure This project is split into 3 chapters: Chapter 1: Designing an infectious disease model Chapter 2: Fitting a single variant model in Stan Chapter 3: Fitting a multivariant model in Stan Each chapter is interactive, with questions and activities along the way. Therefore, for each chapter you will find 2 RMD files, one with and one without solutions. Chapter 1 This chapter will demonstrate how to design an infectious disease compartmental model, including choosing the model priors and likelihood. Chapter 2 This chapter will fit a single-variant compartmental model to simulated data in order to explore the transmission dynamics of omicron in Gauteng. In order to do fit the model, this chapter demonstrates how to: simulate data compare different methods of solving ordinary differential equations in Stan code up an infectious disease model in Stan fit infectious disease models in Stan run model diagnostics plot the model fit against data Chapter 3 This chapter builds on everything introduced in chapter 2 in order to fit a more complicated model. Specifically, chapter 3 shows how to fit a multistain compartmental model to simulated data in order to explore the transmission dynamics of omicron and delta in Gauteng. The model accounts for population testing, vaccination and waning immunity. Chapter 3 also includes some optional, open ended challenges. Repository Structure The documents related to each chapter are organised in the following folders: docs This folder contains all the .md files associated with each chapter and was used to render the documentation. The MD file testing introduces formal testing and the package test that . All R. files with the prefix test are scripts which run formal testing on a specific function. Tutorials This folder contains the corresponding .html and .Rmd files of each chapter. R Each RMD file takes as in input multiple functions, each with a specific purpose. Frequently, these functions take as input the output of the function before. This folder contains all the functions needed to run the Rmd file. All R. files with the prefix test are scripts which run formal testing on a specific function. As stated above, each function has a specific purpose and the functions are designed to be run in order. The functions are as follows: simulate_data.R : Functions to produce simulated reported incidence data using the model model1_deSolve.R or model2_deSolve.R . Takes as input parameter values for the model. Outputs a data frame of solutions to the derivatives of all compartments at each time step. calc_sim_incidence.R : Functions to calculate the simulated reported incidence. Takes as input a data frame of solutions to the derivatives of all compartments at each time step. Outputs a data frame and ggplot of reported incidence over time. run_stan_models.R : Function to fit a stan model. Uses the function draw_init_values.R . At minimum, takes as in put a list of data to fit the model and a Stan model. Outputs a fitted stan model. draw_init_values.R : Functions sourced within run_stan_models.R which generates a different starting values for each Markov chain. Takes as input a seed value and the number of variants the model is fitting to. Outputs an initial value for each parameter and each chain. diagnose_stan_fit.R : a function to run diagnostics on a Stan fit. Takes as input a fitted Stan model and the parameters to check. Outputs the number of divergent transitions, diagnostic plots and parameter summary statistics. plot_model_fit.R : a function to plot the results of a fitted Stan model against the data to which it was fit. Takes as input a fitted Stan model, the name of the variables to be plotted, and the simulated or observed data. compare_param_est.R : a function to compare parameter estimates between models or methods of solving ODEs, i.e., in order to check whether a Stan model is able to recover true parameter estimates from simulated data. Takes as input a vector of true parameter values, estimated posterior mean and 95% CrI from a Stan fit and parameter names. Outputs plots comparing parameter values. models: This folder contains the compartmental models used in part 1. R models: model1_deSolve.R : a function to solve a single strain SEIQR model which is sourced by the function simulate_data.R . model2_deSolve.R : a function to solve a multistrain SEIQRS model which is sourced by the function simulate_data.R . Stan models (written in C++): model1_Euler_V1.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Euler method at a single day step. model1_Euler_V2.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Euler method at a user-defined time step. model1_RK_V1.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Runge-Kutta Method. model2_Euler_V1.stan : a Stan model of a multistrain SEIQRS model, the ODEs are solved using the Euler method at a user-defined time step. model2_Euler_V2.stan : a Stan model of a multistrain SEIQRS model, the ODEs are solved using the Euler method at a user-defined time step.","title":"Home"},{"location":"#bayesian-inference-for-sars-cov-2-transmission-modelling-using-stan","text":"","title":"Bayesian inference for SARS-CoV-2 transmission modelling, using Stan"},{"location":"#author-bethan-cracknell-daniels","text":"","title":"Author: Bethan Cracknell Daniels"},{"location":"#description","text":"The aim of this exemplar is to demonstrate how to design and fit a mathematical model of disease transmission to real data, in order to estimate key epidemiological parameters and inform public health responses. Specifically, we will model the emergence of the SARS-CoV-2 variant of concern Omicron in Gauteng, South Africa. To fit the model, we use Stan, a free, accessible and efficient Bayesian inference software. Adopting a Bayesian approach to model fitting allows us to account for uncertainty, which is especially important when modelling a new pathogen or variant. The transmission model uses compartments to track the populations movement between states, for instance from susceptible to infectious. By fitting a compartmental model to epidemiological surveillance data, we will recreate the transmission dynamics of Omicron and other circulating variants, and estimate key epidemiological parameters. Together these estimates are useful for guiding policy, especially in the early stages of an emerging variant or pathogen, when there are lots of unknowns.","title":"Description"},{"location":"#useful-external-resources","text":"Bayesian workflow for disease transmission modeling in Stan A students guide to Bayesian statistics is accompanied by a lecture course on youtube A brief introduction to Stan The Stan manual Statistical Rethinking - this a thorough course on Bayesian data analysis which uses Stan. The course consists of lectures, homework and can be completed alongside reading the textbook of the same title","title":"Useful external resources:"},{"location":"#requirements","text":"","title":"Requirements:"},{"location":"#academic","text":"Required: - Experience using R, for instance the Graduate school course R programming . - Knowledge of Bayesian statistics, for instance, the textbook A students guide to Bayesian statistics by Ben Lambert is a great place to start. Chapter 16 also introduces Stan. - Download Rstan following these instructions. Beneficial: - Some familiarity with Stan. - Experience of infectious disease modelling.","title":"Academic"},{"location":"#system","text":"Program Version R Any","title":"System"},{"location":"#learning-outcomes","text":"Upon completion of this tutorial, students will be able to: design an infectious disease compartmental model to answer public health questions. compare methods of solving ODE using Stan. write a Stan model to fit an infectious disease model. interpret Stan model diagnostics and implement appropriate solutions. structure R code into files based on functionality. write tests in R to check code.","title":"Learning outcomes"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#try-the-code-with-docker-container","text":"If you have Docker engine installed on your computer, please set Docker engine to use at least 6GB RAM, 4GB Swap, and 4 CPUs. Pull the container image in a command window (Windows) or a terminal window (Mac or Linux) by running docker pull jianlianggao/recode_idms:20220726 When the image is pulled, to run the image in a container instance, please run the following command docker run --rm -p 127.0.0.1:8787:8787 -e DISABLE_AUTH=true jianlianggao/recode_idms:20220726 Let the above command run in the terminal window and keep it open in the background, you can open 127.0.0.1:8787:8787 in your favourite web brower and you will have a RStudio (it is officially called posit now) interface to open and run tutorial code of chapter 1, chapter 2 or chapter 3 in R Markdown. You can modify the code in R Markdown but you do not have permissions to save the file. If you want to save changes you have made, please stop the container instance in the terminal window by pressing Control + C . Then start a new container instance by running docker run --rm -p 127.0.0.1:8787:8787 -v /tmp:/home/rstudio/data -e DISABLE_AUTH=true jianlianggao/recode_idms:20220703 Again, please keep the command window (or terminal window) opened in the background. View RStudio from your favourite web browser by visiting 127.0.0.1:8787 and now you should be able to save changes in the /home/rstudio/data folder, which is mapping to /tmp in your computer. You can copy the save files to other folder later on. For Windows users, the mount path format /tmp is different, you may need to replace it with d:/tmp for example. This has been tested yet. We will update when we have a chance to test it on a Windows computer. In RStudio in your web browser, please run config.R before running any other code.","title":"Try the code with Docker container:"},{"location":"#project-structure","text":"This project is split into 3 chapters: Chapter 1: Designing an infectious disease model Chapter 2: Fitting a single variant model in Stan Chapter 3: Fitting a multivariant model in Stan Each chapter is interactive, with questions and activities along the way. Therefore, for each chapter you will find 2 RMD files, one with and one without solutions.","title":"Project structure"},{"location":"#chapter-1","text":"This chapter will demonstrate how to design an infectious disease compartmental model, including choosing the model priors and likelihood.","title":"Chapter 1"},{"location":"#chapter-2","text":"This chapter will fit a single-variant compartmental model to simulated data in order to explore the transmission dynamics of omicron in Gauteng. In order to do fit the model, this chapter demonstrates how to: simulate data compare different methods of solving ordinary differential equations in Stan code up an infectious disease model in Stan fit infectious disease models in Stan run model diagnostics plot the model fit against data","title":"Chapter 2"},{"location":"#chapter-3","text":"This chapter builds on everything introduced in chapter 2 in order to fit a more complicated model. Specifically, chapter 3 shows how to fit a multistain compartmental model to simulated data in order to explore the transmission dynamics of omicron and delta in Gauteng. The model accounts for population testing, vaccination and waning immunity. Chapter 3 also includes some optional, open ended challenges.","title":"Chapter 3"},{"location":"#repository-structure","text":"The documents related to each chapter are organised in the following folders:","title":"Repository Structure"},{"location":"#docs","text":"This folder contains all the .md files associated with each chapter and was used to render the documentation. The MD file testing introduces formal testing and the package test that . All R. files with the prefix test are scripts which run formal testing on a specific function.","title":"docs"},{"location":"#tutorials","text":"This folder contains the corresponding .html and .Rmd files of each chapter.","title":"Tutorials"},{"location":"#r","text":"Each RMD file takes as in input multiple functions, each with a specific purpose. Frequently, these functions take as input the output of the function before. This folder contains all the functions needed to run the Rmd file. All R. files with the prefix test are scripts which run formal testing on a specific function. As stated above, each function has a specific purpose and the functions are designed to be run in order. The functions are as follows: simulate_data.R : Functions to produce simulated reported incidence data using the model model1_deSolve.R or model2_deSolve.R . Takes as input parameter values for the model. Outputs a data frame of solutions to the derivatives of all compartments at each time step. calc_sim_incidence.R : Functions to calculate the simulated reported incidence. Takes as input a data frame of solutions to the derivatives of all compartments at each time step. Outputs a data frame and ggplot of reported incidence over time. run_stan_models.R : Function to fit a stan model. Uses the function draw_init_values.R . At minimum, takes as in put a list of data to fit the model and a Stan model. Outputs a fitted stan model. draw_init_values.R : Functions sourced within run_stan_models.R which generates a different starting values for each Markov chain. Takes as input a seed value and the number of variants the model is fitting to. Outputs an initial value for each parameter and each chain. diagnose_stan_fit.R : a function to run diagnostics on a Stan fit. Takes as input a fitted Stan model and the parameters to check. Outputs the number of divergent transitions, diagnostic plots and parameter summary statistics. plot_model_fit.R : a function to plot the results of a fitted Stan model against the data to which it was fit. Takes as input a fitted Stan model, the name of the variables to be plotted, and the simulated or observed data. compare_param_est.R : a function to compare parameter estimates between models or methods of solving ODEs, i.e., in order to check whether a Stan model is able to recover true parameter estimates from simulated data. Takes as input a vector of true parameter values, estimated posterior mean and 95% CrI from a Stan fit and parameter names. Outputs plots comparing parameter values.","title":"R"},{"location":"#models","text":"This folder contains the compartmental models used in part 1. R models: model1_deSolve.R : a function to solve a single strain SEIQR model which is sourced by the function simulate_data.R . model2_deSolve.R : a function to solve a multistrain SEIQRS model which is sourced by the function simulate_data.R . Stan models (written in C++): model1_Euler_V1.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Euler method at a single day step. model1_Euler_V2.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Euler method at a user-defined time step. model1_RK_V1.stan : a Stan model of a single strain SEIQR model, the ODEs are solved using the Runge-Kutta Method. model2_Euler_V1.stan : a Stan model of a multistrain SEIQRS model, the ODEs are solved using the Euler method at a user-defined time step. model2_Euler_V2.stan : a Stan model of a multistrain SEIQRS model, the ODEs are solved using the Euler method at a user-defined time step.","title":"models:"},{"location":"Testing/","text":"What is testing? Testing is the process of executing code in order to find errors and debug them. You probably already do testing, informally, to check that your code or functions are working as expected. However, it is less likely that you write functions and then test them formally on several different input and expected output values to ensure they are robust. This is formal testing, and is useful because a function that works initially with a specific set of input values may not work when even a small input value changes. In this project, the functions are mostly standalone, however when developing more complex code with functions that rely on the output of other functions, unit testing become increasingly useful to debug code. Unit testing checks small parts of the code one at a time to check they are behaving as expected. If they are not, then it is easier to debug why than when an error appears as part of a large chain of dependent functions. In order to facilitate testing, this project splits the code into short functions with a clear and singular purpose. Therefore, by writing code that is easy to test, we improve the quality of our code, by writing more manageable functions. Test that In order to run our unit testing, this project uses the testthat package , which tries to make testing easy and, possibly, fun. Each test takes a known input (i.e., arguments provided to a function) and checks that the output is expected (i.e., a pre-defined value, object etc. returned by the function). Once you have written all the tests for all the functions in your project, testthat will run them all and return an output which states how many tests pass, fail or throw warnings. As you build up your code and continue to test regularly, if a function changes or a new input throws an error then testthat will flag it and it will be more straightforward to debug! Testing functions In the R file test-functions.R there is code to test 4 functions: simulate_data_single_var , simulate_data_multi_var , draw_init_values and compare_param_est . For instance, the first two functions are used to simulate infectious disease transmission data by solving a set of ordinary differential equations (ODE).One of the tests we want to run is to check that the outputs are always positive, as we can't have negative numbers of people! If the outputs are negative then this could mean that our ODE equations aren't balanced. Fortunately, test.that will warn us quickly so we can address the problem before it has a knock on affect to downstream analysis. As well as testing regularly, the act of writing the tests helps us to improve the functions. For instance, when writing the tests for simulate_data_single_var , I realised that if any of the rate parameters were negative, this could also lead to the outputs being negative. Therefore I added checks at the start of the function, to ensure that all parameter values are valid. For instance: if(n_pop <0 ) stop(\"n_pop cannot be negative\") . Once you have written tests for all the functions, the testthat package makes it easy to run all the tests in one go: simply execute test_dir(\".\") , in the console below. As long as the code to test is saved in the current working directory and has the prefix test, the testthat package will find and run all your tests. Challenge: Only some of the functions here have test written for them, in order to demonstrate the testthat package. However, you would ideally write tests for all functions. Try writing some tests for additional functions (locations in the R folder). You can either do this by adding to the script test-functions.R , or write a new script with the prefix test in its name. Once you have written the tests, you can execute them as before using test_dir(\".\") . You may find that you want to edit the functions you are testing too, to ensure they are robust!","title":"Testing"},{"location":"Testing/#what-is-testing","text":"Testing is the process of executing code in order to find errors and debug them. You probably already do testing, informally, to check that your code or functions are working as expected. However, it is less likely that you write functions and then test them formally on several different input and expected output values to ensure they are robust. This is formal testing, and is useful because a function that works initially with a specific set of input values may not work when even a small input value changes. In this project, the functions are mostly standalone, however when developing more complex code with functions that rely on the output of other functions, unit testing become increasingly useful to debug code. Unit testing checks small parts of the code one at a time to check they are behaving as expected. If they are not, then it is easier to debug why than when an error appears as part of a large chain of dependent functions. In order to facilitate testing, this project splits the code into short functions with a clear and singular purpose. Therefore, by writing code that is easy to test, we improve the quality of our code, by writing more manageable functions.","title":"What is testing?"},{"location":"Testing/#test-that","text":"In order to run our unit testing, this project uses the testthat package , which tries to make testing easy and, possibly, fun. Each test takes a known input (i.e., arguments provided to a function) and checks that the output is expected (i.e., a pre-defined value, object etc. returned by the function). Once you have written all the tests for all the functions in your project, testthat will run them all and return an output which states how many tests pass, fail or throw warnings. As you build up your code and continue to test regularly, if a function changes or a new input throws an error then testthat will flag it and it will be more straightforward to debug!","title":"Test that"},{"location":"Testing/#testing-functions","text":"In the R file test-functions.R there is code to test 4 functions: simulate_data_single_var , simulate_data_multi_var , draw_init_values and compare_param_est . For instance, the first two functions are used to simulate infectious disease transmission data by solving a set of ordinary differential equations (ODE).One of the tests we want to run is to check that the outputs are always positive, as we can't have negative numbers of people! If the outputs are negative then this could mean that our ODE equations aren't balanced. Fortunately, test.that will warn us quickly so we can address the problem before it has a knock on affect to downstream analysis. As well as testing regularly, the act of writing the tests helps us to improve the functions. For instance, when writing the tests for simulate_data_single_var , I realised that if any of the rate parameters were negative, this could also lead to the outputs being negative. Therefore I added checks at the start of the function, to ensure that all parameter values are valid. For instance: if(n_pop <0 ) stop(\"n_pop cannot be negative\") . Once you have written tests for all the functions, the testthat package makes it easy to run all the tests in one go: simply execute test_dir(\".\") , in the console below. As long as the code to test is saved in the current working directory and has the prefix test, the testthat package will find and run all your tests. Challenge: Only some of the functions here have test written for them, in order to demonstrate the testthat package. However, you would ideally write tests for all functions. Try writing some tests for additional functions (locations in the R folder). You can either do this by adding to the script test-functions.R , or write a new script with the prefix test in its name. Once you have written the tests, you can execute them as before using test_dir(\".\") . You may find that you want to edit the functions you are testing too, to ensure they are robust!","title":"Testing functions"},{"location":"chapter_1/","text":"Hi and welcome to the chapter in this exampler on designing an infectious disease model. The overall aim of this script is to design a Susceptible (S) - Exposed (E) - Infectious (I) - Quarantine (Q) - Recovered (R) model to explore the transmission dynamics of Omicron in Gauteng, South Africa between late 2021 and early 2022. This script show step by step how to design an infectious disease compartmental model to answer a public health question. There are many choices to be made along the way, so it is important to think about the assumptions we are making so our model is robust. Some questions include: What are the most important disease and epidemiological features? How do we represent these features in a model? What data do is needed to calibrate the model? What parameters should be estimated? Disclaimer: \"all models are wrong. Some models are useful\" - George E. P. Box Introduction to infectious disease modelling First, lets take a look at the storyboard below. It outlines some of the key steps when designing and building a model logically. Briefly, we need to define (1) our research question, (2) population and time period. Then we need to think about (3) how our model can reproduce the observed data. Are we modelling incidence or prevalence data? Next, we need to (4) design the compartmental model. Compartmental models are the bread and butter of infectious disease modelling. They are a system of differential equations which describe the flows of individuals from one infectious state to another and represent the infection history. In the figure we show an SIR model, the most simple model typically used. In this model we often assume that individuals in a population start out susceptible to a disease, i.e., they have no prior protective immunity. This is the S compartment. From there, individuals may be infected by the pathogen, at which point they are also infectious and enter the I compartment. Finally, when they recover from the disease and are no longer infectious, they enter the R compartment. I will assume you are familiar with compartmental models and so won't go into further detail here. If you are not so familiar, there are lots of good resources out there which already explain SIR models. For instance, Imperial has a module on SIR modules on Coursera . Or there are an abundance of videos on YouTube where people introduce SIR models, especially since COVID-19. This is a nice intro! Having designed the model, we need to (5) think about the initial conditions for each state. If an infectious agent is entirely new to a population, like SARS-CoV-2 was at the start of 2020, we would expect all of the population to be in the S compartment at time (t) = 0 , with a few individuals in the infectious compartment: S_{t0} = N - I_{t0} Where I_{t0} is the initial number infectious and N is the population size. If the in pathogen is not novel and there is prior immunity, then we might expect some of the population to be in the recovered compartment. Critically, the sum of all the compartments must equal the population size N , S + I + R = N The flow between the compartments is governed by rates (6). In this example, we have the transmission rate, typically denoted \\beta and the recovery rate, \\gamma . Note that because transmission depends on the number of infectious people we need to account for this. Hence, the force of infection (the per capita rate that susceptible individuals contract the infection) depends on he transmission rate and on the proportion of the population that is infectious: \\lambda = \\beta\\frac{I}{N} Next, we need to (7) convert our flow diagram into ODE equations. Simply, arrows leading out of a compartment represent subtractions and arrows leading into a compartment represent additions. After that, we need to decide (8) which parameters we want to fix and (9) which we want to estimate. This likely depends on the research question and available data and parameter estimates in the literature. As we are fitting the model using Bayesian inference, the next decisions we need to make are about the priors (10) and likelihood (11). Hopefully you are familiar with Bayesian statistics, but if not then I recommend going back to some of the resources suggested in the README.md . Briefly, what we are asking is, given the data y , what are the most likely parameters \\theta . Note, when we talk of parameters here, this refers to those we are estimating, not the fixed parameters . In other words, our posterior distribution is Pr(\\theta|y) . Bayes rule tells us that: Pr(\\theta | y) \\propto Pr(y | \\theta) Pr(\\theta) Where, Pr(y | \\theta) is the likelihood, or sampling distribution, and Pr(\\theta) is our prior distribution. The likelihood tells us how to generate our data y , given our model parameters. Our prior distributions allow us to incorporate existing domain knowledge into the model. Flat (i.e., uniform priors) and \"uninformative\" priors are discouraged in Stan, so we are going to avoid them. Ben Lambert explains here why priors are, depending on the frame of reference, never completely uninformative. Instead, we want prior distributions to be vague enough to explore all reasonable parameter values whilst preventing the sampler exploring areas of the parameter space that are implausible. For instance, say we were to estimate the recovery rate, \\gamma . \\gamma = \\frac{1}{D} , where D is the average duration of the infection. We know that this must be a positive number, so we can reflect this in our prior distribution. Moreover, even if we did not know very much about the clinical progression of COVID-19, we know that is an acute infection, not a chronic infection - i.e., people generally recovery within days - weeks. So we would want to explore recovery rates that reflect this. Allowing the sampler to explore the posterior distribution where \\frac{1}{\\gamma} is hundreds or even thousands of days would be inefficient. For more detail on choosing prior values take a look at this post written by Andrew Gelman, one of the developers of Stan. We also need to think about the model likelihood, which aims to capture the data generating process. Essentially, we need to link the chosen model output to the data we are fitting the model to. The distribution we choose to link our model output depends on the type of data we have, and there often isn't only one choice. In infectious disease modelling we often have incidence data, which we may want to fit using a Poisson likelihood . The Poisson distribution has one parameter, \\lambda which represents the mean rate of the event (in this case, infections) occurring in a fixed time and the variance. Q1: If we were to use the Poisson distribution to fit to incidence data, what model output would we fit to? Alternatively, if the data are over-dispersed, that is if the variance is larger than the mean then we might want to use a Negative Binomial likelihood. The Negative Binomial distribution extends the Poisson distribution with an additional parameter \\kappa which controls the over-dispersion of the distribution. Critically, the variance is now > \\lambda . When \\kappa is very small, over-dispersion is high, but when \\kappa is large enough, the Negative Binomial distribution converges on the Poisson! The final step in building our model is to think about the assumptions we have made along the way. As we said before, no model is perfect. We want our model to be as simple as possible, whilst still capturing the important features of the pathogen. This means we have to make simplifying assumptions in how we represent the transmission process in our compartments. One notable assumption is that everyone in each compartment is assumed to be homogeneous. Equally, there might be lots of unknowns about the disease or the data, which again means we will have to make assumptions! We can also do sensitivity analyses to explore the impact of our assumptions. An important thing to note is that although the steps in building a model may appear linear, model fitting is far from a linear process. These steps provide a loose guidance for the first iteration of model building, which should be as simple as possible. It is important to be flexible with these steps and to expect to have to go back and make changes to the model once you start fitting to the data. It may be that you realise you need additional data (3), you realise one of your simplifying assumptions (12) doesn't allow you to capture a key aspect of the data and so you amend the model by introducing extra compartments (4). Maybe there is more data available than when you started so you change a fixed parameter value (8) or amend your priors to incorporate additional domain knowledge (10)... you get the idea. So, now lets design the model. Step 1: Define the reseach question There may be multiple questions you want to answer in an analysis, and listing them helps you keep the focus. In this example, one of the key questions is: What is the reproduction number of the Omicron variant of concern? Step 2: What is the population and time period? This is partly answered by the research question, we are interested in the population of Gauteng and the period of time when Omicron first emerged.The population of Gauteng is 15,810,388 people. We know that Omicron was first detected in October 2021, but we suspect that there was probably some transmission before it was detected, so the start of our modelling period will be September 2021. We want to explore whether we can reconstruct the dynamics observed in the Omicron wave. If you look at this dashboard provided by the WHO, we can see that this 4 th wave was over by ~February. We will run our model till the 23 rd of February to make sure we capture all of the epidemic curve. Step 3: What data are we fitting the model to? We are going to fit to the reported incidence of SARS-CoV-2 for Gauteng, South Africa. We need to reconstruct the reported incidence from the model. Step 4: What compartments do we minimally need to represent the disease transmission process? Starting with the SIR model, we want to account for the incubation period of COVID-19 and we need to account for only having data on the reported incidence. Therefore, we want to extend the simple SIR model in some way which allows for individuals to either be detected, reported and isolated or not detected, in which case they remain infectious and are not isolated for the whole duration of the infection. Q2: draw out a compartmental model which accounts for the above Step 5: What are the initial conditions? What do we want to estimate? What do we want to fix? Our population = N = 15810388. We can assume that E_{t0} and Q_{t0} = 0. As we are fitting to the 4 th wave of SARS-CoV-2 in Gauteng, we know some of the population will already have had an infection and have immunity, so they go in the R compartment. We can look to seroprevalence surveys for data on the percentage of the population with immunity.56.2% of the unvaccinated population of Gauteng had antibodies to SARS-CoV-2 in December 2021 [1]. Note, this is slightly after the emergence of Omicron but it is the best data we have for now. So: R_{t0} = 15,810,388 * 0.562 = 8,885,438 For this tutorial, we will assume that the initial number of infections I_{t0} = 1 , however as the true number of infections is an unobserved quantity, this is often a parameter value to be estimated. Finally, S_{t0} = N - R_{t0} - I_{t0} Step 6: What are the rate parameters which describe flows between the compartments? Note, \\beta , \\sigma and \\gamma are all per capita rates, whereas \\rho is a probability. All individuals will progress to be infectious at an average rate of \\sigma and a proportion \\rho will be tested, reported and quarantined. Step 7: What are the equations that govern the model? Once you have a flow diagram with rates, writing the equations is simple! Arrows out of a state are subtracted, arrows into a stated are added. A good check is to make sure the equations balance. Step 8: Which parameters can we fix based on the literature? We will assume an average latent period \\frac{1}{\\sigma} of 3.03 days, as estimated for Omicron [2] and an average infectious period \\frac{1}{\\gamma} of 4.17 days [3]. Step 9: Which parameters do we need to estimate? Having fixed the generation time (i.e., \\sigma and \\gamma ), we are going to estimate \\beta and \\rho . Q3: why would we want to estimate these parameters? Step 10: Do we have any domain knowledge to inform the parameter priors? As stated above, we want to choose weakly informative priors in order to include enough information to regularise the model. One way to achieve this, is to not use hard bounds, unless there are true constrains. For example, \\rho , is the probability of reporting which must be between 0 and 1, therefore using a beta prior is suitable here. If we thought that every value of \\rho was equally likely, we could set a prior \\rho \\sim Beta(1,1) . As it is, a sero-survey from Gauteng, South Africa in January 2021 estimated a 2-20 fold underreporting of cases, corresponding to a reporting rate <50% [5]. Therefore, lets assume a prior that supports values below 50%, but still allows for higher values if the data support it: \\rho \\sim Beta(2,8) . Q4: use the function rbeta() to check the distribution of \\rho \\sim Beta(2,8) Another way to explore the shape of distributions is the distribution zoo , created by Ben Lambert and Fergus Cooper. For the \\beta parameter, we are not sure how transmissible Omicron is yet, but we think somewhere similar or more transmissible than the Delta variant. A useful measure of transmission is the Reproduction number ( R_0 ), the average number of secondary cases produced per infectious individual in an susceptible population. The R_0 for a simple SIR model is equal to the transmission rate multiplied by the average duration of the infectious period. For a simple SIR model this would be: R_0 = \\frac{\\beta}{\\gamma} For our model: R_0 = \\frac{(1-\\rho)\\beta}{\\gamma} Intuitively, this is due to the fact that only a proportion (1-\\rho) of subjects contribute to onwards transmission. More formally, this can also be demonstrated using the next generation matrices method , if interested. The R_0 of Delta is estimated around 5 [4], so exploring values of \\beta that correspond to R_0 estimates around 5 and above seems reasonable. Q5: Define a prior for \\beta which supports R_0 values around 5 but allows for higher values if the data supports it, given \\rho values between 0 and 0.5. Step 11: What is the model likelihood? SARS-CoV-2 is known to be overdispersed, so we will use a Negative-Binomial likelihood. We will match the reported incidence data to the reported incidence in our model, which is the rate of entry into the Q compartment. Thus, let \\mu = \\rho \\sigma E . Our likelihood is therefore: y \\sim NegBin(\\mu, \\kappa) This means we need to additionally estimate \\kappa . We will assume for which we will assume the prior \\kappa \\sim exp(0.01) which allows for a wide range of values reflecting our uncertainty. Step 12: What assumptions have we made? Some of the assumptions include: All reported incidence cases are due to the Omicron variant No waning immunity No vaccination No pre-symptomatic transmission All tested individuals isolate with 100% compliance The final model Now we have designed our first infectious disease model, the next step is to code it up in Stan, which we will do in chapter 2. References (1) Madhi SA, Kwatra G, Myers JE, et al. Population Immunity and Covid-19 Severity with Omicron Variant in South Africa. N Engl J Med 2022; 386(14): 1314-26. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Liu, Y. & Rocklov, J. Liu Y, Rocklov J. The reproductive number of the Delta variant of SARS-CoV-2 is far higher compared to the ancestral SARS-CoV-2 virus. J Travel Med 2021; 28(7). (5) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17.","title":"Chapter 1"},{"location":"chapter_1/#introduction-to-infectious-disease-modelling","text":"First, lets take a look at the storyboard below. It outlines some of the key steps when designing and building a model logically. Briefly, we need to define (1) our research question, (2) population and time period. Then we need to think about (3) how our model can reproduce the observed data. Are we modelling incidence or prevalence data? Next, we need to (4) design the compartmental model. Compartmental models are the bread and butter of infectious disease modelling. They are a system of differential equations which describe the flows of individuals from one infectious state to another and represent the infection history. In the figure we show an SIR model, the most simple model typically used. In this model we often assume that individuals in a population start out susceptible to a disease, i.e., they have no prior protective immunity. This is the S compartment. From there, individuals may be infected by the pathogen, at which point they are also infectious and enter the I compartment. Finally, when they recover from the disease and are no longer infectious, they enter the R compartment. I will assume you are familiar with compartmental models and so won't go into further detail here. If you are not so familiar, there are lots of good resources out there which already explain SIR models. For instance, Imperial has a module on SIR modules on Coursera . Or there are an abundance of videos on YouTube where people introduce SIR models, especially since COVID-19. This is a nice intro! Having designed the model, we need to (5) think about the initial conditions for each state. If an infectious agent is entirely new to a population, like SARS-CoV-2 was at the start of 2020, we would expect all of the population to be in the S compartment at time (t) = 0 , with a few individuals in the infectious compartment: S_{t0} = N - I_{t0} Where I_{t0} is the initial number infectious and N is the population size. If the in pathogen is not novel and there is prior immunity, then we might expect some of the population to be in the recovered compartment. Critically, the sum of all the compartments must equal the population size N , S + I + R = N The flow between the compartments is governed by rates (6). In this example, we have the transmission rate, typically denoted \\beta and the recovery rate, \\gamma . Note that because transmission depends on the number of infectious people we need to account for this. Hence, the force of infection (the per capita rate that susceptible individuals contract the infection) depends on he transmission rate and on the proportion of the population that is infectious: \\lambda = \\beta\\frac{I}{N} Next, we need to (7) convert our flow diagram into ODE equations. Simply, arrows leading out of a compartment represent subtractions and arrows leading into a compartment represent additions. After that, we need to decide (8) which parameters we want to fix and (9) which we want to estimate. This likely depends on the research question and available data and parameter estimates in the literature. As we are fitting the model using Bayesian inference, the next decisions we need to make are about the priors (10) and likelihood (11). Hopefully you are familiar with Bayesian statistics, but if not then I recommend going back to some of the resources suggested in the README.md . Briefly, what we are asking is, given the data y , what are the most likely parameters \\theta . Note, when we talk of parameters here, this refers to those we are estimating, not the fixed parameters . In other words, our posterior distribution is Pr(\\theta|y) . Bayes rule tells us that: Pr(\\theta | y) \\propto Pr(y | \\theta) Pr(\\theta) Where, Pr(y | \\theta) is the likelihood, or sampling distribution, and Pr(\\theta) is our prior distribution. The likelihood tells us how to generate our data y , given our model parameters. Our prior distributions allow us to incorporate existing domain knowledge into the model. Flat (i.e., uniform priors) and \"uninformative\" priors are discouraged in Stan, so we are going to avoid them. Ben Lambert explains here why priors are, depending on the frame of reference, never completely uninformative. Instead, we want prior distributions to be vague enough to explore all reasonable parameter values whilst preventing the sampler exploring areas of the parameter space that are implausible. For instance, say we were to estimate the recovery rate, \\gamma . \\gamma = \\frac{1}{D} , where D is the average duration of the infection. We know that this must be a positive number, so we can reflect this in our prior distribution. Moreover, even if we did not know very much about the clinical progression of COVID-19, we know that is an acute infection, not a chronic infection - i.e., people generally recovery within days - weeks. So we would want to explore recovery rates that reflect this. Allowing the sampler to explore the posterior distribution where \\frac{1}{\\gamma} is hundreds or even thousands of days would be inefficient. For more detail on choosing prior values take a look at this post written by Andrew Gelman, one of the developers of Stan. We also need to think about the model likelihood, which aims to capture the data generating process. Essentially, we need to link the chosen model output to the data we are fitting the model to. The distribution we choose to link our model output depends on the type of data we have, and there often isn't only one choice. In infectious disease modelling we often have incidence data, which we may want to fit using a Poisson likelihood . The Poisson distribution has one parameter, \\lambda which represents the mean rate of the event (in this case, infections) occurring in a fixed time and the variance. Q1: If we were to use the Poisson distribution to fit to incidence data, what model output would we fit to? Alternatively, if the data are over-dispersed, that is if the variance is larger than the mean then we might want to use a Negative Binomial likelihood. The Negative Binomial distribution extends the Poisson distribution with an additional parameter \\kappa which controls the over-dispersion of the distribution. Critically, the variance is now > \\lambda . When \\kappa is very small, over-dispersion is high, but when \\kappa is large enough, the Negative Binomial distribution converges on the Poisson! The final step in building our model is to think about the assumptions we have made along the way. As we said before, no model is perfect. We want our model to be as simple as possible, whilst still capturing the important features of the pathogen. This means we have to make simplifying assumptions in how we represent the transmission process in our compartments. One notable assumption is that everyone in each compartment is assumed to be homogeneous. Equally, there might be lots of unknowns about the disease or the data, which again means we will have to make assumptions! We can also do sensitivity analyses to explore the impact of our assumptions. An important thing to note is that although the steps in building a model may appear linear, model fitting is far from a linear process. These steps provide a loose guidance for the first iteration of model building, which should be as simple as possible. It is important to be flexible with these steps and to expect to have to go back and make changes to the model once you start fitting to the data. It may be that you realise you need additional data (3), you realise one of your simplifying assumptions (12) doesn't allow you to capture a key aspect of the data and so you amend the model by introducing extra compartments (4). Maybe there is more data available than when you started so you change a fixed parameter value (8) or amend your priors to incorporate additional domain knowledge (10)... you get the idea. So, now lets design the model.","title":"Introduction to infectious disease modelling"},{"location":"chapter_1/#step-1-define-the-reseach-question","text":"There may be multiple questions you want to answer in an analysis, and listing them helps you keep the focus. In this example, one of the key questions is: What is the reproduction number of the Omicron variant of concern?","title":"Step 1: Define the reseach question"},{"location":"chapter_1/#step-2-what-is-the-population-and-time-period","text":"This is partly answered by the research question, we are interested in the population of Gauteng and the period of time when Omicron first emerged.The population of Gauteng is 15,810,388 people. We know that Omicron was first detected in October 2021, but we suspect that there was probably some transmission before it was detected, so the start of our modelling period will be September 2021. We want to explore whether we can reconstruct the dynamics observed in the Omicron wave. If you look at this dashboard provided by the WHO, we can see that this 4 th wave was over by ~February. We will run our model till the 23 rd of February to make sure we capture all of the epidemic curve.","title":"Step 2: What is the population and time period?"},{"location":"chapter_1/#step-3-what-data-are-we-fitting-the-model-to","text":"We are going to fit to the reported incidence of SARS-CoV-2 for Gauteng, South Africa. We need to reconstruct the reported incidence from the model.","title":"Step 3: What data are we fitting the model to?"},{"location":"chapter_1/#step-4-what-compartments-do-we-minimally-need-to-represent-the-disease-transmission-process","text":"Starting with the SIR model, we want to account for the incubation period of COVID-19 and we need to account for only having data on the reported incidence. Therefore, we want to extend the simple SIR model in some way which allows for individuals to either be detected, reported and isolated or not detected, in which case they remain infectious and are not isolated for the whole duration of the infection. Q2: draw out a compartmental model which accounts for the above","title":"Step 4: What compartments do we minimally need to represent the disease transmission process?"},{"location":"chapter_1/#step-5-what-are-the-initial-conditions-what-do-we-want-to-estimate-what-do-we-want-to-fix","text":"Our population = N = 15810388. We can assume that E_{t0} and Q_{t0} = 0. As we are fitting to the 4 th wave of SARS-CoV-2 in Gauteng, we know some of the population will already have had an infection and have immunity, so they go in the R compartment. We can look to seroprevalence surveys for data on the percentage of the population with immunity.56.2% of the unvaccinated population of Gauteng had antibodies to SARS-CoV-2 in December 2021 [1]. Note, this is slightly after the emergence of Omicron but it is the best data we have for now. So: R_{t0} = 15,810,388 * 0.562 = 8,885,438 For this tutorial, we will assume that the initial number of infections I_{t0} = 1 , however as the true number of infections is an unobserved quantity, this is often a parameter value to be estimated. Finally, S_{t0} = N - R_{t0} - I_{t0}","title":"Step 5: What are the initial conditions? What do we want to estimate? What do we want to fix?"},{"location":"chapter_1/#step-6-what-are-the-rate-parameters-which-describe-flows-between-the-compartments","text":"Note, \\beta , \\sigma and \\gamma are all per capita rates, whereas \\rho is a probability. All individuals will progress to be infectious at an average rate of \\sigma and a proportion \\rho will be tested, reported and quarantined.","title":"Step 6: What are the rate parameters which describe flows between the compartments?"},{"location":"chapter_1/#step-7-what-are-the-equations-that-govern-the-model","text":"Once you have a flow diagram with rates, writing the equations is simple! Arrows out of a state are subtracted, arrows into a stated are added. A good check is to make sure the equations balance.","title":"Step 7: What are the equations that govern the model?"},{"location":"chapter_1/#step-8-which-parameters-can-we-fix-based-on-the-literature","text":"We will assume an average latent period \\frac{1}{\\sigma} of 3.03 days, as estimated for Omicron [2] and an average infectious period \\frac{1}{\\gamma} of 4.17 days [3].","title":"Step 8: Which parameters can we fix based on the literature?"},{"location":"chapter_1/#step-9-which-parameters-do-we-need-to-estimate","text":"Having fixed the generation time (i.e., \\sigma and \\gamma ), we are going to estimate \\beta and \\rho . Q3: why would we want to estimate these parameters?","title":"Step 9: Which parameters do we need to estimate?"},{"location":"chapter_1/#step-10-do-we-have-any-domain-knowledge-to-inform-the-parameter-priors","text":"As stated above, we want to choose weakly informative priors in order to include enough information to regularise the model. One way to achieve this, is to not use hard bounds, unless there are true constrains. For example, \\rho , is the probability of reporting which must be between 0 and 1, therefore using a beta prior is suitable here. If we thought that every value of \\rho was equally likely, we could set a prior \\rho \\sim Beta(1,1) . As it is, a sero-survey from Gauteng, South Africa in January 2021 estimated a 2-20 fold underreporting of cases, corresponding to a reporting rate <50% [5]. Therefore, lets assume a prior that supports values below 50%, but still allows for higher values if the data support it: \\rho \\sim Beta(2,8) . Q4: use the function rbeta() to check the distribution of \\rho \\sim Beta(2,8) Another way to explore the shape of distributions is the distribution zoo , created by Ben Lambert and Fergus Cooper. For the \\beta parameter, we are not sure how transmissible Omicron is yet, but we think somewhere similar or more transmissible than the Delta variant. A useful measure of transmission is the Reproduction number ( R_0 ), the average number of secondary cases produced per infectious individual in an susceptible population. The R_0 for a simple SIR model is equal to the transmission rate multiplied by the average duration of the infectious period. For a simple SIR model this would be: R_0 = \\frac{\\beta}{\\gamma} For our model: R_0 = \\frac{(1-\\rho)\\beta}{\\gamma} Intuitively, this is due to the fact that only a proportion (1-\\rho) of subjects contribute to onwards transmission. More formally, this can also be demonstrated using the next generation matrices method , if interested. The R_0 of Delta is estimated around 5 [4], so exploring values of \\beta that correspond to R_0 estimates around 5 and above seems reasonable. Q5: Define a prior for \\beta which supports R_0 values around 5 but allows for higher values if the data supports it, given \\rho values between 0 and 0.5.","title":"Step 10: Do we have any domain knowledge to inform the parameter priors?"},{"location":"chapter_1/#step-11-what-is-the-model-likelihood","text":"SARS-CoV-2 is known to be overdispersed, so we will use a Negative-Binomial likelihood. We will match the reported incidence data to the reported incidence in our model, which is the rate of entry into the Q compartment. Thus, let \\mu = \\rho \\sigma E . Our likelihood is therefore: y \\sim NegBin(\\mu, \\kappa) This means we need to additionally estimate \\kappa . We will assume for which we will assume the prior \\kappa \\sim exp(0.01) which allows for a wide range of values reflecting our uncertainty.","title":"Step 11: What is the model likelihood?"},{"location":"chapter_1/#step-12-what-assumptions-have-we-made","text":"Some of the assumptions include: All reported incidence cases are due to the Omicron variant No waning immunity No vaccination No pre-symptomatic transmission All tested individuals isolate with 100% compliance","title":"Step 12: What assumptions have we made?"},{"location":"chapter_1/#the-final-model","text":"Now we have designed our first infectious disease model, the next step is to code it up in Stan, which we will do in chapter 2.","title":"The final model"},{"location":"chapter_1/#references","text":"(1) Madhi SA, Kwatra G, Myers JE, et al. Population Immunity and Covid-19 Severity with Omicron Variant in South Africa. N Engl J Med 2022; 386(14): 1314-26. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Liu, Y. & Rocklov, J. Liu Y, Rocklov J. The reproductive number of the Delta variant of SARS-CoV-2 is far higher compared to the ancestral SARS-CoV-2 virus. J Travel Med 2021; 28(7). (5) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17.","title":"References"},{"location":"chapter_1_solutions/","text":"Hi and welcome to the chapter in this exampler on designing an infectious disease model. The overall aim of this script is to design a Susceptible (S) - Exposed (E) - Infectious (I) - Quarantine (Q) - Recovered (R) model to explore the transmission dynamics of Omicron in Gauteng, South Africa between late 2021 and early 2022. This script show step by step how to design an infectious disease compartmental model to answer a public health question. There are many choices to be made along the way, so it is important to think about the assumptions we are making so our model is robust. Some questions include: What are the most important disease and epidemiological features? How do we represent these features in a model? What data do is needed to calibrate the model? What parameters should be estimated? Disclaimer: \"all models are wrong. Some models are useful\" - George E. P. Box Introduction to infectious disease modelling First, lets take a look at the storyboard below. It outlines some of the key steps when designing and building a model logically. Briefly, we need to define (1) our research question, (2) population and time period. Then we need to think about (3) how our model can reproduce the observed data. Are we modelling incidence or prevalence data? Next, we need to (4) design the compartmental model. Compartmental models are the bread and butter of infectious disease modelling. They are a system of differential equations which describe the flows of individuals from one infectious state to another and represent the infection history. In the figure we show an SIR model, the most simple model typically used. In this model we often assume that individuals in a population start out susceptible to a disease, i.e., they have no prior protective immunity. This is the S compartment. From there, individuals may be infected by the pathogen, at which point they are also infectious and enter the I compartment. Finally, when they recover from the disease and are no longer infectious, they enter the R compartment. I will assume you are familiar with compartmental models and so won't go into further detail here. If you are not so familiar, there are lots of good resources out there which already explain SIR models. For instance, Imperial has a module on SIR modules on Coursera . Or there are an abundance of videos on YouTube where people introduce SIR models, especially since COVID-19. This is a nice intro! Having designed the model, we need to (5) think about the initial conditions for each state. If an infectious agent is entirely new to a population, like SARS-CoV-2 was at the start of 2020, we would expect all of the population to be in the S compartment at time (t) = 0 , with a few individuals in the infectious compartment: S_{t0} = N - I_{t0} Where I_{t0} is the initial number infectious and N is the population size. If the in pathogen is not novel and there is prior immunity, then we might expect some of the population to be in the recovered compartment. Critically, the sum of all the compartments must equal the population size N , S + I + R = N The flow between the compartments is governed by rates (6). In this example, we have the transmission rate, typically denoted \\beta and the recovery rate, \\gamma . Note that because transmission depends on the number of infectious people we need to account for this. Hence, the force of infection (the per capita rate that susceptible individuals contract the infection) depends on he transmission rate and on the proportion of the population that is infectious: \\lambda = \\beta\\frac{I}{N} Next, we need to (7) convert our flow diagram into ODE equations. Simply, arrows leading out of a compartment represent subtractions and arrows leading into a compartment represent additions. After that, we need to decide (8) which parameters we want to fix and (9) which we want to estimate. This likely depends on the research question and available data and parameter estimates in the literature. As we are fitting the model using Bayesian inference, the next decisions we need to make are about the priors (10) and likelihood (11). Hopefully you are familiar with Bayesian statistics, but if not then I recommend going back to some of the resources suggested in the README.md . Briefly, what we are asking is, given the data y , what are the most likely parameters \\theta . Note, when we talk of parameters here, this refers to those we are estimating, not the fixed parameters . In other words, our posterior distribution is Pr(\\theta|y) . Bayes rule tells us that: Pr(\\theta | y) \\propto Pr(y | \\theta) Pr(\\theta) Where, Pr(y | \\theta) is the likelihood, or sampling distribution, and Pr(\\theta) is our prior distribution. The likelihood tells us how to generate our data y , given our model parameters. Our prior distributions allow us to incorporate existing domain knowledge into the model. Flat (i.e., uniform priors) and \"uninformative\" priors are discouraged in Stan, so we are going to avoid them. Ben Lambert explains here why priors are, depending on the frame of reference, never completely uninformative. Instead, we want prior distributions to be vague enough to explore all reasonable parameter values whilst preventing the sampler exploring areas of the parameter space that are implausible. For instance, say we were to estimate the recovery rate, \\gamma . \\gamma = \\frac{1}{D} , where D is the average duration of the infection. We know that this must be a positive number, so we can reflect this in our prior distribution. Moreover, even if we did not know very much about the clinical progression of COVID-19, we know that is an acute infection, not a chronic infection - i.e., people generally recovery within days - weeks. So we would want to explore recovery rates that reflect this. Allowing the sampler to explore the posterior distribution where \\frac{1}{\\gamma} is hundreds or even thousands of days would be inefficient. For more detail on choosing prior values take a look at this post written by Andrew Gelman, one of the developers of Stan. We also need to think about the model likelihood, which aims to capture the data generating process. Essentially, we need to link the chosen model output to the data we are fitting the model to. The distribution we choose to link our model output depends on the type of data we have, and there often isn't only one choice. In infectious disease modelling we often have incidence data, which we may want to fit using a Poisson likelihood . The Poisson distribution has one parameter, \\lambda which represents the mean rate of the event (in this case, infections) occurring in a fixed time and the variance. Q1: If we were to use the Poisson distribution to fit to incidence data, what model output would we fit to? A1: The rate that individuals become infectious, i.e., the rate that they enter the I compartment, = \\beta \\frac{I}{N} S . Alternatively, if the data are over-dispersed, that is if the variance is larger than the mean then we might want to use a Negative Binomial likelihood. The Negative Binomial distribution extends the Poisson distribution with an additional parameter \\kappa which controls the over-dispersion of the distribution. Critically, the variance is now > \\lambda . When \\kappa is very small, over-dispersion is high, but when \\kappa is large enough, the Negative Binomial distribution converges on the Poisson! The final step in building our model is to think about the assumptions we have made along the way. As we said before, no model is perfect. We want our model to be as simple as possible, whilst still capturing the important features of the pathogen. This means we have to make simplifying assumptions in how we represent the transmission process in our compartments. One notable assumption is that everyone in each compartment is assumed to be homogeneous. Equally, there might be lots of unknowns about the disease or the data, which again means we will have to make assumptions! We can also do sensitivity analyses to explore the impact of our assumptions. An important thing to note is that although the steps in building a model may appear linear, model fitting is far from a linear process. These steps provide a loose guidance for the first iteration of model building, which should be as simple as possible. It is important to be flexible with these steps and to expect to have to go back and make changes to the model once you start fitting to the data. It may be that you realise you need additional data (3), you realise one of your simplifying assumptions (12) doesn't allow you to capture a key aspect of the data and so you amend the model by introducing extra compartments (4). Maybe there is more data available than when you started so you change a fixed parameter value (8) or amend your priors to incorporate additional domain knowledge (10)... you get the idea. So, now lets design the model. Step 1: Define the reseach question There may be multiple questions you want to answer in an analysis, and listing them helps you keep the focus. In this example, one of the key questions is: What is the reproduction number of the Omicron variant of concern? Step 2: What is the population and time period? This is partly answered by the research question, we are interested in the population of Gauteng and the period of time when Omicron first emerged.The population of Gauteng is 15,810,388 people. We know that Omicron was first detected in October 2021, but we suspect that there was probably some transmission before it was detected, so the start of our modelling period will be September 2021. We want to explore whether we can reconstruct the dynamics observed in the Omicron wave. If you look at this dashboard provided by the WHO, we can see that this 4 th wave was over by ~February. We will run our model till the 23 rd of February to make sure we capture all of the epidemic curve. Step 3: What data are we fitting the model to? We are going to fit to the reported incidence of SARS-CoV-2 for Gauteng, South Africa. We need to reconstruct the reported incidence from the model. Step 4: What compartments do we minimally need to represent the disease transmission process? Starting with the SIR model, we want to account for the incubation period of COVID-19 and we need to account for only having data on the reported incidence. Therefore, we want to extend the simple SIR model in some way which allows for individuals to either be detected, reported and isolated or not detected, in which case they remain infectious and are not isolated for the whole duration of the infection. Q2: draw out a compartmental model which accounts for the above A2: see flow diagram figure below Step 5: What are the initial conditions? What do we want to estimate? What do we want to fix? Our population = N = 15810388. We can assume that E_{t0} and Q_{t0} = 0. As we are fitting to the 4 th wave of SARS-CoV-2 in Gauteng, we know some of the population will already have had an infection and have immunity, so they go in the R compartment. We can look to seroprevalence surveys for data on the percentage of the population with immunity.56.2% of the unvaccinated population of Gauteng had antibodies to SARS-CoV-2 in December 2021 [1]. Note, this is slightly after the emergence of Omicron but it is the best data we have for now. So: R_{t0} = 15,810,388 * 0.562 = 8,885,438 For this tutorial, we will assume that the initial number of infections I_{t0} = 1 , however as the true number of infections is an unobserved quantity, this is often a parameter value to be estimated. Finally, S_{t0} = N - R_{t0} - I_{t0} Step 6: What are the rate parameters which describe flows between the compartments? Note, \\beta , \\sigma and \\gamma are all per capita rates, whereas \\rho is a probability. All individuals will progress to be infectious at an average rate of \\sigma and a proportion \\rho will be tested, reported and quarantined. Step 7: What are the equations that govern the model? Once you have a flow diagram with rates, writing the equations is simple! Arrows out of a state are subtracted, arrows into a stated are added. A good check is to make sure the equations balance. Step 8: Which parameters can we fix based on the literature? We will assume an average latent period \\frac{1}{\\sigma} of 3.03 days, as estimated for Omicron [2] and an average infectious period \\frac{1}{\\gamma} of 4.17 days [3]. Step 9: Which parameters do we need to estimate? Having fixed the generation time (i.e., \\sigma and \\gamma ), we are going to estimate \\beta and \\rho . Q3: why would we want to estimate these parameters? Q3: We want to estimate \\beta as it is variant-specific and therefore unknown following the emergence of a new SARS-CoV-2 variant. Estimating \\beta allows us to calculate the R_0 . We need to estimate \\rho as the true incidence of SARS-CoV-2 is unobserved, so the level of under-reporting is unknown. Moreover, reporting and detection of cases is dependent on the rate of population testing soit is spatiotemporally heterogeneous Step 10: Do we have any domain knowledge to inform the parameter priors? As stated above, we want to choose weakly informative priors in order to include enough information to regularise the model. One way to achieve this, is to not use hard bounds, unless there are true constrains. For example, \\rho , is the probability of reporting which must be between 0 and 1, therefore using a beta prior is suitable here. If we thought that every value of \\rho was equally likely, we could set a prior \\rho \\sim Beta(1,1) . As it is, a sero-survey from Gauteng, South Africa in January 2021 estimated a 2-20 fold underreporting of cases, corresponding to a reporting rate <50% [5]. Therefore, lets assume a prior that supports values below 50%, but still allows for higher values if the data support it: \\rho \\sim Beta(2,8) . Q4: use the function rbeta() to check the distribution of \\rho \\sim Beta(2,8) A4 samp = rbeta ( 10000 , 2 , 8 ) qplot ( samp ) Another way to explore the shape of distributions is the distribution zoo , created by Ben Lambert and Fergus Cooper. For the \\beta parameter, we are not sure how transmissible Omicron is yet, but we think somewhere similar or more transmissible than the Delta variant. A useful measure of transmission is the Reproduction number ( R_0 ), the average number of secondary cases produced per infectious individual in an susceptible population. The R_0 for a simple SIR model is equal to the transmission rate multiplied by the average duration of the infectious period. For a simple SIR model this would be: R_0 = \\frac{\\beta}{\\gamma} For our model: R_0 = \\frac{(1-\\rho)\\beta}{\\gamma} Intuitively, this is due to the fact that only a proportion (1-\\rho) of subjects contribute to onwards transmission. More formally, this can also be demonstrated using the next generation matrices method , if interested. The R_0 of Delta is estimated around 5 [4], so exploring values of \\beta that correspond to R_0 estimates around 5 and above seems reasonable. Q5: Define a prior for \\beta which supports R_0 values around 5 but allows for higher values if the data supports it, given \\rho values between 0 and 0.5. A5 \\beta = \\frac{R_0 \\gamma}{(1-\\rho)} . set.seed ( 12 ) R0 = runif ( 10000 , 4 , 10 ) # draw randomly 10,000 values between 4 and 10 gamma = 1 / 4.17 rho = runif ( 10000 , 0 , 0.5 ) # calculate values of beta beta = R0 * gamma / ( 1 - rho ) # 95% quantiles of beta quantile ( beta , probs = c ( 0.025 , 0.5 , 0.975 )) ## 2.5% 50% 97.5% ## 1.156041 2.236819 4.067416 # draw from a normal distribution beta_prior = rnorm ( 10000 , 2.2 , 1 ) qplot ( beta_prior ) # check values of beta support R0 range R0_p = ( 1 - rho ) * ( beta_prior ) / gamma quantile ( R0_p , probs = c ( 0.025 , 0.1 , 0.25 , 0.5 , 0.75 , 0.9 , 0.975 )) ## 2.5% 10% 25% 50% 75% 90% 97.5% ## 0.7447701 2.7193864 4.5400148 6.6724047 9.0758795 11.4707453 14.2731938 qplot ( R0_p ) We can see that \\beta \\sim ND(2.2,1) supports R_0 values mostly between 4 and 10, but allow for extreme values of R_0 if the data supports it. Step 11: What is the model likelihood? SARS-CoV-2 is known to be overdispersed, so we will use a Negative-Binomial likelihood. We will match the reported incidence data to the reported incidence in our model, which is the rate of entry into the Q compartment. Thus, let \\mu = \\rho \\sigma E . Our likelihood is therefore: y \\sim NegBin(\\mu, \\kappa) This means we need to additionally estimate \\kappa . We will assume for which we will assume the prior \\kappa \\sim exp(0.01) which allows for a wide range of values reflecting our uncertainty. Step 12: What assumptions have we made? Some of the assumptions include: All reported incidence cases are due to the Omicron variant No waning immunity No vaccination No pre-symptomatic transmission All tested individuals isolate with 100% compliance The final model Now we have designed our first infectious disease model, the next step is to code it up in Stan, which we will do in chapter 2. References (1) Madhi SA, Kwatra G, Myers JE, et al. Population Immunity and Covid-19 Severity with Omicron Variant in South Africa. N Engl J Med 2022; 386(14): 1314-26. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Liu, Y. & Rocklov, J. Liu Y, Rocklov J. The reproductive number of the Delta variant of SARS-CoV-2 is far higher compared to the ancestral SARS-CoV-2 virus. J Travel Med 2021; 28(7). (5) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17.","title":"Chapter 1: Designing an infectious disease model"},{"location":"chapter_1_solutions/#introduction-to-infectious-disease-modelling","text":"First, lets take a look at the storyboard below. It outlines some of the key steps when designing and building a model logically. Briefly, we need to define (1) our research question, (2) population and time period. Then we need to think about (3) how our model can reproduce the observed data. Are we modelling incidence or prevalence data? Next, we need to (4) design the compartmental model. Compartmental models are the bread and butter of infectious disease modelling. They are a system of differential equations which describe the flows of individuals from one infectious state to another and represent the infection history. In the figure we show an SIR model, the most simple model typically used. In this model we often assume that individuals in a population start out susceptible to a disease, i.e., they have no prior protective immunity. This is the S compartment. From there, individuals may be infected by the pathogen, at which point they are also infectious and enter the I compartment. Finally, when they recover from the disease and are no longer infectious, they enter the R compartment. I will assume you are familiar with compartmental models and so won't go into further detail here. If you are not so familiar, there are lots of good resources out there which already explain SIR models. For instance, Imperial has a module on SIR modules on Coursera . Or there are an abundance of videos on YouTube where people introduce SIR models, especially since COVID-19. This is a nice intro! Having designed the model, we need to (5) think about the initial conditions for each state. If an infectious agent is entirely new to a population, like SARS-CoV-2 was at the start of 2020, we would expect all of the population to be in the S compartment at time (t) = 0 , with a few individuals in the infectious compartment: S_{t0} = N - I_{t0} Where I_{t0} is the initial number infectious and N is the population size. If the in pathogen is not novel and there is prior immunity, then we might expect some of the population to be in the recovered compartment. Critically, the sum of all the compartments must equal the population size N , S + I + R = N The flow between the compartments is governed by rates (6). In this example, we have the transmission rate, typically denoted \\beta and the recovery rate, \\gamma . Note that because transmission depends on the number of infectious people we need to account for this. Hence, the force of infection (the per capita rate that susceptible individuals contract the infection) depends on he transmission rate and on the proportion of the population that is infectious: \\lambda = \\beta\\frac{I}{N} Next, we need to (7) convert our flow diagram into ODE equations. Simply, arrows leading out of a compartment represent subtractions and arrows leading into a compartment represent additions. After that, we need to decide (8) which parameters we want to fix and (9) which we want to estimate. This likely depends on the research question and available data and parameter estimates in the literature. As we are fitting the model using Bayesian inference, the next decisions we need to make are about the priors (10) and likelihood (11). Hopefully you are familiar with Bayesian statistics, but if not then I recommend going back to some of the resources suggested in the README.md . Briefly, what we are asking is, given the data y , what are the most likely parameters \\theta . Note, when we talk of parameters here, this refers to those we are estimating, not the fixed parameters . In other words, our posterior distribution is Pr(\\theta|y) . Bayes rule tells us that: Pr(\\theta | y) \\propto Pr(y | \\theta) Pr(\\theta) Where, Pr(y | \\theta) is the likelihood, or sampling distribution, and Pr(\\theta) is our prior distribution. The likelihood tells us how to generate our data y , given our model parameters. Our prior distributions allow us to incorporate existing domain knowledge into the model. Flat (i.e., uniform priors) and \"uninformative\" priors are discouraged in Stan, so we are going to avoid them. Ben Lambert explains here why priors are, depending on the frame of reference, never completely uninformative. Instead, we want prior distributions to be vague enough to explore all reasonable parameter values whilst preventing the sampler exploring areas of the parameter space that are implausible. For instance, say we were to estimate the recovery rate, \\gamma . \\gamma = \\frac{1}{D} , where D is the average duration of the infection. We know that this must be a positive number, so we can reflect this in our prior distribution. Moreover, even if we did not know very much about the clinical progression of COVID-19, we know that is an acute infection, not a chronic infection - i.e., people generally recovery within days - weeks. So we would want to explore recovery rates that reflect this. Allowing the sampler to explore the posterior distribution where \\frac{1}{\\gamma} is hundreds or even thousands of days would be inefficient. For more detail on choosing prior values take a look at this post written by Andrew Gelman, one of the developers of Stan. We also need to think about the model likelihood, which aims to capture the data generating process. Essentially, we need to link the chosen model output to the data we are fitting the model to. The distribution we choose to link our model output depends on the type of data we have, and there often isn't only one choice. In infectious disease modelling we often have incidence data, which we may want to fit using a Poisson likelihood . The Poisson distribution has one parameter, \\lambda which represents the mean rate of the event (in this case, infections) occurring in a fixed time and the variance. Q1: If we were to use the Poisson distribution to fit to incidence data, what model output would we fit to? A1: The rate that individuals become infectious, i.e., the rate that they enter the I compartment, = \\beta \\frac{I}{N} S . Alternatively, if the data are over-dispersed, that is if the variance is larger than the mean then we might want to use a Negative Binomial likelihood. The Negative Binomial distribution extends the Poisson distribution with an additional parameter \\kappa which controls the over-dispersion of the distribution. Critically, the variance is now > \\lambda . When \\kappa is very small, over-dispersion is high, but when \\kappa is large enough, the Negative Binomial distribution converges on the Poisson! The final step in building our model is to think about the assumptions we have made along the way. As we said before, no model is perfect. We want our model to be as simple as possible, whilst still capturing the important features of the pathogen. This means we have to make simplifying assumptions in how we represent the transmission process in our compartments. One notable assumption is that everyone in each compartment is assumed to be homogeneous. Equally, there might be lots of unknowns about the disease or the data, which again means we will have to make assumptions! We can also do sensitivity analyses to explore the impact of our assumptions. An important thing to note is that although the steps in building a model may appear linear, model fitting is far from a linear process. These steps provide a loose guidance for the first iteration of model building, which should be as simple as possible. It is important to be flexible with these steps and to expect to have to go back and make changes to the model once you start fitting to the data. It may be that you realise you need additional data (3), you realise one of your simplifying assumptions (12) doesn't allow you to capture a key aspect of the data and so you amend the model by introducing extra compartments (4). Maybe there is more data available than when you started so you change a fixed parameter value (8) or amend your priors to incorporate additional domain knowledge (10)... you get the idea. So, now lets design the model.","title":"Introduction to infectious disease modelling"},{"location":"chapter_1_solutions/#step-1-define-the-reseach-question","text":"There may be multiple questions you want to answer in an analysis, and listing them helps you keep the focus. In this example, one of the key questions is: What is the reproduction number of the Omicron variant of concern?","title":"Step 1: Define the reseach question"},{"location":"chapter_1_solutions/#step-2-what-is-the-population-and-time-period","text":"This is partly answered by the research question, we are interested in the population of Gauteng and the period of time when Omicron first emerged.The population of Gauteng is 15,810,388 people. We know that Omicron was first detected in October 2021, but we suspect that there was probably some transmission before it was detected, so the start of our modelling period will be September 2021. We want to explore whether we can reconstruct the dynamics observed in the Omicron wave. If you look at this dashboard provided by the WHO, we can see that this 4 th wave was over by ~February. We will run our model till the 23 rd of February to make sure we capture all of the epidemic curve.","title":"Step 2: What is the population and time period?"},{"location":"chapter_1_solutions/#step-3-what-data-are-we-fitting-the-model-to","text":"We are going to fit to the reported incidence of SARS-CoV-2 for Gauteng, South Africa. We need to reconstruct the reported incidence from the model.","title":"Step 3: What data are we fitting the model to?"},{"location":"chapter_1_solutions/#step-4-what-compartments-do-we-minimally-need-to-represent-the-disease-transmission-process","text":"Starting with the SIR model, we want to account for the incubation period of COVID-19 and we need to account for only having data on the reported incidence. Therefore, we want to extend the simple SIR model in some way which allows for individuals to either be detected, reported and isolated or not detected, in which case they remain infectious and are not isolated for the whole duration of the infection. Q2: draw out a compartmental model which accounts for the above A2: see flow diagram figure below","title":"Step 4: What compartments do we minimally need to represent the disease transmission process?"},{"location":"chapter_1_solutions/#step-5-what-are-the-initial-conditions-what-do-we-want-to-estimate-what-do-we-want-to-fix","text":"Our population = N = 15810388. We can assume that E_{t0} and Q_{t0} = 0. As we are fitting to the 4 th wave of SARS-CoV-2 in Gauteng, we know some of the population will already have had an infection and have immunity, so they go in the R compartment. We can look to seroprevalence surveys for data on the percentage of the population with immunity.56.2% of the unvaccinated population of Gauteng had antibodies to SARS-CoV-2 in December 2021 [1]. Note, this is slightly after the emergence of Omicron but it is the best data we have for now. So: R_{t0} = 15,810,388 * 0.562 = 8,885,438 For this tutorial, we will assume that the initial number of infections I_{t0} = 1 , however as the true number of infections is an unobserved quantity, this is often a parameter value to be estimated. Finally, S_{t0} = N - R_{t0} - I_{t0}","title":"Step 5: What are the initial conditions? What do we want to estimate? What do we want to fix?"},{"location":"chapter_1_solutions/#step-6-what-are-the-rate-parameters-which-describe-flows-between-the-compartments","text":"Note, \\beta , \\sigma and \\gamma are all per capita rates, whereas \\rho is a probability. All individuals will progress to be infectious at an average rate of \\sigma and a proportion \\rho will be tested, reported and quarantined.","title":"Step 6: What are the rate parameters which describe flows between the compartments?"},{"location":"chapter_1_solutions/#step-7-what-are-the-equations-that-govern-the-model","text":"Once you have a flow diagram with rates, writing the equations is simple! Arrows out of a state are subtracted, arrows into a stated are added. A good check is to make sure the equations balance.","title":"Step 7: What are the equations that govern the model?"},{"location":"chapter_1_solutions/#step-8-which-parameters-can-we-fix-based-on-the-literature","text":"We will assume an average latent period \\frac{1}{\\sigma} of 3.03 days, as estimated for Omicron [2] and an average infectious period \\frac{1}{\\gamma} of 4.17 days [3].","title":"Step 8: Which parameters can we fix based on the literature?"},{"location":"chapter_1_solutions/#step-9-which-parameters-do-we-need-to-estimate","text":"Having fixed the generation time (i.e., \\sigma and \\gamma ), we are going to estimate \\beta and \\rho . Q3: why would we want to estimate these parameters? Q3: We want to estimate \\beta as it is variant-specific and therefore unknown following the emergence of a new SARS-CoV-2 variant. Estimating \\beta allows us to calculate the R_0 . We need to estimate \\rho as the true incidence of SARS-CoV-2 is unobserved, so the level of under-reporting is unknown. Moreover, reporting and detection of cases is dependent on the rate of population testing soit is spatiotemporally heterogeneous","title":"Step 9: Which parameters do we need to estimate?"},{"location":"chapter_1_solutions/#step-10-do-we-have-any-domain-knowledge-to-inform-the-parameter-priors","text":"As stated above, we want to choose weakly informative priors in order to include enough information to regularise the model. One way to achieve this, is to not use hard bounds, unless there are true constrains. For example, \\rho , is the probability of reporting which must be between 0 and 1, therefore using a beta prior is suitable here. If we thought that every value of \\rho was equally likely, we could set a prior \\rho \\sim Beta(1,1) . As it is, a sero-survey from Gauteng, South Africa in January 2021 estimated a 2-20 fold underreporting of cases, corresponding to a reporting rate <50% [5]. Therefore, lets assume a prior that supports values below 50%, but still allows for higher values if the data support it: \\rho \\sim Beta(2,8) . Q4: use the function rbeta() to check the distribution of \\rho \\sim Beta(2,8) A4 samp = rbeta ( 10000 , 2 , 8 ) qplot ( samp ) Another way to explore the shape of distributions is the distribution zoo , created by Ben Lambert and Fergus Cooper. For the \\beta parameter, we are not sure how transmissible Omicron is yet, but we think somewhere similar or more transmissible than the Delta variant. A useful measure of transmission is the Reproduction number ( R_0 ), the average number of secondary cases produced per infectious individual in an susceptible population. The R_0 for a simple SIR model is equal to the transmission rate multiplied by the average duration of the infectious period. For a simple SIR model this would be: R_0 = \\frac{\\beta}{\\gamma} For our model: R_0 = \\frac{(1-\\rho)\\beta}{\\gamma} Intuitively, this is due to the fact that only a proportion (1-\\rho) of subjects contribute to onwards transmission. More formally, this can also be demonstrated using the next generation matrices method , if interested. The R_0 of Delta is estimated around 5 [4], so exploring values of \\beta that correspond to R_0 estimates around 5 and above seems reasonable. Q5: Define a prior for \\beta which supports R_0 values around 5 but allows for higher values if the data supports it, given \\rho values between 0 and 0.5. A5 \\beta = \\frac{R_0 \\gamma}{(1-\\rho)} . set.seed ( 12 ) R0 = runif ( 10000 , 4 , 10 ) # draw randomly 10,000 values between 4 and 10 gamma = 1 / 4.17 rho = runif ( 10000 , 0 , 0.5 ) # calculate values of beta beta = R0 * gamma / ( 1 - rho ) # 95% quantiles of beta quantile ( beta , probs = c ( 0.025 , 0.5 , 0.975 )) ## 2.5% 50% 97.5% ## 1.156041 2.236819 4.067416 # draw from a normal distribution beta_prior = rnorm ( 10000 , 2.2 , 1 ) qplot ( beta_prior ) # check values of beta support R0 range R0_p = ( 1 - rho ) * ( beta_prior ) / gamma quantile ( R0_p , probs = c ( 0.025 , 0.1 , 0.25 , 0.5 , 0.75 , 0.9 , 0.975 )) ## 2.5% 10% 25% 50% 75% 90% 97.5% ## 0.7447701 2.7193864 4.5400148 6.6724047 9.0758795 11.4707453 14.2731938 qplot ( R0_p ) We can see that \\beta \\sim ND(2.2,1) supports R_0 values mostly between 4 and 10, but allow for extreme values of R_0 if the data supports it.","title":"Step 10: Do we have any domain knowledge to inform the parameter priors?"},{"location":"chapter_1_solutions/#step-11-what-is-the-model-likelihood","text":"SARS-CoV-2 is known to be overdispersed, so we will use a Negative-Binomial likelihood. We will match the reported incidence data to the reported incidence in our model, which is the rate of entry into the Q compartment. Thus, let \\mu = \\rho \\sigma E . Our likelihood is therefore: y \\sim NegBin(\\mu, \\kappa) This means we need to additionally estimate \\kappa . We will assume for which we will assume the prior \\kappa \\sim exp(0.01) which allows for a wide range of values reflecting our uncertainty.","title":"Step 11: What is the model likelihood?"},{"location":"chapter_1_solutions/#step-12-what-assumptions-have-we-made","text":"Some of the assumptions include: All reported incidence cases are due to the Omicron variant No waning immunity No vaccination No pre-symptomatic transmission All tested individuals isolate with 100% compliance","title":"Step 12: What assumptions have we made?"},{"location":"chapter_1_solutions/#the-final-model","text":"Now we have designed our first infectious disease model, the next step is to code it up in Stan, which we will do in chapter 2.","title":"The final model"},{"location":"chapter_1_solutions/#references","text":"(1) Madhi SA, Kwatra G, Myers JE, et al. Population Immunity and Covid-19 Severity with Omicron Variant in South Africa. N Engl J Med 2022; 386(14): 1314-26. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Liu, Y. & Rocklov, J. Liu Y, Rocklov J. The reproductive number of the Delta variant of SARS-CoV-2 is far higher compared to the ancestral SARS-CoV-2 virus. J Travel Med 2021; 28(7). (5) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17.","title":"References"},{"location":"chapter_2/","text":"In this chapter, we are going to fit the single variant model designed in chapter 1, using Stan. First, we need to load some packages. We also need to source the functions needed to run this script, found in the R folder. Finally, we need to compile the Stan models, found in the models folder. library ( dplyr ) library ( ggplot2 ) library ( rstan ) rstan_options ( auto_write = TRUE ) options ( mc.cores = parallel :: detectCores ()) # Functions source ( \"R/simulate_data.R\" ) source ( \"R/calc_sim_incidence.R\" ) source ( \"R/draw_init_values.R\" ) source ( \"R/run_stan_models.R\" ) source ( \"R/diagnose_stan_fit.R\" ) source ( \"R/plot_model_fit.R\" ) source ( \"R/compare_param_est.R\" ) source ( \"R/tidy_data.R\" ) # Models m1_EU = stan_model ( \"models/model1_Euler_V1.stan\" ) m1_RK = stan_model ( \"models/model1_RK_V1.stan\" ) m1_EU2 = stan_model ( \"models/model1_Euler_V2.stan\" ) Simulating data In this project, we are going to use simulated data. This is useful to check we have no bugs in our code. Also, even though Stan has lots of helpful diagnostics, we can never be completely certain our sampling algorithm has converged on the true posterior distribution. The diagnostics only confirm when it definitely hasn't. Therefore, using simulated data lets us check that the model can recover known posterior estimates, which gives us more confidence when it comes to fitting to observed data. Defining global parameters First, lets set the start and end date over which to fit the model, converted into a date format in R. For more detail on working with dates in R, see here . As mentioned, we want to seed Omicron 1 month before we fit to data, so we can define that here too. date_seed_omicron = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) end_date = as.Date.character ( \"23-02-2022\" , format = \"%d-%m-%Y\" ) all_dates = seq.Date ( from = date_seed_omicron , to = end_date , by = \"days\" ) # model times date_fit_omicron = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) ts = 1 : length ( all_dates ) As we are simulating data, we next need to define both the fixed and estimated parameters. We are assuming an R_0 of 5 and and that \\rho is 0.2. R0 = 5 # reproduction number immunity = 0.562 # seroprevalence n_pop = 15810388 # population n_recov = round ( immunity * n_pop ) # recovered population n_inf = 1 # seed rho = 0.2 # reporting probability gamma = 1 / 4.17 # recovery rate sigma = 1 / 3.03 # latent rate beta = ( R0 * gamma ) / ( 1 - rho ) # transmission rate Next, we simulate our transmission data by solving a set of ODEs using the function simulate_data_single_var . The model equations are defined in models/model1_deSolve . The function requires that we provide the % of immunity in the population, the initial number of infected individuals, the reporting probability, the transmission rate and the time steps at which to solve the model. We can additionally set the population and recovery and latent rates, if we don't want to use the predefined values. The function will return a data frame of solutions to the derivatives of all compartments at each time step. It will also print the plot of each compartment across time, so we can check everything is behaving as expected. sim_data = simulate_data_single_var ( immunity = immunity , # seroprevalence n_inf = n_inf , # seed rho = rho , # reporting probability beta = beta , # transmission rate ts = ts # time steps ) Calculating reported incidence and adding noise to the data Next we calculate the reported incidence (i.e., the rate that individuals enter the Q compartment, \\mu = \\rho \\sigma Q ). The function calc_sim_incidence_single_var calculates the reported incidence and discards the first month as unobserved transmission. It also uses the function rnbinom to add noise to our simulated data by drawing from a Negative Binomial distribution with a mean \\mu and a dispersion parameter \\kappa = 10 . A list is returned which includes a data frame containing the date and the reported incidence (with and without noise). It also a returns a plot of the reported incidence with and without noise. simulated_data = calc_sim_incidence_single_var ( ODE_data = sim_data , # ODE solutions all_dates = all_dates , # model dates date_fit = date_fit_omicron , # date to seed omicron rho = rho # reporting probability ) sim_inc = simulated_data [[ 1 ]] simulated_data [[ 2 ]] # plot of reported incidence with and without noise The reported incidence with noise is what we will fit the Stan models to. Model fitting If you aren't familiar with Stan I recommend taking a look at some of the extra materials suggested in the README.md . You should also watch this and this for an introduction into coding a Stan model and the Hamiltonian Monte Carlo algorithm - the algorithm which will sample our posterior distribution. If you are familiar with Stan then we can move to coding up the infectious disease model. The first thing to note is that there are two ways to solve our ODEs in Stan. Method 1: Euler's Method Euler's Method is the simplest numerical integration method. Consider an infectious disease model, where susceptible individuals are infected at rate \\beta \\frac{I}{N} but never recover. \\frac{dS}{dt} = - \\beta S \\frac{I}{N} \\frac{dI}{dt} = \\beta S \\frac{I}{N} To solve this, we calculates the change in compartments during time interval t and predict the next state at time t+1 : S_{t+1} = S_t - \\beta S_t \\frac{I_t}{N} I_{t+1} = I_t + \\beta S_t \\frac{I_t}{N} Assume we have a population N=100 and a transmission rate of \\beta = 1 . The initial conditions are: I_{t0} = 1 and S_{t0} = 99 . At t_1 , we can calculate our states as: S_{t1} = 99 - 1 * 99 * \\frac{1}{100} = 98.01 I_{t1} = 1 + 1 * 99 * \\frac{1}{100} = 1.99 At t_2 , we can calculate our states as: S_{t1} = 98.01 - 1 * 98.01 * \\frac{1.99}{100} = 96.06 I_{t1} = 1.99 + 1 * 99 * \\frac{1.99}{100} = 3.94 And so on... To solve our ODEs in Stan using this method, we can simply use a for loop to solve the equations at each time step and predict the state at the next time step. This method is simple, but its accuracy depends on the time step used. Smaller time steps will get closer to the exact solution. For instance, when fitting a model over the course of a year, day intervals may be sufficient. If fitting a model over days, then hours might be a more appropriate interval. A benefit of using simulated data, as we will see, is that we can check that our time step is sufficiently small to obtain an accurate approximation of the solution. Depending on the required level of accuracy, the time step needed to obtain an acceptable approximation may be so small as to be computationally expensive. In this instance, higher order methods are used such as the Runge-Kutta Method . To see how we code up the SEIQR model in Stan using Euler's Method, go ahead and open up model1_Euler_V1.stan , in the models folder or run m1_EU (the name of the compiled model). You will find a data block, a parameters block, a transformed parameters block a model block and a generated quantities block. For any Stan model you need at minimum, the data, parameters and model block. Note also that the order of the blocks matter. Data block The data block includes the number of data points we have, as well as the number of time steps to run the model over. These two values aren't the same as we don't expect to have observed the transmission of Omicron from the very first day of its emergence. To account for this, we seed our model ( I_{t0} ) a month before we observe data. The time point that we seed Omicron is also provided in the data block. The data block also contains the parameters and initial conditions we aren't estimating, and of course, our observed data. Parameters block This contains the parameters we want to estimate. Note the bounds we put on parameters, which must all be positive and for \\rho must be between 0 and 1. Transformed parameters block This is where we estimate the solution to the ODEs at each time step. We also calculate the reported incidence and extract the time points we are going to fit to. Model block This contains the model likelihood and priors that we defined in chapter 1. Generated quantities block This contains code to calculate any other quantities of interest, that are not needed for the model block. In this instance, we will calculate R_0 . Take some time to read over the model and check it makes sense. Method 2: Runge-Kutta Method This second method builds on Euler's method, but rather than calculating a single rate of change at each time step, we calculate 4 different slopes. These slopes are then used as a weighted average to approximate the actual rate of change of states. Because we calculate multiple slopes at each interval, we obtain a more accurate approximation. For a more detailed visualisation of this method, see here . To implement this method, we use one of Stan's two inbuilt ODE integrators, integrate_ode_rk45 , which is the faster (but potentially less robust) of the two. Note, Stan issues warning messages if an integrator fails to solve an ODE (although we have never had this issue), at which point the solver may need to be adjusted or swapped . We specify the ODE in Stan using a function within, unsurprisingly, the functions block. See the section of this tutorial on coding the ODE in Stan for more details. To see how we code up the SEIQR model in Stan using integrate_ode_rk45 open up model1_RK_V1.stan , in the models folder, or run m1_RK (the name of the compiled Stan model). As before, you will find a data block, a parameters block, a transformed parameters block, a model block, a generated quantities block, plus a functions block. The next step is to run the Stan model using the function run_stan_models . The very minimum we need to input into this function to fit the model is: The data (in list format) The compiled Stan model We can also provide other arguments if we want to, including: A vector of seed values used when randomly selecting initial values for the Markov chains^. The number of seeds must be equal to the number of Markov chains and must all take different values. Number of chains to run. Number of iterations per chain. Number of warmup iterations per chain. Running this function will fit our Stan model to the simulated data and return the fitted results. It also prints the model run time, which will be useful as model complexity increases. ^ A note on choosing initial values. The MCMC algorithm needs starting points for each chain. If no initial values are given, Stan will randomly generate values between -2 and 2. On the other hand, setting initial values that are likely under the posterior distribution for at least some of the parameters can help model convergence, especially as model complexity increases (including non-linear systems of ODEs). We want the initial values to be different, so we can see that the Markov chains are converging, however we also want them to within a plausible range. To do this, we create a function called draw_init_values which randomly draws a sample from a uniform distribution, whose bounds cover a reasonable range of expected parameter values. If we don't set the seed, it will be 1 and we will always obtain the same initial values. Instead, the function run_stan_models calls draw_init_values and uses seed values to create a list of values using different seeds, so we have different starting values for each chain. Fitting using the Euler method First, we are going to fit the model using the Euler method: stan_fit_EU = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ) ), model = m1_EU ) ## Time difference of 37.17431 secs Model diagnostics If there are divergent transitions, Stan will warn us. Check out what divergent transitions are and why they can never be ignored here . Good news however, we obtained no immediate warnings about our model. To be on the safe side, lets check with some model diagnostics. diagnose_stan_fit takes our fitted Stan results and parameters of interest and returns diagnostics plots and a table of summary statistics. EU_diag = diagnose_stan_fit ( stan_fit_EU , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 2.1201857 0.0074768725 0.15123149 1.8975327 2.0120366 2.0998440 2.1955781 ## rho 0.4039729 0.0019475674 0.04009354 0.3368118 0.3742744 0.4005873 0.4275271 ## R_0 5.2445714 0.0009289445 0.03540958 5.1714145 5.2215314 5.2445332 5.2679685 ## 97.5% n_eff Rhat ## beta 2.5055947 409.1142 1.0046159 ## rho 0.4980691 423.8028 1.0038597 ## R_0 5.3142524 1452.9881 0.9989401 The first output shows the bivariate marginal posterior distribution which will show divergent transitions in red, if there are any. Note also, the strong correlation between parameters. The next outputs show markov chain trace plots to check for model convergence and the univariate marginal posterior distribution by chain. Finally, the function also returns a summary of the parameters we are interested in. This includes the mean and median, as well Credible intervals (CrI). Other useful statistics are given including the effective sample size and Rhat . Plotting the model fit We want to plot the model output against the true data so we can see whether our model is fitting the data well. We use the function plot_model_fit which requires as input the stan fit, the simulated data and the name of the parameter we fit, in this instance lambda (our reported incidence). When we first extract the model posterior and convert it into a dataframe the object named stan_fit_df within in the function), the first column is the iterations, the second is the time step and the the third is the estimated value (reported incidence). The function allow us to calculate the mean and 95% CrI, which are the 2.5% and 97.5% percentiles. Remember, credible intervals state that given the observed data, there is a 95% probability the value falls between this range. We then plot these against our simulated data, over time. EU_plot = plot_model_fit ( stan_fit_EU , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU_plot The fit here is poor, as the model peaks too late. Next we will compare this to the the Runge-Kutta Method. Fitting using the Runge-Kutta Method Q6: Using the functions run_stan_models , diagnose_stan_fit and plot_model_fit , fit the compiled model m1_RK to the simulated data Q7: Which method is fastest? By how much? Q8: Which method recovers the true parameters with more accuracy? Improving the accuracy of the Euler method Q9: Reduce the time step at which model1_Euler_V1.stan solves the ODEs to improve the accuracy of the fit. What is the minimum reduction in step size needed to ensure the posterior distribution captures the true parameter value? Having compared the two methods fitting to single variant data, in chapter 3 we will look at fitting a more complicated multi-variant model using the Euler method.","title":"Chapter 2"},{"location":"chapter_2/#simulating-data","text":"In this project, we are going to use simulated data. This is useful to check we have no bugs in our code. Also, even though Stan has lots of helpful diagnostics, we can never be completely certain our sampling algorithm has converged on the true posterior distribution. The diagnostics only confirm when it definitely hasn't. Therefore, using simulated data lets us check that the model can recover known posterior estimates, which gives us more confidence when it comes to fitting to observed data.","title":"Simulating data"},{"location":"chapter_2/#defining-global-parameters","text":"First, lets set the start and end date over which to fit the model, converted into a date format in R. For more detail on working with dates in R, see here . As mentioned, we want to seed Omicron 1 month before we fit to data, so we can define that here too. date_seed_omicron = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) end_date = as.Date.character ( \"23-02-2022\" , format = \"%d-%m-%Y\" ) all_dates = seq.Date ( from = date_seed_omicron , to = end_date , by = \"days\" ) # model times date_fit_omicron = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) ts = 1 : length ( all_dates ) As we are simulating data, we next need to define both the fixed and estimated parameters. We are assuming an R_0 of 5 and and that \\rho is 0.2. R0 = 5 # reproduction number immunity = 0.562 # seroprevalence n_pop = 15810388 # population n_recov = round ( immunity * n_pop ) # recovered population n_inf = 1 # seed rho = 0.2 # reporting probability gamma = 1 / 4.17 # recovery rate sigma = 1 / 3.03 # latent rate beta = ( R0 * gamma ) / ( 1 - rho ) # transmission rate Next, we simulate our transmission data by solving a set of ODEs using the function simulate_data_single_var . The model equations are defined in models/model1_deSolve . The function requires that we provide the % of immunity in the population, the initial number of infected individuals, the reporting probability, the transmission rate and the time steps at which to solve the model. We can additionally set the population and recovery and latent rates, if we don't want to use the predefined values. The function will return a data frame of solutions to the derivatives of all compartments at each time step. It will also print the plot of each compartment across time, so we can check everything is behaving as expected. sim_data = simulate_data_single_var ( immunity = immunity , # seroprevalence n_inf = n_inf , # seed rho = rho , # reporting probability beta = beta , # transmission rate ts = ts # time steps )","title":"Defining global parameters"},{"location":"chapter_2/#calculating-reported-incidence-and-adding-noise-to-the-data","text":"Next we calculate the reported incidence (i.e., the rate that individuals enter the Q compartment, \\mu = \\rho \\sigma Q ). The function calc_sim_incidence_single_var calculates the reported incidence and discards the first month as unobserved transmission. It also uses the function rnbinom to add noise to our simulated data by drawing from a Negative Binomial distribution with a mean \\mu and a dispersion parameter \\kappa = 10 . A list is returned which includes a data frame containing the date and the reported incidence (with and without noise). It also a returns a plot of the reported incidence with and without noise. simulated_data = calc_sim_incidence_single_var ( ODE_data = sim_data , # ODE solutions all_dates = all_dates , # model dates date_fit = date_fit_omicron , # date to seed omicron rho = rho # reporting probability ) sim_inc = simulated_data [[ 1 ]] simulated_data [[ 2 ]] # plot of reported incidence with and without noise The reported incidence with noise is what we will fit the Stan models to.","title":"Calculating reported incidence and adding noise to the data"},{"location":"chapter_2/#model-fitting","text":"If you aren't familiar with Stan I recommend taking a look at some of the extra materials suggested in the README.md . You should also watch this and this for an introduction into coding a Stan model and the Hamiltonian Monte Carlo algorithm - the algorithm which will sample our posterior distribution. If you are familiar with Stan then we can move to coding up the infectious disease model. The first thing to note is that there are two ways to solve our ODEs in Stan.","title":"Model fitting"},{"location":"chapter_2/#method-1-eulers-method","text":"Euler's Method is the simplest numerical integration method. Consider an infectious disease model, where susceptible individuals are infected at rate \\beta \\frac{I}{N} but never recover. \\frac{dS}{dt} = - \\beta S \\frac{I}{N} \\frac{dI}{dt} = \\beta S \\frac{I}{N} To solve this, we calculates the change in compartments during time interval t and predict the next state at time t+1 : S_{t+1} = S_t - \\beta S_t \\frac{I_t}{N} I_{t+1} = I_t + \\beta S_t \\frac{I_t}{N} Assume we have a population N=100 and a transmission rate of \\beta = 1 . The initial conditions are: I_{t0} = 1 and S_{t0} = 99 . At t_1 , we can calculate our states as: S_{t1} = 99 - 1 * 99 * \\frac{1}{100} = 98.01 I_{t1} = 1 + 1 * 99 * \\frac{1}{100} = 1.99 At t_2 , we can calculate our states as: S_{t1} = 98.01 - 1 * 98.01 * \\frac{1.99}{100} = 96.06 I_{t1} = 1.99 + 1 * 99 * \\frac{1.99}{100} = 3.94 And so on... To solve our ODEs in Stan using this method, we can simply use a for loop to solve the equations at each time step and predict the state at the next time step. This method is simple, but its accuracy depends on the time step used. Smaller time steps will get closer to the exact solution. For instance, when fitting a model over the course of a year, day intervals may be sufficient. If fitting a model over days, then hours might be a more appropriate interval. A benefit of using simulated data, as we will see, is that we can check that our time step is sufficiently small to obtain an accurate approximation of the solution. Depending on the required level of accuracy, the time step needed to obtain an acceptable approximation may be so small as to be computationally expensive. In this instance, higher order methods are used such as the Runge-Kutta Method . To see how we code up the SEIQR model in Stan using Euler's Method, go ahead and open up model1_Euler_V1.stan , in the models folder or run m1_EU (the name of the compiled model). You will find a data block, a parameters block, a transformed parameters block a model block and a generated quantities block. For any Stan model you need at minimum, the data, parameters and model block. Note also that the order of the blocks matter.","title":"Method 1: Euler's Method"},{"location":"chapter_2/#data-block","text":"The data block includes the number of data points we have, as well as the number of time steps to run the model over. These two values aren't the same as we don't expect to have observed the transmission of Omicron from the very first day of its emergence. To account for this, we seed our model ( I_{t0} ) a month before we observe data. The time point that we seed Omicron is also provided in the data block. The data block also contains the parameters and initial conditions we aren't estimating, and of course, our observed data.","title":"Data block"},{"location":"chapter_2/#parameters-block","text":"This contains the parameters we want to estimate. Note the bounds we put on parameters, which must all be positive and for \\rho must be between 0 and 1.","title":"Parameters block"},{"location":"chapter_2/#transformed-parameters-block","text":"This is where we estimate the solution to the ODEs at each time step. We also calculate the reported incidence and extract the time points we are going to fit to.","title":"Transformed parameters block"},{"location":"chapter_2/#model-block","text":"This contains the model likelihood and priors that we defined in chapter 1.","title":"Model block"},{"location":"chapter_2/#generated-quantities-block","text":"This contains code to calculate any other quantities of interest, that are not needed for the model block. In this instance, we will calculate R_0 . Take some time to read over the model and check it makes sense.","title":"Generated quantities block"},{"location":"chapter_2/#method-2-runge-kutta-method","text":"This second method builds on Euler's method, but rather than calculating a single rate of change at each time step, we calculate 4 different slopes. These slopes are then used as a weighted average to approximate the actual rate of change of states. Because we calculate multiple slopes at each interval, we obtain a more accurate approximation. For a more detailed visualisation of this method, see here . To implement this method, we use one of Stan's two inbuilt ODE integrators, integrate_ode_rk45 , which is the faster (but potentially less robust) of the two. Note, Stan issues warning messages if an integrator fails to solve an ODE (although we have never had this issue), at which point the solver may need to be adjusted or swapped . We specify the ODE in Stan using a function within, unsurprisingly, the functions block. See the section of this tutorial on coding the ODE in Stan for more details. To see how we code up the SEIQR model in Stan using integrate_ode_rk45 open up model1_RK_V1.stan , in the models folder, or run m1_RK (the name of the compiled Stan model). As before, you will find a data block, a parameters block, a transformed parameters block, a model block, a generated quantities block, plus a functions block. The next step is to run the Stan model using the function run_stan_models . The very minimum we need to input into this function to fit the model is: The data (in list format) The compiled Stan model We can also provide other arguments if we want to, including: A vector of seed values used when randomly selecting initial values for the Markov chains^. The number of seeds must be equal to the number of Markov chains and must all take different values. Number of chains to run. Number of iterations per chain. Number of warmup iterations per chain. Running this function will fit our Stan model to the simulated data and return the fitted results. It also prints the model run time, which will be useful as model complexity increases. ^ A note on choosing initial values. The MCMC algorithm needs starting points for each chain. If no initial values are given, Stan will randomly generate values between -2 and 2. On the other hand, setting initial values that are likely under the posterior distribution for at least some of the parameters can help model convergence, especially as model complexity increases (including non-linear systems of ODEs). We want the initial values to be different, so we can see that the Markov chains are converging, however we also want them to within a plausible range. To do this, we create a function called draw_init_values which randomly draws a sample from a uniform distribution, whose bounds cover a reasonable range of expected parameter values. If we don't set the seed, it will be 1 and we will always obtain the same initial values. Instead, the function run_stan_models calls draw_init_values and uses seed values to create a list of values using different seeds, so we have different starting values for each chain.","title":" Method 2: Runge-Kutta Method"},{"location":"chapter_2/#fitting-using-the-euler-method","text":"First, we are going to fit the model using the Euler method: stan_fit_EU = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ) ), model = m1_EU ) ## Time difference of 37.17431 secs","title":"Fitting using the Euler method"},{"location":"chapter_2/#model-diagnostics","text":"If there are divergent transitions, Stan will warn us. Check out what divergent transitions are and why they can never be ignored here . Good news however, we obtained no immediate warnings about our model. To be on the safe side, lets check with some model diagnostics. diagnose_stan_fit takes our fitted Stan results and parameters of interest and returns diagnostics plots and a table of summary statistics. EU_diag = diagnose_stan_fit ( stan_fit_EU , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 2.1201857 0.0074768725 0.15123149 1.8975327 2.0120366 2.0998440 2.1955781 ## rho 0.4039729 0.0019475674 0.04009354 0.3368118 0.3742744 0.4005873 0.4275271 ## R_0 5.2445714 0.0009289445 0.03540958 5.1714145 5.2215314 5.2445332 5.2679685 ## 97.5% n_eff Rhat ## beta 2.5055947 409.1142 1.0046159 ## rho 0.4980691 423.8028 1.0038597 ## R_0 5.3142524 1452.9881 0.9989401 The first output shows the bivariate marginal posterior distribution which will show divergent transitions in red, if there are any. Note also, the strong correlation between parameters. The next outputs show markov chain trace plots to check for model convergence and the univariate marginal posterior distribution by chain. Finally, the function also returns a summary of the parameters we are interested in. This includes the mean and median, as well Credible intervals (CrI). Other useful statistics are given including the effective sample size and Rhat .","title":"Model diagnostics"},{"location":"chapter_2/#plotting-the-model-fit","text":"We want to plot the model output against the true data so we can see whether our model is fitting the data well. We use the function plot_model_fit which requires as input the stan fit, the simulated data and the name of the parameter we fit, in this instance lambda (our reported incidence). When we first extract the model posterior and convert it into a dataframe the object named stan_fit_df within in the function), the first column is the iterations, the second is the time step and the the third is the estimated value (reported incidence). The function allow us to calculate the mean and 95% CrI, which are the 2.5% and 97.5% percentiles. Remember, credible intervals state that given the observed data, there is a 95% probability the value falls between this range. We then plot these against our simulated data, over time. EU_plot = plot_model_fit ( stan_fit_EU , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU_plot The fit here is poor, as the model peaks too late. Next we will compare this to the the Runge-Kutta Method.","title":"Plotting the model fit"},{"location":"chapter_2/#fitting-using-the-runge-kutta-method","text":"Q6: Using the functions run_stan_models , diagnose_stan_fit and plot_model_fit , fit the compiled model m1_RK to the simulated data Q7: Which method is fastest? By how much? Q8: Which method recovers the true parameters with more accuracy?","title":"Fitting using the Runge-Kutta Method"},{"location":"chapter_2/#improving-the-accuracy-of-the-euler-method","text":"Q9: Reduce the time step at which model1_Euler_V1.stan solves the ODEs to improve the accuracy of the fit. What is the minimum reduction in step size needed to ensure the posterior distribution captures the true parameter value? Having compared the two methods fitting to single variant data, in chapter 3 we will look at fitting a more complicated multi-variant model using the Euler method.","title":"Improving the accuracy of the Euler method"},{"location":"chapter_2_solutions/","text":"In this chapter, we are going to fit the single variant model designed in chapter 1, using Stan. First, we need to load some packages. We also need to source the functions needed to run this script, found in the R folder. Finally, we need to compile the Stan models, found in the models folder. library ( dplyr ) library ( ggplot2 ) library ( rstan ) rstan_options ( auto_write = TRUE ) options ( mc.cores = parallel :: detectCores ()) # Functions source ( \"R/simulate_data.R\" ) source ( \"R/calc_sim_incidence.R\" ) source ( \"R/draw_init_values.R\" ) source ( \"R/run_stan_models.R\" ) source ( \"R/diagnose_stan_fit.R\" ) source ( \"R/plot_model_fit.R\" ) source ( \"R/compare_param_est.R\" ) source ( \"R/tidy_data.R\" ) # Models m1_EU = stan_model ( \"models/model1_Euler_V1.stan\" ) m1_RK = stan_model ( \"models/model1_RK_V1.stan\" ) m1_EU2 = stan_model ( \"models/model1_Euler_V2.stan\" ) Simulating data In this project, we are going to use simulated data. This is useful to check we have no bugs in our code. Also, even though Stan has lots of helpful diagnostics, we can never be completely certain our sampling algorithm has converged on the true posterior distribution. The diagnostics only confirm when it definitely hasn't. Therefore, using simulated data lets us check that the model can recover known posterior estimates, which gives us more confidence when it comes to fitting to observed data. Defining global parameters First, lets set the start and end date over which to fit the model, converted into a date format in R. For more detail on working with dates in R, see here . As mentioned, we want to seed Omicron 1 month before we fit to data, so we can define that here too. date_seed_omicron = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) end_date = as.Date.character ( \"23-02-2022\" , format = \"%d-%m-%Y\" ) all_dates = seq.Date ( from = date_seed_omicron , to = end_date , by = \"days\" ) # model times date_fit_omicron = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) ts = 1 : length ( all_dates ) As we are simulating data, we next need to define both the fixed and estimated parameters. We are assuming an R_0 of 5 and and that \\rho is 0.2. R0 = 5 # reproduction number immunity = 0.562 # seroprevalence n_pop = 15810388 # population n_recov = round ( immunity * n_pop ) # recovered population n_inf = 1 # seed rho = 0.2 # reporting probability gamma = 1 / 4.17 # recovery rate sigma = 1 / 3.03 # latent rate beta = ( R0 * gamma ) / ( 1 - rho ) # transmission rate Next, we simulate our transmission data by solving a set of ODEs using the function simulate_data_single_var . The model equations are defined in models/model1_deSolve . The function requires that we provide the % of immunity in the population, the initial number of infected individuals, the reporting probability, the transmission rate and the time steps at which to solve the model. We can additionally set the population and recovery and latent rates, if we don't want to use the predefined values. The function will return a data frame of solutions to the derivatives of all compartments at each time step. It will also print the plot of each compartment across time, so we can check everything is behaving as expected. sim_data = simulate_data_single_var ( immunity = immunity , # seroprevalence n_inf = n_inf , # seed rho = rho , # reporting probability beta = beta , # transmission rate ts = ts # time steps ) Calculating reported incidence and adding noise to the data Next we calculate the reported incidence (i.e., the rate that individuals enter the Q compartment, \\mu = \\rho \\sigma Q ). The function calc_sim_incidence_single_var calculates the reported incidence and discards the first month as unobserved transmission. It also uses the function rnbinom to add noise to our simulated data by drawing from a Negative Binomial distribution with a mean \\mu and a dispersion parameter \\kappa = 10 . A list is returned which includes a data frame containing the date and the reported incidence (with and without noise). It also a returns a plot of the reported incidence with and without noise. simulated_data = calc_sim_incidence_single_var ( ODE_data = sim_data , # ODE solutions all_dates = all_dates , # model dates date_fit = date_fit_omicron , # date to seed omicron rho = rho # reporting probability ) sim_inc = simulated_data [[ 1 ]] simulated_data [[ 2 ]] # plot of reported incidence with and without noise The reported incidence with noise is what we will fit the Stan models to. Model fitting If you aren't familiar with Stan I recommend taking a look at some of the extra materials suggested in the README.md . You should also watch this and this for an introduction into coding a Stan model and the Hamiltonian Monte Carlo algorithm - the algorithm which will sample our posterior distribution. If you are familiar with Stan then we can move to coding up the infectious disease model. The first thing to note is that there are two ways to solve our ODEs in Stan. Method 1: Euler's Method Euler's Method is the simplest numerical integration method. Consider an infectious disease model, where susceptible individuals are infected at rate \\beta \\frac{I}{N} but never recover. \\frac{dS}{dt} = - \\beta S \\frac{I}{N} \\frac{dI}{dt} = \\beta S \\frac{I}{N} To solve this, we calculates the change in compartments during time interval t and predict the next state at time t+1 : S_{t+1} = S_t - \\beta S_t \\frac{I_t}{N} I_{t+1} = I_t + \\beta S_t \\frac{I_t}{N} Assume we have a population N=100 and a transmission rate of \\beta = 1 . The initial conditions are: I_{t0} = 1 and S_{t0} = 99 . At t_1 , we can calculate our states as: S_{t1} = 99 - 1 * 99 * \\frac{1}{100} = 98.01 I_{t1} = 1 + 1 * 99 * \\frac{1}{100} = 1.99 At t_2 , we can calculate our states as: S_{t1} = 98.01 - 1 * 98.01 * \\frac{1.99}{100} = 96.06 I_{t1} = 1.99 + 1 * 99 * \\frac{1.99}{100} = 3.94 And so on... To solve our ODEs in Stan using this method, we can simply use a for loop to solve the equations at each time step and predict the state at the next time step. This method is simple, but its accuracy depends on the time step used. Smaller time steps will get closer to the exact solution. For instance, when fitting a model over the course of a year, day intervals may be sufficient. If fitting a model over days, then hours might be a more appropriate interval. A benefit of using simulated data, as we will see, is that we can check that our time step is sufficiently small to obtain an accurate approximation of the solution. Depending on the required level of accuracy, the time step needed to obtain an acceptable approximation may be so small as to be computationally expensive. In this instance, higher order methods are used such as the Runge-Kutta Method . To see how we code up the SEIQR model in Stan using Euler's Method, go ahead and open up model1_Euler_V1.stan , in the models folder or run m1_EU (the name of the compiled model). You will find a data block, a parameters block, a transformed parameters block a model block and a generated quantities block. For any Stan model you need at minimum, the data, parameters and model block. Note also that the order of the blocks matter. Data block The data block includes the number of data points we have, as well as the number of time steps to run the model over. These two values aren't the same as we don't expect to have observed the transmission of Omicron from the very first day of its emergence. To account for this, we seed our model ( I_{t0} ) a month before we observe data. The time point that we seed Omicron is also provided in the data block. The data block also contains the parameters and initial conditions we aren't estimating, and of course, our observed data. Parameters block This contains the parameters we want to estimate. Note the bounds we put on parameters, which must all be positive and for \\rho must be between 0 and 1. Transformed parameters block This is where we estimate the solution to the ODEs at each time step. We also calculate the reported incidence and extract the time points we are going to fit to. Model block This contains the model likelihood and priors that we defined in chapter 1. Generated quantities block This contains code to calculate any other quantities of interest, that are not needed for the model block. In this instance, we will calculate R_0 . Take some time to read over the model and check it makes sense. Method 2: Runge-Kutta Method This second method builds on Euler's method, but rather than calculating a single rate of change at each time step, we calculate 4 different slopes. These slopes are then used as a weighted average to approximate the actual rate of change of states. Because we calculate multiple slopes at each interval, we obtain a more accurate approximation. For a more detailed visualisation of this method, see here . To implement this method, we use one of Stan's two inbuilt ODE integrators, integrate_ode_rk45 , which is the faster (but potentially less robust) of the two. Note, Stan issues warning messages if an integrator fails to solve an ODE (although we have never had this issue), at which point the solver may need to be adjusted or swapped . We specify the ODE in Stan using a function within, unsurprisingly, the functions block. See the section of this tutorial on coding the ODE in Stan for more details. To see how we code up the SEIQR model in Stan using integrate_ode_rk45 open up model1_RK_V1.stan , in the models folder, or run m1_RK (the name of the compiled Stan model). As before, you will find a data block, a parameters block, a transformed parameters block, a model block, a generated quantities block, plus a functions block. The next step is to run the Stan model using the function run_stan_models . The very minimum we need to input into this function to fit the model is: The data (in list format) The compiled Stan model We can also provide other arguments if we want to, including: A vector of seed values used when randomly selecting initial values for the Markov chains^. The number of seeds must be equal to the number of Markov chains and must all take different values. Number of chains to run. Number of iterations per chain. Number of warmup iterations per chain. Running this function will fit our Stan model to the simulated data and return the fitted results. It also prints the model run time, which will be useful as model complexity increases. ^ A note on choosing initial values. The MCMC algorithm needs starting points for each chain. If no initial values are given, Stan will randomly generate values between -2 and 2. On the other hand, setting initial values that are likely under the posterior distribution for at least some of the parameters can help model convergence, especially as model complexity increases (including non-linear systems of ODEs). We want the initial values to be different, so we can see that the Markov chains are converging, however we also want them to within a plausible range. To do this, we create a function called draw_init_values which randomly draws a sample from a uniform distribution, whose bounds cover a reasonable range of expected parameter values. If we don't set the seed, it will be 1 and we will always obtain the same initial values. Instead, the function run_stan_models calls draw_init_values and uses seed values to create a list of values using different seeds, so we have different starting values for each chain. Fitting using the Euler method First, we are going to fit the model using the Euler method: stan_fit_EU = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ) ), model = m1_EU ) ## Time difference of 37.17431 secs Model diagnostics If there are divergent transitions, Stan will warn us. Check out what divergent transitions are and why they can never be ignored here . Good news however, we obtained no immediate warnings about our model. To be on the safe side, lets check with some model diagnostics. diagnose_stan_fit takes our fitted Stan results and parameters of interest and returns diagnostics plots and a table of summary statistics. EU_diag = diagnose_stan_fit ( stan_fit_EU , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 2.1201857 0.0074768725 0.15123149 1.8975327 2.0120366 2.0998440 2.1955781 ## rho 0.4039729 0.0019475674 0.04009354 0.3368118 0.3742744 0.4005873 0.4275271 ## R_0 5.2445714 0.0009289445 0.03540958 5.1714145 5.2215314 5.2445332 5.2679685 ## 97.5% n_eff Rhat ## beta 2.5055947 409.1142 1.0046159 ## rho 0.4980691 423.8028 1.0038597 ## R_0 5.3142524 1452.9881 0.9989401 The first output shows the bivariate marginal posterior distribution which will show divergent transitions in red, if there are any. Note also, the strong correlation between parameters. The next outputs show markov chain trace plots to check for model convergence and the univariate marginal posterior distribution by chain. Finally, the function also returns a summary of the parameters we are interested in. This includes the mean and median, as well Credible intervals (CrI). Other useful statistics are given including the effective sample size and Rhat . Plotting the model fit We want to plot the model output against the true data so we can see whether our model is fitting the data well. We use the function plot_model_fit which requires as input the stan fit, the simulated data and the name of the parameter we fit, in this instance lambda (our reported incidence). When we first extract the model posterior and convert it into a dataframe the object named stan_fit_df within in the function), the first column is the iterations, the second is the time step and the the third is the estimated value (reported incidence). The function allow us to calculate the mean and 95% CrI, which are the 2.5% and 97.5% percentiles. Remember, credible intervals state that given the observed data, there is a 95% probability the value falls between this range. We then plot these against our simulated data, over time. EU_plot = plot_model_fit ( stan_fit_EU , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU_plot The fit here is poor, as the model peaks too late. Next we will compare this to the the Runge-Kutta Method. Fitting using the Runge-Kutta Method Q6: Using the functions run_stan_models , diagnose_stan_fit and plot_model_fit , fit the compiled model m1_RK to the simulated data A6: Looking at m1_RK , you can see we need to add some additional data to the list provided to Stan, namely a vector of time steps at which to solve the model. stan_fit_RK = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ), ts = ts # time steps ), model = m1_RK ) ## Time difference of 2.245508 mins Diagnostics still look good. RK_diag = diagnose_stan_fit ( stan_fit_RK , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) RK_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 1.4576613 0.0010627769 0.02235308 1.4174613 1.4425718 1.4550144 1.4719345 ## rho 0.1942493 0.0005025086 0.01051176 0.1754508 0.1872102 0.1932687 0.2013505 ## R_0 4.8967717 0.0006947997 0.02190915 4.8562482 4.8815042 4.8960670 4.9114831 ## 97.5% n_eff Rhat ## beta 1.5076162 442.3749 1.004954 ## rho 0.2166354 437.5868 1.003838 ## R_0 4.9407966 994.3332 1.003822 The fit is better than the Euler method, although we are not quite capturing the peak of the epidemic curve. RK_plot = plot_model_fit ( stan_fit_RK , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) RK_plot Q7: Which method is fastest? By how much? A7: the Euler method is ~5 x faster Q8: Which method recovers the true parameters with more accuracy? A8: Lets plot our original values, alongside the mean and 95% CrI of the posterior distributions of our estimated parameters, using the function compare_param_est compare_param_est ( parameter_names = c ( \"beta\" , \"rho\" , \"R_0\" ), # parameters to compare true_param_values = c ( beta , rho , R0 ), # true values param_values1 = EU_diag [[ 3 ]][, c ( 1 , 4 , 8 )], # estimated values from model 1 param_values2 = RK_diag [[ 3 ]][, c ( 1 , 4 , 8 )] # estimated values from model 2 ) ## [[1]] ## ## [[2]] ## ## [[3]] It looks like the RK method is better able to recover the parameter values, which makes sense as it fits the date better. The RK method does underestimate the true R_0 , which explains why the model was not quite able to capture the peak of the epidemic curve. It is also important to remember that the data are generated using fixed parameter values, whereas in Bayesian modelling we consider parameters to be distributions. This highlights the limitations of using a single simulated data set, how do we decide if the posterior distribution is close enough to the \"correct\" value? Nevertheless, we can see that the parameter values and model fit estimated by the Euler method are subject to less accurate and subject to more uncertainty. One option we can explore is reducing the time step at which we solve the ODE equations using the Euler method. Improving the accuracy of the Euler method Q9: Reduce the time step at which model1_Euler_V1.stan solves the ODEs to improve the accuracy of the fit. What is the minimum reduction in step size needed to ensure the posterior distribution captures the true parameter value? A9: m1_EU2 shows how to modify the original model to allow us to estimate the ODE solutions at a scaled time step, which is smaller than 1 day. We now just need to provide an additional data variable, the amount to scale by. Within the model, we also need to divide all the rate parameters by our scaling factor, as \\sigma and \\gamma are in days. We do this in the transformed data block. Once we have solved the model at our desired resolution, we need to aggregate the reported incidence back into days so that we can fit to the data. This is done in the model block using a for loop which adds to the index as it runs # run the model stan_fit_EU2 = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ), scale_time_step = 7 # amount to reduce time step ), model = m1_EU2 ) ## Time difference of 1.521639 mins Reducing the time step by 6 or 7 should be sufficient, and is still faster than the RK method. Let's check the diagnostics now and see if we are able to improve the accuracy. EU2_diag = diagnose_stan_fit ( stan_fit_EU2 , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 1.5300896 0.0011393195 0.02480530 1.4849911 1.5129051 1.5282113 1.5461856 ## rho 0.2132518 0.0005091546 0.01116703 0.1934163 0.2052791 0.2126142 0.2208024 ## R_0 5.0187005 0.0005883898 0.01965081 4.9800628 5.0049975 5.0190336 5.0319124 ## 97.5% n_eff Rhat ## beta 1.5816731 474.0215 0.9991952 ## rho 0.2364666 481.0344 0.9994794 ## R_0 5.0586932 1115.4001 0.9995148 EU2_plot = plot_model_fit ( stan_fit_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU2_plot Finally, lets compare parameter estimates again compare_param_est ( parameter_names = c ( \"beta\" , \"rho\" , \"R0\" ), true_param_values = c ( beta , rho , R0 ), param_values1 = EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], param_values2 = RK_diag [[ 3 ]][, c ( 1 , 4 , 8 )] ) ## [[1]] ## ## [[2]] ## ## [[3]] This final fit is able to recover our true parameters, although the model doesn't quite capture the peak. However, as the data incorporates additional noise, we would not expect the model to perfectly fit every point, otherwise we would be concerned about over-fitting the model. Having compared the two methods fitting to single variant data, in chapter 3 we will look at fitting a more complicated multi-variant model using the Euler method.","title":"Chapter 2: fitting a single strain model in Stan"},{"location":"chapter_2_solutions/#simulating-data","text":"In this project, we are going to use simulated data. This is useful to check we have no bugs in our code. Also, even though Stan has lots of helpful diagnostics, we can never be completely certain our sampling algorithm has converged on the true posterior distribution. The diagnostics only confirm when it definitely hasn't. Therefore, using simulated data lets us check that the model can recover known posterior estimates, which gives us more confidence when it comes to fitting to observed data.","title":"Simulating data"},{"location":"chapter_2_solutions/#defining-global-parameters","text":"First, lets set the start and end date over which to fit the model, converted into a date format in R. For more detail on working with dates in R, see here . As mentioned, we want to seed Omicron 1 month before we fit to data, so we can define that here too. date_seed_omicron = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) end_date = as.Date.character ( \"23-02-2022\" , format = \"%d-%m-%Y\" ) all_dates = seq.Date ( from = date_seed_omicron , to = end_date , by = \"days\" ) # model times date_fit_omicron = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) ts = 1 : length ( all_dates ) As we are simulating data, we next need to define both the fixed and estimated parameters. We are assuming an R_0 of 5 and and that \\rho is 0.2. R0 = 5 # reproduction number immunity = 0.562 # seroprevalence n_pop = 15810388 # population n_recov = round ( immunity * n_pop ) # recovered population n_inf = 1 # seed rho = 0.2 # reporting probability gamma = 1 / 4.17 # recovery rate sigma = 1 / 3.03 # latent rate beta = ( R0 * gamma ) / ( 1 - rho ) # transmission rate Next, we simulate our transmission data by solving a set of ODEs using the function simulate_data_single_var . The model equations are defined in models/model1_deSolve . The function requires that we provide the % of immunity in the population, the initial number of infected individuals, the reporting probability, the transmission rate and the time steps at which to solve the model. We can additionally set the population and recovery and latent rates, if we don't want to use the predefined values. The function will return a data frame of solutions to the derivatives of all compartments at each time step. It will also print the plot of each compartment across time, so we can check everything is behaving as expected. sim_data = simulate_data_single_var ( immunity = immunity , # seroprevalence n_inf = n_inf , # seed rho = rho , # reporting probability beta = beta , # transmission rate ts = ts # time steps )","title":"Defining global parameters"},{"location":"chapter_2_solutions/#calculating-reported-incidence-and-adding-noise-to-the-data","text":"Next we calculate the reported incidence (i.e., the rate that individuals enter the Q compartment, \\mu = \\rho \\sigma Q ). The function calc_sim_incidence_single_var calculates the reported incidence and discards the first month as unobserved transmission. It also uses the function rnbinom to add noise to our simulated data by drawing from a Negative Binomial distribution with a mean \\mu and a dispersion parameter \\kappa = 10 . A list is returned which includes a data frame containing the date and the reported incidence (with and without noise). It also a returns a plot of the reported incidence with and without noise. simulated_data = calc_sim_incidence_single_var ( ODE_data = sim_data , # ODE solutions all_dates = all_dates , # model dates date_fit = date_fit_omicron , # date to seed omicron rho = rho # reporting probability ) sim_inc = simulated_data [[ 1 ]] simulated_data [[ 2 ]] # plot of reported incidence with and without noise The reported incidence with noise is what we will fit the Stan models to.","title":"Calculating reported incidence and adding noise to the data"},{"location":"chapter_2_solutions/#model-fitting","text":"If you aren't familiar with Stan I recommend taking a look at some of the extra materials suggested in the README.md . You should also watch this and this for an introduction into coding a Stan model and the Hamiltonian Monte Carlo algorithm - the algorithm which will sample our posterior distribution. If you are familiar with Stan then we can move to coding up the infectious disease model. The first thing to note is that there are two ways to solve our ODEs in Stan.","title":"Model fitting"},{"location":"chapter_2_solutions/#method-1-eulers-method","text":"Euler's Method is the simplest numerical integration method. Consider an infectious disease model, where susceptible individuals are infected at rate \\beta \\frac{I}{N} but never recover. \\frac{dS}{dt} = - \\beta S \\frac{I}{N} \\frac{dI}{dt} = \\beta S \\frac{I}{N} To solve this, we calculates the change in compartments during time interval t and predict the next state at time t+1 : S_{t+1} = S_t - \\beta S_t \\frac{I_t}{N} I_{t+1} = I_t + \\beta S_t \\frac{I_t}{N} Assume we have a population N=100 and a transmission rate of \\beta = 1 . The initial conditions are: I_{t0} = 1 and S_{t0} = 99 . At t_1 , we can calculate our states as: S_{t1} = 99 - 1 * 99 * \\frac{1}{100} = 98.01 I_{t1} = 1 + 1 * 99 * \\frac{1}{100} = 1.99 At t_2 , we can calculate our states as: S_{t1} = 98.01 - 1 * 98.01 * \\frac{1.99}{100} = 96.06 I_{t1} = 1.99 + 1 * 99 * \\frac{1.99}{100} = 3.94 And so on... To solve our ODEs in Stan using this method, we can simply use a for loop to solve the equations at each time step and predict the state at the next time step. This method is simple, but its accuracy depends on the time step used. Smaller time steps will get closer to the exact solution. For instance, when fitting a model over the course of a year, day intervals may be sufficient. If fitting a model over days, then hours might be a more appropriate interval. A benefit of using simulated data, as we will see, is that we can check that our time step is sufficiently small to obtain an accurate approximation of the solution. Depending on the required level of accuracy, the time step needed to obtain an acceptable approximation may be so small as to be computationally expensive. In this instance, higher order methods are used such as the Runge-Kutta Method . To see how we code up the SEIQR model in Stan using Euler's Method, go ahead and open up model1_Euler_V1.stan , in the models folder or run m1_EU (the name of the compiled model). You will find a data block, a parameters block, a transformed parameters block a model block and a generated quantities block. For any Stan model you need at minimum, the data, parameters and model block. Note also that the order of the blocks matter.","title":"Method 1: Euler's Method"},{"location":"chapter_2_solutions/#data-block","text":"The data block includes the number of data points we have, as well as the number of time steps to run the model over. These two values aren't the same as we don't expect to have observed the transmission of Omicron from the very first day of its emergence. To account for this, we seed our model ( I_{t0} ) a month before we observe data. The time point that we seed Omicron is also provided in the data block. The data block also contains the parameters and initial conditions we aren't estimating, and of course, our observed data.","title":"Data block"},{"location":"chapter_2_solutions/#parameters-block","text":"This contains the parameters we want to estimate. Note the bounds we put on parameters, which must all be positive and for \\rho must be between 0 and 1.","title":"Parameters block"},{"location":"chapter_2_solutions/#transformed-parameters-block","text":"This is where we estimate the solution to the ODEs at each time step. We also calculate the reported incidence and extract the time points we are going to fit to.","title":"Transformed parameters block"},{"location":"chapter_2_solutions/#model-block","text":"This contains the model likelihood and priors that we defined in chapter 1.","title":"Model block"},{"location":"chapter_2_solutions/#generated-quantities-block","text":"This contains code to calculate any other quantities of interest, that are not needed for the model block. In this instance, we will calculate R_0 . Take some time to read over the model and check it makes sense.","title":"Generated quantities block"},{"location":"chapter_2_solutions/#method-2-runge-kutta-method","text":"This second method builds on Euler's method, but rather than calculating a single rate of change at each time step, we calculate 4 different slopes. These slopes are then used as a weighted average to approximate the actual rate of change of states. Because we calculate multiple slopes at each interval, we obtain a more accurate approximation. For a more detailed visualisation of this method, see here . To implement this method, we use one of Stan's two inbuilt ODE integrators, integrate_ode_rk45 , which is the faster (but potentially less robust) of the two. Note, Stan issues warning messages if an integrator fails to solve an ODE (although we have never had this issue), at which point the solver may need to be adjusted or swapped . We specify the ODE in Stan using a function within, unsurprisingly, the functions block. See the section of this tutorial on coding the ODE in Stan for more details. To see how we code up the SEIQR model in Stan using integrate_ode_rk45 open up model1_RK_V1.stan , in the models folder, or run m1_RK (the name of the compiled Stan model). As before, you will find a data block, a parameters block, a transformed parameters block, a model block, a generated quantities block, plus a functions block. The next step is to run the Stan model using the function run_stan_models . The very minimum we need to input into this function to fit the model is: The data (in list format) The compiled Stan model We can also provide other arguments if we want to, including: A vector of seed values used when randomly selecting initial values for the Markov chains^. The number of seeds must be equal to the number of Markov chains and must all take different values. Number of chains to run. Number of iterations per chain. Number of warmup iterations per chain. Running this function will fit our Stan model to the simulated data and return the fitted results. It also prints the model run time, which will be useful as model complexity increases. ^ A note on choosing initial values. The MCMC algorithm needs starting points for each chain. If no initial values are given, Stan will randomly generate values between -2 and 2. On the other hand, setting initial values that are likely under the posterior distribution for at least some of the parameters can help model convergence, especially as model complexity increases (including non-linear systems of ODEs). We want the initial values to be different, so we can see that the Markov chains are converging, however we also want them to within a plausible range. To do this, we create a function called draw_init_values which randomly draws a sample from a uniform distribution, whose bounds cover a reasonable range of expected parameter values. If we don't set the seed, it will be 1 and we will always obtain the same initial values. Instead, the function run_stan_models calls draw_init_values and uses seed values to create a list of values using different seeds, so we have different starting values for each chain.","title":" Method 2: Runge-Kutta Method"},{"location":"chapter_2_solutions/#fitting-using-the-euler-method","text":"First, we are going to fit the model using the Euler method: stan_fit_EU = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ) ), model = m1_EU ) ## Time difference of 37.17431 secs","title":"Fitting using the Euler method"},{"location":"chapter_2_solutions/#model-diagnostics","text":"If there are divergent transitions, Stan will warn us. Check out what divergent transitions are and why they can never be ignored here . Good news however, we obtained no immediate warnings about our model. To be on the safe side, lets check with some model diagnostics. diagnose_stan_fit takes our fitted Stan results and parameters of interest and returns diagnostics plots and a table of summary statistics. EU_diag = diagnose_stan_fit ( stan_fit_EU , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 2.1201857 0.0074768725 0.15123149 1.8975327 2.0120366 2.0998440 2.1955781 ## rho 0.4039729 0.0019475674 0.04009354 0.3368118 0.3742744 0.4005873 0.4275271 ## R_0 5.2445714 0.0009289445 0.03540958 5.1714145 5.2215314 5.2445332 5.2679685 ## 97.5% n_eff Rhat ## beta 2.5055947 409.1142 1.0046159 ## rho 0.4980691 423.8028 1.0038597 ## R_0 5.3142524 1452.9881 0.9989401 The first output shows the bivariate marginal posterior distribution which will show divergent transitions in red, if there are any. Note also, the strong correlation between parameters. The next outputs show markov chain trace plots to check for model convergence and the univariate marginal posterior distribution by chain. Finally, the function also returns a summary of the parameters we are interested in. This includes the mean and median, as well Credible intervals (CrI). Other useful statistics are given including the effective sample size and Rhat .","title":"Model diagnostics"},{"location":"chapter_2_solutions/#plotting-the-model-fit","text":"We want to plot the model output against the true data so we can see whether our model is fitting the data well. We use the function plot_model_fit which requires as input the stan fit, the simulated data and the name of the parameter we fit, in this instance lambda (our reported incidence). When we first extract the model posterior and convert it into a dataframe the object named stan_fit_df within in the function), the first column is the iterations, the second is the time step and the the third is the estimated value (reported incidence). The function allow us to calculate the mean and 95% CrI, which are the 2.5% and 97.5% percentiles. Remember, credible intervals state that given the observed data, there is a 95% probability the value falls between this range. We then plot these against our simulated data, over time. EU_plot = plot_model_fit ( stan_fit_EU , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU_plot The fit here is poor, as the model peaks too late. Next we will compare this to the the Runge-Kutta Method.","title":"Plotting the model fit"},{"location":"chapter_2_solutions/#fitting-using-the-runge-kutta-method","text":"Q6: Using the functions run_stan_models , diagnose_stan_fit and plot_model_fit , fit the compiled model m1_RK to the simulated data A6: Looking at m1_RK , you can see we need to add some additional data to the list provided to Stan, namely a vector of time steps at which to solve the model. stan_fit_RK = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ), ts = ts # time steps ), model = m1_RK ) ## Time difference of 2.245508 mins Diagnostics still look good. RK_diag = diagnose_stan_fit ( stan_fit_RK , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) RK_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 1.4576613 0.0010627769 0.02235308 1.4174613 1.4425718 1.4550144 1.4719345 ## rho 0.1942493 0.0005025086 0.01051176 0.1754508 0.1872102 0.1932687 0.2013505 ## R_0 4.8967717 0.0006947997 0.02190915 4.8562482 4.8815042 4.8960670 4.9114831 ## 97.5% n_eff Rhat ## beta 1.5076162 442.3749 1.004954 ## rho 0.2166354 437.5868 1.003838 ## R_0 4.9407966 994.3332 1.003822 The fit is better than the Euler method, although we are not quite capturing the peak of the epidemic curve. RK_plot = plot_model_fit ( stan_fit_RK , variable_model = \"lambda\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) RK_plot Q7: Which method is fastest? By how much? A7: the Euler method is ~5 x faster Q8: Which method recovers the true parameters with more accuracy? A8: Lets plot our original values, alongside the mean and 95% CrI of the posterior distributions of our estimated parameters, using the function compare_param_est compare_param_est ( parameter_names = c ( \"beta\" , \"rho\" , \"R_0\" ), # parameters to compare true_param_values = c ( beta , rho , R0 ), # true values param_values1 = EU_diag [[ 3 ]][, c ( 1 , 4 , 8 )], # estimated values from model 1 param_values2 = RK_diag [[ 3 ]][, c ( 1 , 4 , 8 )] # estimated values from model 2 ) ## [[1]] ## ## [[2]] ## ## [[3]] It looks like the RK method is better able to recover the parameter values, which makes sense as it fits the date better. The RK method does underestimate the true R_0 , which explains why the model was not quite able to capture the peak of the epidemic curve. It is also important to remember that the data are generated using fixed parameter values, whereas in Bayesian modelling we consider parameters to be distributions. This highlights the limitations of using a single simulated data set, how do we decide if the posterior distribution is close enough to the \"correct\" value? Nevertheless, we can see that the parameter values and model fit estimated by the Euler method are subject to less accurate and subject to more uncertainty. One option we can explore is reducing the time step at which we solve the ODE equations using the Euler method.","title":"Fitting using the Runge-Kutta Method"},{"location":"chapter_2_solutions/#improving-the-accuracy-of-the-euler-method","text":"Q9: Reduce the time step at which model1_Euler_V1.stan solves the ODEs to improve the accuracy of the fit. What is the minimum reduction in step size needed to ensure the posterior distribution captures the true parameter value? A9: m1_EU2 shows how to modify the original model to allow us to estimate the ODE solutions at a scaled time step, which is smaller than 1 day. We now just need to provide an additional data variable, the amount to scale by. Within the model, we also need to divide all the rate parameters by our scaling factor, as \\sigma and \\gamma are in days. We do this in the transformed data block. Once we have solved the model at our desired resolution, we need to aggregate the reported incidence back into days so that we can fit to the data. This is done in the model block using a for loop which adds to the index as it runs # run the model stan_fit_EU2 = run_stan_models ( list_data = list ( n_ts = length ( all_dates ), # no. time steps n_pop = n_pop , # population n_recov = n_recov , # recovered population I0 = n_inf , # infection seed y = sim_inc $ rep_inc_noise , # incidence data n_data = dim ( sim_inc )[ 1 ], # no. data sigma = sigma , # latent rate gamma = gamma , # recovery rate time_seed_omicron = # index seed omicron which ( all_dates == date_fit_omicron ), scale_time_step = 7 # amount to reduce time step ), model = m1_EU2 ) ## Time difference of 1.521639 mins Reducing the time step by 6 or 7 should be sufficient, and is still faster than the RK method. Let's check the diagnostics now and see if we are able to improve the accuracy. EU2_diag = diagnose_stan_fit ( stan_fit_EU2 , pars = c ( \"beta\" , \"rho\" , \"R_0\" )) EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% 50% 75% ## beta 1.5300896 0.0011393195 0.02480530 1.4849911 1.5129051 1.5282113 1.5461856 ## rho 0.2132518 0.0005091546 0.01116703 0.1934163 0.2052791 0.2126142 0.2208024 ## R_0 5.0187005 0.0005883898 0.01965081 4.9800628 5.0049975 5.0190336 5.0319124 ## 97.5% n_eff Rhat ## beta 1.5816731 474.0215 0.9991952 ## rho 0.2364666 481.0344 0.9994794 ## R_0 5.0586932 1115.4001 0.9995148 EU2_plot = plot_model_fit ( stan_fit_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_noise\" , data = sim_inc , all_dates = all_dates ) EU2_plot Finally, lets compare parameter estimates again compare_param_est ( parameter_names = c ( \"beta\" , \"rho\" , \"R0\" ), true_param_values = c ( beta , rho , R0 ), param_values1 = EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], param_values2 = RK_diag [[ 3 ]][, c ( 1 , 4 , 8 )] ) ## [[1]] ## ## [[2]] ## ## [[3]] This final fit is able to recover our true parameters, although the model doesn't quite capture the peak. However, as the data incorporates additional noise, we would not expect the model to perfectly fit every point, otherwise we would be concerned about over-fitting the model. Having compared the two methods fitting to single variant data, in chapter 3 we will look at fitting a more complicated multi-variant model using the Euler method.","title":"Improving the accuracy of the Euler method"},{"location":"chapter_3/","text":"library ( dplyr ) library ( ggplot2 ) library ( rstan ) library ( tidyr ) rstan_options ( auto_write = TRUE ) options ( mc.cores = parallel :: detectCores ()) # Functions source ( \"R/simulate_data.R\" ) source ( \"R/calc_sim_incidence.R\" ) source ( \"R/draw_init_values.R\" ) source ( \"R/run_stan_models.R\" ) source ( \"R/diagnose_stan_fit.R\" ) source ( \"R/plot_model_fit.R\" ) source ( \"R/compare_param_est.R\" ) # Models m2_EU1 = stan_model ( \"models/model2_Euler_V1.stan\" ) m2_EU2 = stan_model ( \"models/model2_Euler_V2.stan\" ) A multivariant model In this chapter, we are going to fit a multivariate model to capture the dynamics of both the Delta and Omicron VOC's in Gauteng. This means fitting to the incidence data observed during the third wave, driven by Delta, and the fourth wave, driven by Omicron. We will assume that between July 2021 - October 2021 the incidence data is Delta, whilst between October 2021 and December 2021 the incidence data is Omicron ^. As before, we will seed both variants 1 month before fitting to the data. That means we seed Delta in May and we seed Omicron in September. ^Note that these dates are not quite in line with the observed waves in Gauteng. In order to reduce memory usage and the time taken to fit the models in Stan we have assumed shorter waves and a reduce time period over which to model. The flow diagram of the multivariate model is shown in the following figure: Let subscript Y refer to the virus variant ( D = Delta, O = Omicron). Susceptible individuals ( S compartment) are infected at rate \\lambda_Y = \\beta_Y \\frac{I_{t0}} {S_{t0}} . Following infection individuals are latent with the virus ( E compartments) for an average of c \\frac{1}{\\sigma} days. After incubating the virus, a proportion \\rho_Y of individuals are detected, reported and enter isolation ( Q compartments). The remaining proportion become infectious ( I compartments) and contribute to the transmission of SARS-CoV-2. The infectious period lasts on average \\frac{1}{\\gamma} days, and then individuals recover and test negative ( R compartment). Susceptible individuals are also vaccinated and enter the R compartment directly at rate \\nu . Once recovered, immunity to the Omicron variant wanes at a rate of \\epsilon ( S_O compartment) and individuals are infected at a rate of \\lambda_O . Initial conditions As before, we will assume a single infectious individual seeds both the Delta and Omicron variants. We need redefine the number of recovered individuals, as we are now looking prior to the third wave. A sero-suvery in Gauteng reported a seroprevalence of 19% in at the end of January 2021 [1], so we will assume that R_{t0} = N * 0.19 and S_{t0} = N -R_{t0} . We will assume that the E , Q and S_O compartments are all 0 at t_0 . Model parameters As before, we will fix \\sigma and \\gamma using estimates from the literature, but we will assume they are variant-specific. For Omicron these we assume an average latent period \\frac{1}{\\sigma_D} of 3.03 days [2] and an average infectious period \\frac{1}{\\gamma_D} of 4.17 days [3]. FOr Delta, we will assume an average latent period \\frac{1}{\\sigma_O} 4.3 days [4] and an infectious period an average infectious period \\frac{1}{\\gamma_O} of 2.9 days [3]. We are also going to fix the rate of vaccination, assuming a constant per capita rate of vaccination of \\nu = 0.001 . We are going to estimate the variant-specific transmission rates \\beta_Y , the variant-specific reporting probability, \\rho_Y and the rate of immune waning \\epsilon . Q1: Why might we want to assume a variant specific reporting probability? During the third wave, driven by Delta, interventions were introduced across South Africa between 15-06-21 and 13-09-2021. We will use our model to also estimate the impact of these interventions on transmission. Let \\omega be the percentage reduction in transmission due to interventions. We model this impact on transmission as follows: \\beta' = \\beta * (1-\\omega) Finally, we are also going to estimate the over-dispersion parameter \\kappa , introduced in the previous chapters. Likelihood and priors As before we are going to assume a beta prior for the reporting probabilities: \\rho_Y \\sim Beta(2,8) , a normal distribution prior for the transmission rates: \\beta_Y \\sim ND(2.2,1) and an exponential distribution for the overdispersion parameter prior: \\kappa \\sim exp(0.01) . As a starting point, lets say that we fairly certain a SARS-CoV-2 infection or vaccination provides immunity for a year, and assume the following prior: \\epsilon \\sim ND(0.003,0.001) . Q2: Given what we know about the impact of interventions on transmission, what prior should we assume for \\omega ? Finally, we need to define our likelihood functions. As before, we assume that SARS-CoV-2 reported incidence is overdispersed and assume a Negative Binomial distribution: y_Y \\sim NegBin(\\mu_Y, \\kappa) Note, this time we have two likelihood functions, one for each variant. As before, we reconstruct the reported incidence from the model \\mu_Y as the rate of entry into the Q compartment: \\mu_Y = \\rho_Y \\sigma_Y E_Y . Including multiple likelihoods in Stan is easy, we just define them on separate lines and Stan will sum them automatically to calculate the overall model likelihood. Assumptions No pre-symptomatic transmission. All reported incidence is dichotomously assumed to be either the Delta or Omicron variants, with no over variants in circulation. All tested individuals isolate with 100% compliance. Simulating multivariant data Defining key dates: # Date we start fitting the incidence to Delta date_fit_D = as.Date.character ( \"01-06-2021\" , format = \"%d-%m-%Y\" ) # Date we start fitting the incidence data to Omicron date_fit_O = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) # Date we seed Delta (1 month before we fit) date_seed_D = as.Date.character ( \"01-05-2021\" , format = \"%d-%m-%Y\" ) # Date we seed D (1 month before we fit) date_seed_O = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) # Date interventions date_int = as.Date.character ( c ( \"15-06-2021\" , \"13-09-2021\" ), format = \"%d-%m-%Y\" ) # Final data of modelling period end_date = as.Date.character ( \"01-01-2022\" , format = \"%d-%m-%Y\" ) # All dates of modelling period all_dates_mv = seq.Date ( from = date_seed_D , to = end_date , by = \"days\" ) # model times As we are simulating data again, we need to define both the estimated and fixed parameters: # Define variables n_pop = 15810388 # Population immunity_mv = 0.19 # Percentage of the population with immunity n_inf_D = 1 # Initial Delta seed n_inf_O = 1 # Initial Omicron seed # Defining fixed parameters gamma_O = 1 / 4.17 # Omicron recovery rate gamma_D = 1 / 2.9 # Delta recovery rate sigma_O = 1 / 3.03 # Omicron latent rate sigma_D = 1 / 4.3 # Delta latent rate nu = 0.002 # Vaccination rate # Defining \"unknown\" parameters R0_D = 5 # Delta reproduction number R0_O = 8 # Omicron reproduction number rho_D = 0.2 # Probability of reporting a Delta case rho_O = 0.1 # Probability of reporting an Omicron case epsilon = 1 / 180 # Rate of immune waning omega = 0.65 # Percentage reduction in transmission due to interventions beta_D = ( R0_D * gamma_D ) / ( 1 - rho_D ) # Delta transmission rate beta_O = ( R0_O * gamma_O ) / ( 1 - rho_O ) # Omicron transmission rate Like the function simulate_data_single_var in chapter 2, simulate_data_multi_var takes as input our model parameters, starting values and time steps. This time we also need to tell the model when to start and end interventions and when to seed the Omicron variant. The model equations are defined in models/model2_deSolve.R . multi_var_sim_data = simulate_data_multi_var ( immunity = immunity_mv , n_inf_D = n_inf_D , n_inf_O = n_inf_O , rho_D = rho_D , rho_O = rho_O , beta_D = beta_D , beta_O = beta_O , epsilon = epsilon , omega = omega , nu = nu , gamma_O = gamma_O , gamma_D = gamma_D , sigma_O = sigma_O , sigma_D = sigma_D , ts = 1 : length ( all_dates_mv ), time_int_start = which ( all_dates_mv == date_int [ 1 ]), time_int_end = which ( all_dates_mv == date_int [ 2 ]), time_seed_O = which ( all_dates_mv == date_seed_O ) ) We can then plot the reported incidence with noise for the Delta and Omicron variants. multi_var_sim_inc = calc_sim_incidence_multi_var ( ODE_data = multi_var_sim_data , all_dates = all_dates_mv , date_fit_D = date_fit_D , date_fit_O = date_fit_O , rho_D = rho_D , rho_O = rho_O , sigma_D = sigma_D , sigma_O = sigma_O ) multi_var_sim_inc [[ 2 ]] # Plot As we are assuming that incidence between July 2021 - October 2021 is Delta and that incidence between October 2021 and December 2021 is Omicron, all other data are \"NA\" which we need to discard: # Removing missing data y_D = multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise )] y_O = multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise )] Fitting the multivariant model in Stan The multivariate SEIQRS model using Euler's method is coded up in model2_Euler_V1.stan , in the models folder. Spend some time looking over the model to check everything is clear. The variables for storing the outputs of the E, I, Q compartments are now 2D matrices, where the rows are the each time step at which we solve the model and the columns are the variants. Once you are happy with the model, we can fit it to the data: stan_fit_m2_EU1 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 6 , # amount to reduce time step, nu = nu ), model = m2_EU1 , n_var = 2 , model_no = 2 , n_iter = 400 , n_warmup = 200 ) ## Warning: The largest R-hat is NA, indicating chains have not mixed. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#r-hat ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#bulk-ess ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#tail-ess ## Time difference of 8.191365 mins Stan is providing us with a series of warnings that the chains have not mixed and that our posterior distributions are unreliable. To investigate this further, run diagnostics on the model as before: m2_EU1_diag = diagnose_stan_fit ( stan_fit_m2_EU1 , # pars = c ( \"beta[1]\" , \"rho[1]\" , \"rho[2]\" , \"beta[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"epsilon\" , \"omega\" )) m2_EU1_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.174278594 0.032742915 0.086212251 2.076230820 2.126329648 ## rho[1] 0.201609983 0.012991698 0.030939623 0.167216827 0.184687568 ## rho[2] 0.126246817 0.003388824 0.014708580 0.103874931 0.116838378 ## beta[2] 3.971081625 1.781548465 2.210453651 2.271054659 2.402496851 ## R_0[1] 5.026515710 0.010703291 0.027965750 4.957186757 5.017956338 ## R_0[2] 14.417304447 6.391065805 7.932560673 8.433757470 8.816767533 ## epsilon 0.005681398 0.001027253 0.001328556 0.004372203 0.004714769 ## omega 0.686398775 0.043428414 0.058106890 0.620262206 0.645499375 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.150393516 2.187886913 2.404599547 6.932714 1.195066 ## rho[1] 0.192530698 0.205612432 0.285419766 5.671503 1.235327 ## rho[2] 0.123385478 0.132640129 0.163287402 18.838378 1.102571 ## beta[2] 2.491639868 6.536477611 8.006769192 1.539457 6.311293 ## R_0[1] 5.031984652 5.042884379 5.058545954 6.826817 1.173300 ## R_0[2] 9.071625754 23.593396160 28.833707087 1.540566 6.206673 ## epsilon 0.004959327 0.007003534 0.008489794 1.672649 3.119356 ## omega 0.660125727 0.732646287 0.815256899 1.790224 2.430118 The warnings and diagnostic plots all show the model has failed to converge. Looking at the trace plot, it seems the model is converging on the parameters specific to Delta. Conversely, for the parameters relating to Omicron, the model is exploring two different regions of the posterior distribution. To help diagnose the problem, we can look at the lp (the log posterior) to try and understand whether the chains are exploring parameter values that are equally likely. Note, that as the lp_ is the log density up to a constant , it is not the same as the log likelihood and should not be used to compare models, as the constant from different models are likely to be different. Therefore, the is only useful as a rough indicator for comparing the log posterior of chains within the same model. If a model is non-identifiable it means that two values of a parameter are equally likely, for instance because there are two modes in the posterior distribution. In this instance, we would expect to see chains exploring different regions of parameter space and obtaining similar estimates of the log posterior. Conversely, if we see that chains are exploring different parameter values with different log probabilities it suggests one or more of the chains may be stuck in a local mode. Q3: Looking at the trace plots, do you think the model is non-identifiable or that one or more of the chains are stuck in a local mode? If we plot the model fit against the data, we can see that the model is able to recreate the Delta incidence but only partly captures the Omicron transmission dynamics: plot_model_fit_multi_var ( stan_fit_m2_EU1 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) To explore this further, we can even plot the model fit for each chain separately. This allows us to confirm that the chains with a high log posterior are indeed exploring parameter values that are able to capture the transmission dynamics: As expected, chains 1 and 2 are able to capture the transmission dynamics of Omicron, whilst chain 3 peaks too early. This makes sense, given that this chain was exploring much higher values of the Omicron R_0 . Improving the Stan model From the above diagnostics we can see that the model is having problems converging. One option is to run the model for more iterations, e.g, 2000 iterations with the first 1000 discarded as burn in. In this instance, the model still fails to converge (you can test this if you like, it takes ~30 minutes to run). Alternatively, we can take failure to converge as a sign that our model needs improving. In practice it is often likely that our model is missing some key component of the data generating process. In that instance, we would need to revisit the assumptions underlying our model structure and fixed parameter values in order to extend and improve our model. However, as we simulated the data we know that this is not the case. Instead, lets revisit our parameter priors. For \\epsilon , the rate that immunity wanes against Omicron, the model is exploring two models. The first is ~0.005 and the second is ~0.0075, corresponding to immunity last on average for 200 days and 130 days respectively. Based on the diagnostics we ran, we know that an average duration of immunity around 200 days is more likely. We originally assumed \\epsilon \\sim ND(0.003,0.001) : eps_prior = rnorm ( 100000 , 0.003 , 0.001 ) quantile ( eps_prior , probs = c ( 0.025 , 0.25 , 0.5 , 0.75 , 0.975 )) ## 2.5% 25% 50% 75% 97.5% ## 0.001030631 0.002324570 0.003002029 0.003671811 0.004967465 In isolation, this prior supports parameter values between 0.001-0.005, or immunity lasting 250-1000 days, and yet in our model the sampler is stuck in a local mode exploring values of immunity <150 days. Clearly, our prior is not regularising our model in the way that we had hoped. Lets try relaxing the prior on \\epsilon to see if that helps: \\epsilon \\sim Exponential(5) . model2_Euler_V2.stan is exactly the same as model2_Euler_V1.stan but with the updated prio. We will also increase the frequency with which we solve the ODEs from 6 times per day to 10 times per day, to improve accuracy. stan_fit_m2_EU2 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 10 , # amount to reduce time step, nu = nu ), model = m2_EU2 , n_var = 2 , model_no = 2 ) ## Time difference of 19.98115 mins This time, we received no warnings and the diagnostics all look good: m2_EU2_diag = diagnose_stan_fit ( stan_fit_m2_EU2 , # pars = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" )) m2_EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.116521884 9.899071e-04 0.0269706926 2.067661028 2.097787454 ## beta[2] 2.319350471 5.139249e-03 0.1024861769 2.131684601 2.248085267 ## rho[1] 0.188317783 3.325335e-04 0.0092349010 0.171366430 0.181847303 ## rho[2] 0.115291630 4.347656e-04 0.0090079647 0.099126602 0.108939300 ## R_0[1] 4.981323338 4.041932e-04 0.0119813757 4.957105925 4.973470936 ## R_0[2] 8.553193796 1.482954e-02 0.3023531775 7.980951894 8.344190297 ## omega 0.644320641 5.484722e-04 0.0168800694 0.610813948 0.633733466 ## epsilon 0.005078499 1.653904e-05 0.0003368983 0.004422272 0.004848714 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.116432248 2.133809321 2.175968276 742.3272 1.0010011 ## beta[2] 2.320265733 2.385751498 2.542435142 397.6778 1.0132085 ## rho[1] 0.188335445 0.194204472 0.207661324 771.2475 1.0012060 ## rho[2] 0.115026089 0.121291680 0.134161125 429.2824 1.0127609 ## R_0[1] 4.981861544 4.989864744 5.003023951 878.6892 0.9997183 ## R_0[2] 8.557859890 8.747650458 9.194714836 415.6939 1.0123018 ## omega 0.644341053 0.655534903 0.677306322 947.1947 0.9991738 ## epsilon 0.005053239 0.005293894 0.005769865 414.9321 1.0125417 The model fit is also good: plot_model_fit_multi_var ( stan_fit_m2_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) Finally, we can compare the parameter estimates to the true values: compare_param_est ( parameter_names = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" ), true_param_values = c ( beta_D , beta_O , rho_D , rho_O , R0_D , R0_O , omega , epsilon ), param_values1 = m2_EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], model_names = c ( \"EU\" ) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] ## ## [[7]] ## ## [[8]] The model is broadly able to capture all the parameter values. As the is strong correlation between the parameters values, we might say they are weakly identified, as the posterior distribution mode is a ridge (see the pairs plot). Nevertheless, with sensible priors we are still able to capture the parameter values and obtain a sufficient sample size (see n_eff), indicating that results are unbiased and can be trusted. Model extensions Note, these extensions don't have solutions, and there isn't a single, correct way to approach them. The challanges are more open ended and are provided in case you would like to explore this topic further! 1. Parameter values, priors and likelihoods As discussed throughout the tutorial, there are many choices to made during the model fitting process. These include which parameter values to fix and which to estimate, which priors to use and which likelihood to use. Challenge: Refit the model Swap assuming the likelihood follows a Poisson distribution, rather than a Negative Binomial distribution Challenge: As discussed above, there is a some non-identifiability in the model. One way to address this is fix one of the parameter values. Refit the model fixing one or more of the parameter values. How does this change the parameter estimates? Alternatively, What happens if you try estimating more parameter values? For instance, try estimating the \\gamma and/or the \\sigma parameters. Does the model still converge? Are the estimated parameter values less accurate? Challenge: We have shown that our model can be sensitive to the choice of prior. We fit the model assuming improper, flat priors. Does the model still converge? Can you find a set of priors that result in divergent transitions? 2. Missing data A common problem in epidemiological modelling is missing data. We are frequently using secondary data, which was not collected for the purposes of our study. When modelling multivariate pathogens (e.g., SARS-CoV-2, Influenza, Dengue), we often do not know what variant or serotype someone was infected with, as this is not routinely collected information. For instance, most positive COVID-19 samples are not sequenced, so we do not know which variant they are infected with. In this example, we made the simplifying assumption that only a single variant was circulating at any time. However, this is clearly incorrect. Instead, we could couple genomic surveillance data, for instance that reported in GISAID , to the reported epidemiological incidence to recreate the variant specific incidences, by assuming the variant-specific prevalence in GISAID is proportional to its reported incidence: y_Y = y_{tot} \\frac{x_Y}{n} Where y_Y is the variant specific reported incidence, y_{tot} is the total reported incidence, x_Y is the number of sequences positive for variant Y and n is the number of samples sequenced. A limitation of genomic surveillance, is that it is often spatiotemporally sparse. Even for SARS-CoV-2, which has had more thorough surveillance than most other infectious diseases, there may be months for which now genomic surveillance was done. For instance, say that no genomic surveillance was undertaken in Gauteng for 1 weeks in June and October respectively. Therefore, for those time period we would have missing data for the variant-specific incidence of Delta and Omicron: ggplot ( multi_var_sim_inc_missing_data , aes ( x = date , y = rep_inc_D_noise )) + geom_line () + geom_line ( aes ( y = rep_inc_O_noise ), color = \"red\" ) Whereas in R, we can account for missing data as \"NA\", in Stan missing data cannot be included. Therefore, if we want to fit the model to incidence data where date for certain dates are missing, we need to include an array where we index the dates to be fit. This is similar to seeding the model 1 month prior to fitting, we passed an index to the Stan model telling it at which time point to start fitting the model. Challenge: Save model2_Euler_V2.stan as a new model and extend it to fit to the incidence data in multi_var_sim_inc_missing_data*, accounting for the missing data. * 3. Pre-symptomatic transmission There is evidence that SARS-CoV-2 transmission occurs prior to the onset of symptoms [3], which we do not account for in our model. Challenge: First draw out a compartmental model which allows for pre-symptomatic infectiousness. Assume that the average period from exposure to SARS-CoV-2 to the onset of Viraemia is fixed at 1.31 days [3] (so you do not need to estimate any additional parameters). Next, save model2_deSolve.R as a new model and extend it to include pre-symptomatic infectiousness. How does it change the transmission dynamics of the outbreak? Fianlly, save model2_Euler_V2.stan* as a new model and modify it to include pre-symptomatic infectiousness. * References (1) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Grant R, Charmet T, Schaeffer L, et al. Impact of SARS-CoV-2 Delta variant on incubation, transmission settings and vaccine effectiveness: Results from a nationwide case-control study in France. Lancet Reg Health Eur 2022; 13: 100278 (5) Menni C, Valdes AM, Polidori L, et al. Symptom prevalence, duration, and risk of hospital admission in individuals infected with SARS-CoV-2 during periods of omicron and delta variant dominance: a prospective observational study from the ZOE COVID Study. Lancet 2022; 399(10335): 1618-24.","title":"Chapter 3"},{"location":"chapter_3/#a-multivariant-model","text":"In this chapter, we are going to fit a multivariate model to capture the dynamics of both the Delta and Omicron VOC's in Gauteng. This means fitting to the incidence data observed during the third wave, driven by Delta, and the fourth wave, driven by Omicron. We will assume that between July 2021 - October 2021 the incidence data is Delta, whilst between October 2021 and December 2021 the incidence data is Omicron ^. As before, we will seed both variants 1 month before fitting to the data. That means we seed Delta in May and we seed Omicron in September. ^Note that these dates are not quite in line with the observed waves in Gauteng. In order to reduce memory usage and the time taken to fit the models in Stan we have assumed shorter waves and a reduce time period over which to model. The flow diagram of the multivariate model is shown in the following figure: Let subscript Y refer to the virus variant ( D = Delta, O = Omicron). Susceptible individuals ( S compartment) are infected at rate \\lambda_Y = \\beta_Y \\frac{I_{t0}} {S_{t0}} . Following infection individuals are latent with the virus ( E compartments) for an average of c \\frac{1}{\\sigma} days. After incubating the virus, a proportion \\rho_Y of individuals are detected, reported and enter isolation ( Q compartments). The remaining proportion become infectious ( I compartments) and contribute to the transmission of SARS-CoV-2. The infectious period lasts on average \\frac{1}{\\gamma} days, and then individuals recover and test negative ( R compartment). Susceptible individuals are also vaccinated and enter the R compartment directly at rate \\nu . Once recovered, immunity to the Omicron variant wanes at a rate of \\epsilon ( S_O compartment) and individuals are infected at a rate of \\lambda_O .","title":"A multivariant model"},{"location":"chapter_3/#initial-conditions","text":"As before, we will assume a single infectious individual seeds both the Delta and Omicron variants. We need redefine the number of recovered individuals, as we are now looking prior to the third wave. A sero-suvery in Gauteng reported a seroprevalence of 19% in at the end of January 2021 [1], so we will assume that R_{t0} = N * 0.19 and S_{t0} = N -R_{t0} . We will assume that the E , Q and S_O compartments are all 0 at t_0 .","title":"Initial conditions"},{"location":"chapter_3/#model-parameters","text":"As before, we will fix \\sigma and \\gamma using estimates from the literature, but we will assume they are variant-specific. For Omicron these we assume an average latent period \\frac{1}{\\sigma_D} of 3.03 days [2] and an average infectious period \\frac{1}{\\gamma_D} of 4.17 days [3]. FOr Delta, we will assume an average latent period \\frac{1}{\\sigma_O} 4.3 days [4] and an infectious period an average infectious period \\frac{1}{\\gamma_O} of 2.9 days [3]. We are also going to fix the rate of vaccination, assuming a constant per capita rate of vaccination of \\nu = 0.001 . We are going to estimate the variant-specific transmission rates \\beta_Y , the variant-specific reporting probability, \\rho_Y and the rate of immune waning \\epsilon . Q1: Why might we want to assume a variant specific reporting probability? During the third wave, driven by Delta, interventions were introduced across South Africa between 15-06-21 and 13-09-2021. We will use our model to also estimate the impact of these interventions on transmission. Let \\omega be the percentage reduction in transmission due to interventions. We model this impact on transmission as follows: \\beta' = \\beta * (1-\\omega) Finally, we are also going to estimate the over-dispersion parameter \\kappa , introduced in the previous chapters.","title":"Model parameters"},{"location":"chapter_3/#likelihood-and-priors","text":"As before we are going to assume a beta prior for the reporting probabilities: \\rho_Y \\sim Beta(2,8) , a normal distribution prior for the transmission rates: \\beta_Y \\sim ND(2.2,1) and an exponential distribution for the overdispersion parameter prior: \\kappa \\sim exp(0.01) . As a starting point, lets say that we fairly certain a SARS-CoV-2 infection or vaccination provides immunity for a year, and assume the following prior: \\epsilon \\sim ND(0.003,0.001) . Q2: Given what we know about the impact of interventions on transmission, what prior should we assume for \\omega ? Finally, we need to define our likelihood functions. As before, we assume that SARS-CoV-2 reported incidence is overdispersed and assume a Negative Binomial distribution: y_Y \\sim NegBin(\\mu_Y, \\kappa) Note, this time we have two likelihood functions, one for each variant. As before, we reconstruct the reported incidence from the model \\mu_Y as the rate of entry into the Q compartment: \\mu_Y = \\rho_Y \\sigma_Y E_Y . Including multiple likelihoods in Stan is easy, we just define them on separate lines and Stan will sum them automatically to calculate the overall model likelihood.","title":"Likelihood and priors"},{"location":"chapter_3/#assumptions","text":"No pre-symptomatic transmission. All reported incidence is dichotomously assumed to be either the Delta or Omicron variants, with no over variants in circulation. All tested individuals isolate with 100% compliance.","title":"Assumptions"},{"location":"chapter_3/#simulating-multivariant-data","text":"Defining key dates: # Date we start fitting the incidence to Delta date_fit_D = as.Date.character ( \"01-06-2021\" , format = \"%d-%m-%Y\" ) # Date we start fitting the incidence data to Omicron date_fit_O = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) # Date we seed Delta (1 month before we fit) date_seed_D = as.Date.character ( \"01-05-2021\" , format = \"%d-%m-%Y\" ) # Date we seed D (1 month before we fit) date_seed_O = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) # Date interventions date_int = as.Date.character ( c ( \"15-06-2021\" , \"13-09-2021\" ), format = \"%d-%m-%Y\" ) # Final data of modelling period end_date = as.Date.character ( \"01-01-2022\" , format = \"%d-%m-%Y\" ) # All dates of modelling period all_dates_mv = seq.Date ( from = date_seed_D , to = end_date , by = \"days\" ) # model times As we are simulating data again, we need to define both the estimated and fixed parameters: # Define variables n_pop = 15810388 # Population immunity_mv = 0.19 # Percentage of the population with immunity n_inf_D = 1 # Initial Delta seed n_inf_O = 1 # Initial Omicron seed # Defining fixed parameters gamma_O = 1 / 4.17 # Omicron recovery rate gamma_D = 1 / 2.9 # Delta recovery rate sigma_O = 1 / 3.03 # Omicron latent rate sigma_D = 1 / 4.3 # Delta latent rate nu = 0.002 # Vaccination rate # Defining \"unknown\" parameters R0_D = 5 # Delta reproduction number R0_O = 8 # Omicron reproduction number rho_D = 0.2 # Probability of reporting a Delta case rho_O = 0.1 # Probability of reporting an Omicron case epsilon = 1 / 180 # Rate of immune waning omega = 0.65 # Percentage reduction in transmission due to interventions beta_D = ( R0_D * gamma_D ) / ( 1 - rho_D ) # Delta transmission rate beta_O = ( R0_O * gamma_O ) / ( 1 - rho_O ) # Omicron transmission rate Like the function simulate_data_single_var in chapter 2, simulate_data_multi_var takes as input our model parameters, starting values and time steps. This time we also need to tell the model when to start and end interventions and when to seed the Omicron variant. The model equations are defined in models/model2_deSolve.R . multi_var_sim_data = simulate_data_multi_var ( immunity = immunity_mv , n_inf_D = n_inf_D , n_inf_O = n_inf_O , rho_D = rho_D , rho_O = rho_O , beta_D = beta_D , beta_O = beta_O , epsilon = epsilon , omega = omega , nu = nu , gamma_O = gamma_O , gamma_D = gamma_D , sigma_O = sigma_O , sigma_D = sigma_D , ts = 1 : length ( all_dates_mv ), time_int_start = which ( all_dates_mv == date_int [ 1 ]), time_int_end = which ( all_dates_mv == date_int [ 2 ]), time_seed_O = which ( all_dates_mv == date_seed_O ) ) We can then plot the reported incidence with noise for the Delta and Omicron variants. multi_var_sim_inc = calc_sim_incidence_multi_var ( ODE_data = multi_var_sim_data , all_dates = all_dates_mv , date_fit_D = date_fit_D , date_fit_O = date_fit_O , rho_D = rho_D , rho_O = rho_O , sigma_D = sigma_D , sigma_O = sigma_O ) multi_var_sim_inc [[ 2 ]] # Plot As we are assuming that incidence between July 2021 - October 2021 is Delta and that incidence between October 2021 and December 2021 is Omicron, all other data are \"NA\" which we need to discard: # Removing missing data y_D = multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise )] y_O = multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise )]","title":"Simulating multivariant data"},{"location":"chapter_3/#fitting-the-multivariant-model-in-stan","text":"The multivariate SEIQRS model using Euler's method is coded up in model2_Euler_V1.stan , in the models folder. Spend some time looking over the model to check everything is clear. The variables for storing the outputs of the E, I, Q compartments are now 2D matrices, where the rows are the each time step at which we solve the model and the columns are the variants. Once you are happy with the model, we can fit it to the data: stan_fit_m2_EU1 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 6 , # amount to reduce time step, nu = nu ), model = m2_EU1 , n_var = 2 , model_no = 2 , n_iter = 400 , n_warmup = 200 ) ## Warning: The largest R-hat is NA, indicating chains have not mixed. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#r-hat ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#bulk-ess ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#tail-ess ## Time difference of 8.191365 mins Stan is providing us with a series of warnings that the chains have not mixed and that our posterior distributions are unreliable. To investigate this further, run diagnostics on the model as before: m2_EU1_diag = diagnose_stan_fit ( stan_fit_m2_EU1 , # pars = c ( \"beta[1]\" , \"rho[1]\" , \"rho[2]\" , \"beta[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"epsilon\" , \"omega\" )) m2_EU1_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.174278594 0.032742915 0.086212251 2.076230820 2.126329648 ## rho[1] 0.201609983 0.012991698 0.030939623 0.167216827 0.184687568 ## rho[2] 0.126246817 0.003388824 0.014708580 0.103874931 0.116838378 ## beta[2] 3.971081625 1.781548465 2.210453651 2.271054659 2.402496851 ## R_0[1] 5.026515710 0.010703291 0.027965750 4.957186757 5.017956338 ## R_0[2] 14.417304447 6.391065805 7.932560673 8.433757470 8.816767533 ## epsilon 0.005681398 0.001027253 0.001328556 0.004372203 0.004714769 ## omega 0.686398775 0.043428414 0.058106890 0.620262206 0.645499375 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.150393516 2.187886913 2.404599547 6.932714 1.195066 ## rho[1] 0.192530698 0.205612432 0.285419766 5.671503 1.235327 ## rho[2] 0.123385478 0.132640129 0.163287402 18.838378 1.102571 ## beta[2] 2.491639868 6.536477611 8.006769192 1.539457 6.311293 ## R_0[1] 5.031984652 5.042884379 5.058545954 6.826817 1.173300 ## R_0[2] 9.071625754 23.593396160 28.833707087 1.540566 6.206673 ## epsilon 0.004959327 0.007003534 0.008489794 1.672649 3.119356 ## omega 0.660125727 0.732646287 0.815256899 1.790224 2.430118 The warnings and diagnostic plots all show the model has failed to converge. Looking at the trace plot, it seems the model is converging on the parameters specific to Delta. Conversely, for the parameters relating to Omicron, the model is exploring two different regions of the posterior distribution. To help diagnose the problem, we can look at the lp (the log posterior) to try and understand whether the chains are exploring parameter values that are equally likely. Note, that as the lp_ is the log density up to a constant , it is not the same as the log likelihood and should not be used to compare models, as the constant from different models are likely to be different. Therefore, the is only useful as a rough indicator for comparing the log posterior of chains within the same model. If a model is non-identifiable it means that two values of a parameter are equally likely, for instance because there are two modes in the posterior distribution. In this instance, we would expect to see chains exploring different regions of parameter space and obtaining similar estimates of the log posterior. Conversely, if we see that chains are exploring different parameter values with different log probabilities it suggests one or more of the chains may be stuck in a local mode. Q3: Looking at the trace plots, do you think the model is non-identifiable or that one or more of the chains are stuck in a local mode? If we plot the model fit against the data, we can see that the model is able to recreate the Delta incidence but only partly captures the Omicron transmission dynamics: plot_model_fit_multi_var ( stan_fit_m2_EU1 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) To explore this further, we can even plot the model fit for each chain separately. This allows us to confirm that the chains with a high log posterior are indeed exploring parameter values that are able to capture the transmission dynamics: As expected, chains 1 and 2 are able to capture the transmission dynamics of Omicron, whilst chain 3 peaks too early. This makes sense, given that this chain was exploring much higher values of the Omicron R_0 .","title":"Fitting the multivariant model in Stan"},{"location":"chapter_3/#improving-the-stan-model","text":"From the above diagnostics we can see that the model is having problems converging. One option is to run the model for more iterations, e.g, 2000 iterations with the first 1000 discarded as burn in. In this instance, the model still fails to converge (you can test this if you like, it takes ~30 minutes to run). Alternatively, we can take failure to converge as a sign that our model needs improving. In practice it is often likely that our model is missing some key component of the data generating process. In that instance, we would need to revisit the assumptions underlying our model structure and fixed parameter values in order to extend and improve our model. However, as we simulated the data we know that this is not the case. Instead, lets revisit our parameter priors. For \\epsilon , the rate that immunity wanes against Omicron, the model is exploring two models. The first is ~0.005 and the second is ~0.0075, corresponding to immunity last on average for 200 days and 130 days respectively. Based on the diagnostics we ran, we know that an average duration of immunity around 200 days is more likely. We originally assumed \\epsilon \\sim ND(0.003,0.001) : eps_prior = rnorm ( 100000 , 0.003 , 0.001 ) quantile ( eps_prior , probs = c ( 0.025 , 0.25 , 0.5 , 0.75 , 0.975 )) ## 2.5% 25% 50% 75% 97.5% ## 0.001030631 0.002324570 0.003002029 0.003671811 0.004967465 In isolation, this prior supports parameter values between 0.001-0.005, or immunity lasting 250-1000 days, and yet in our model the sampler is stuck in a local mode exploring values of immunity <150 days. Clearly, our prior is not regularising our model in the way that we had hoped. Lets try relaxing the prior on \\epsilon to see if that helps: \\epsilon \\sim Exponential(5) . model2_Euler_V2.stan is exactly the same as model2_Euler_V1.stan but with the updated prio. We will also increase the frequency with which we solve the ODEs from 6 times per day to 10 times per day, to improve accuracy. stan_fit_m2_EU2 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 10 , # amount to reduce time step, nu = nu ), model = m2_EU2 , n_var = 2 , model_no = 2 ) ## Time difference of 19.98115 mins This time, we received no warnings and the diagnostics all look good: m2_EU2_diag = diagnose_stan_fit ( stan_fit_m2_EU2 , # pars = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" )) m2_EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.116521884 9.899071e-04 0.0269706926 2.067661028 2.097787454 ## beta[2] 2.319350471 5.139249e-03 0.1024861769 2.131684601 2.248085267 ## rho[1] 0.188317783 3.325335e-04 0.0092349010 0.171366430 0.181847303 ## rho[2] 0.115291630 4.347656e-04 0.0090079647 0.099126602 0.108939300 ## R_0[1] 4.981323338 4.041932e-04 0.0119813757 4.957105925 4.973470936 ## R_0[2] 8.553193796 1.482954e-02 0.3023531775 7.980951894 8.344190297 ## omega 0.644320641 5.484722e-04 0.0168800694 0.610813948 0.633733466 ## epsilon 0.005078499 1.653904e-05 0.0003368983 0.004422272 0.004848714 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.116432248 2.133809321 2.175968276 742.3272 1.0010011 ## beta[2] 2.320265733 2.385751498 2.542435142 397.6778 1.0132085 ## rho[1] 0.188335445 0.194204472 0.207661324 771.2475 1.0012060 ## rho[2] 0.115026089 0.121291680 0.134161125 429.2824 1.0127609 ## R_0[1] 4.981861544 4.989864744 5.003023951 878.6892 0.9997183 ## R_0[2] 8.557859890 8.747650458 9.194714836 415.6939 1.0123018 ## omega 0.644341053 0.655534903 0.677306322 947.1947 0.9991738 ## epsilon 0.005053239 0.005293894 0.005769865 414.9321 1.0125417 The model fit is also good: plot_model_fit_multi_var ( stan_fit_m2_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) Finally, we can compare the parameter estimates to the true values: compare_param_est ( parameter_names = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" ), true_param_values = c ( beta_D , beta_O , rho_D , rho_O , R0_D , R0_O , omega , epsilon ), param_values1 = m2_EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], model_names = c ( \"EU\" ) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] ## ## [[7]] ## ## [[8]] The model is broadly able to capture all the parameter values. As the is strong correlation between the parameters values, we might say they are weakly identified, as the posterior distribution mode is a ridge (see the pairs plot). Nevertheless, with sensible priors we are still able to capture the parameter values and obtain a sufficient sample size (see n_eff), indicating that results are unbiased and can be trusted.","title":"Improving the Stan model"},{"location":"chapter_3/#model-extensions","text":"Note, these extensions don't have solutions, and there isn't a single, correct way to approach them. The challanges are more open ended and are provided in case you would like to explore this topic further!","title":"Model extensions"},{"location":"chapter_3/#1-parameter-values-priors-and-likelihoods","text":"As discussed throughout the tutorial, there are many choices to made during the model fitting process. These include which parameter values to fix and which to estimate, which priors to use and which likelihood to use. Challenge: Refit the model Swap assuming the likelihood follows a Poisson distribution, rather than a Negative Binomial distribution Challenge: As discussed above, there is a some non-identifiability in the model. One way to address this is fix one of the parameter values. Refit the model fixing one or more of the parameter values. How does this change the parameter estimates? Alternatively, What happens if you try estimating more parameter values? For instance, try estimating the \\gamma and/or the \\sigma parameters. Does the model still converge? Are the estimated parameter values less accurate? Challenge: We have shown that our model can be sensitive to the choice of prior. We fit the model assuming improper, flat priors. Does the model still converge? Can you find a set of priors that result in divergent transitions?","title":"1. Parameter values, priors and likelihoods"},{"location":"chapter_3/#2-missing-data","text":"A common problem in epidemiological modelling is missing data. We are frequently using secondary data, which was not collected for the purposes of our study. When modelling multivariate pathogens (e.g., SARS-CoV-2, Influenza, Dengue), we often do not know what variant or serotype someone was infected with, as this is not routinely collected information. For instance, most positive COVID-19 samples are not sequenced, so we do not know which variant they are infected with. In this example, we made the simplifying assumption that only a single variant was circulating at any time. However, this is clearly incorrect. Instead, we could couple genomic surveillance data, for instance that reported in GISAID , to the reported epidemiological incidence to recreate the variant specific incidences, by assuming the variant-specific prevalence in GISAID is proportional to its reported incidence: y_Y = y_{tot} \\frac{x_Y}{n} Where y_Y is the variant specific reported incidence, y_{tot} is the total reported incidence, x_Y is the number of sequences positive for variant Y and n is the number of samples sequenced. A limitation of genomic surveillance, is that it is often spatiotemporally sparse. Even for SARS-CoV-2, which has had more thorough surveillance than most other infectious diseases, there may be months for which now genomic surveillance was done. For instance, say that no genomic surveillance was undertaken in Gauteng for 1 weeks in June and October respectively. Therefore, for those time period we would have missing data for the variant-specific incidence of Delta and Omicron: ggplot ( multi_var_sim_inc_missing_data , aes ( x = date , y = rep_inc_D_noise )) + geom_line () + geom_line ( aes ( y = rep_inc_O_noise ), color = \"red\" ) Whereas in R, we can account for missing data as \"NA\", in Stan missing data cannot be included. Therefore, if we want to fit the model to incidence data where date for certain dates are missing, we need to include an array where we index the dates to be fit. This is similar to seeding the model 1 month prior to fitting, we passed an index to the Stan model telling it at which time point to start fitting the model. Challenge: Save model2_Euler_V2.stan as a new model and extend it to fit to the incidence data in multi_var_sim_inc_missing_data*, accounting for the missing data. *","title":"2. Missing data"},{"location":"chapter_3/#3-pre-symptomatic-transmission","text":"There is evidence that SARS-CoV-2 transmission occurs prior to the onset of symptoms [3], which we do not account for in our model. Challenge: First draw out a compartmental model which allows for pre-symptomatic infectiousness. Assume that the average period from exposure to SARS-CoV-2 to the onset of Viraemia is fixed at 1.31 days [3] (so you do not need to estimate any additional parameters). Next, save model2_deSolve.R as a new model and extend it to include pre-symptomatic infectiousness. How does it change the transmission dynamics of the outbreak? Fianlly, save model2_Euler_V2.stan* as a new model and modify it to include pre-symptomatic infectiousness. *","title":"3. Pre-symptomatic transmission"},{"location":"chapter_3/#references","text":"(1) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Grant R, Charmet T, Schaeffer L, et al. Impact of SARS-CoV-2 Delta variant on incubation, transmission settings and vaccine effectiveness: Results from a nationwide case-control study in France. Lancet Reg Health Eur 2022; 13: 100278 (5) Menni C, Valdes AM, Polidori L, et al. Symptom prevalence, duration, and risk of hospital admission in individuals infected with SARS-CoV-2 during periods of omicron and delta variant dominance: a prospective observational study from the ZOE COVID Study. Lancet 2022; 399(10335): 1618-24.","title":"References"},{"location":"chapter_3_solutions/","text":"library ( dplyr ) library ( ggplot2 ) library ( rstan ) library ( tidyr ) rstan_options ( auto_write = TRUE ) options ( mc.cores = parallel :: detectCores ()) # Functions source ( \"R/simulate_data.R\" ) source ( \"R/calc_sim_incidence.R\" ) source ( \"R/draw_init_values.R\" ) source ( \"R/run_stan_models.R\" ) source ( \"R/diagnose_stan_fit.R\" ) source ( \"R/plot_model_fit.R\" ) source ( \"R/compare_param_est.R\" ) # Models m2_EU1 = stan_model ( \"models/model2_Euler_V1.stan\" ) m2_EU2 = stan_model ( \"models/model2_Euler_V2.stan\" ) A multivariant model In this chapter, we are going to fit a multivariate model to capture the dynamics of both the Delta and Omicron VOC's in Gauteng. This means fitting to the incidence data observed during the third wave, driven by Delta, and the fourth wave, driven by Omicron. We will assume that between July 2021 - October 2021 the incidence data is Delta, whilst between October 2021 and December 2021 the incidence data is Omicron ^. As before, we will seed both variants 1 month before fitting to the data. That means we seed Delta in May and we seed Omicron in September. ^Note that these dates are not quite in line with the observed waves in Gauteng. In order to reduce memory usage and the time taken to fit the models in Stan we have assumed shorter waves and a reduce time period over which to model. The flow diagram of the multivariate model is shown in the following figure: Let subscript Y refer to the virus variant ( D = Delta, O = Omicron). Susceptible individuals ( S compartment) are infected at rate \\lambda_Y = \\beta_Y \\frac{I_{t0}} {S_{t0}} . Following infection individuals are latent with the virus ( E compartments) for an average of c \\frac{1}{\\sigma} days. After incubating the virus, a proportion \\rho_Y of individuals are detected, reported and enter isolation ( Q compartments). The remaining proportion become infectious ( I compartments) and contribute to the transmission of SARS-CoV-2. The infectious period lasts on average \\frac{1}{\\gamma} days, and then individuals recover and test negative ( R compartment). Susceptible individuals are also vaccinated and enter the R compartment directly at rate \\nu . Once recovered, immunity to the Omicron variant wanes at a rate of \\epsilon ( S_O compartment) and individuals are infected at a rate of \\lambda_O . Initial conditions As before, we will assume a single infectious individual seeds both the Delta and Omicron variants. We need redefine the number of recovered individuals, as we are now looking prior to the third wave. A sero-suvery in Gauteng reported a seroprevalence of 19% in at the end of January 2021 [1], so we will assume that R_{t0} = N * 0.19 and S_{t0} = N -R_{t0} . We will assume that the E , Q and S_O compartments are all 0 at t_0 . Model parameters As before, we will fix \\sigma and \\gamma using estimates from the literature, but we will assume they are variant-specific. For Omicron these we assume an average latent period \\frac{1}{\\sigma_D} of 3.03 days [2] and an average infectious period \\frac{1}{\\gamma_D} of 4.17 days [3]. FOr Delta, we will assume an average latent period \\frac{1}{\\sigma_O} 4.3 days [4] and an infectious period an average infectious period \\frac{1}{\\gamma_O} of 2.9 days [3]. We are also going to fix the rate of vaccination, assuming a constant per capita rate of vaccination of \\nu = 0.001 . We are going to estimate the variant-specific transmission rates \\beta_Y , the variant-specific reporting probability, \\rho_Y and the rate of immune waning \\epsilon . Q1: Why might we want to assume a variant specific reporting probability? A1: There is a lot of evidence that Omicron is milder than Delta[5]. Individuals with infected with the Omicron variant are therefore less likely to have symptoms and test, so we expect increased underreporting of Omicron. During the third wave, driven by Delta, interventions were introduced across South Africa between 15-06-21 and 13-09-2021. We will use our model to also estimate the impact of these interventions on transmission. Let \\omega be the percentage reduction in transmission due to interventions. We model this impact on transmission as follows: \\beta' = \\beta * (1-\\omega) Finally, we are also going to estimate the over-dispersion parameter \\kappa , introduced in the previous chapters. Likelihood and priors As before we are going to assume a beta prior for the reporting probabilities: \\rho_Y \\sim Beta(2,8) , a normal distribution prior for the transmission rates: \\beta_Y \\sim ND(2.2,1) and an exponential distribution for the overdispersion parameter prior: \\kappa \\sim exp(0.01) . As a starting point, lets say that we fairly certain a SARS-CoV-2 infection or vaccination provides immunity for a year, and assume the following prior: \\epsilon \\sim ND(0.003,0.001) . Q2: Given what we know about the impact of interventions on transmission, what prior should we assume for \\omega ? A2: We don't know very much about \\omega except that it is bound between 0 and 1. So let's assume \\omega \\sim Beta(1,1) . Finally, we need to define our likelihood functions. As before, we assume that SARS-CoV-2 reported incidence is overdispersed and assume a Negative Binomial distribution: y_Y \\sim NegBin(\\mu_Y, \\kappa) Note, this time we have two likelihood functions, one for each variant. As before, we reconstruct the reported incidence from the model \\mu_Y as the rate of entry into the Q compartment: \\mu_Y = \\rho_Y \\sigma_Y E_Y . Including multiple likelihoods in Stan is easy, we just define them on separate lines and Stan will sum them automatically to calculate the overall model likelihood. Assumptions No pre-symptomatic transmission. All reported incidence is dichotomously assumed to be either the Delta or Omicron variants, with no over variants in circulation. All tested individuals isolate with 100% compliance. Simulating multivariant data Defining key dates: # Date we start fitting the incidence to Delta date_fit_D = as.Date.character ( \"01-06-2021\" , format = \"%d-%m-%Y\" ) # Date we start fitting the incidence data to Omicron date_fit_O = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) # Date we seed Delta (1 month before we fit) date_seed_D = as.Date.character ( \"01-05-2021\" , format = \"%d-%m-%Y\" ) # Date we seed D (1 month before we fit) date_seed_O = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) # Date interventions date_int = as.Date.character ( c ( \"15-06-2021\" , \"13-09-2021\" ), format = \"%d-%m-%Y\" ) # Final data of modelling period end_date = as.Date.character ( \"01-01-2022\" , format = \"%d-%m-%Y\" ) # All dates of modelling period all_dates_mv = seq.Date ( from = date_seed_D , to = end_date , by = \"days\" ) # model times As we are simulating data again, we need to define both the estimated and fixed parameters: # Define variables n_pop = 15810388 # Population immunity_mv = 0.19 # Percentage of the population with immunity n_inf_D = 1 # Initial Delta seed n_inf_O = 1 # Initial Omicron seed # Defining fixed parameters gamma_O = 1 / 4.17 # Omicron recovery rate gamma_D = 1 / 2.9 # Delta recovery rate sigma_O = 1 / 3.03 # Omicron latent rate sigma_D = 1 / 4.3 # Delta latent rate nu = 0.002 # Vaccination rate # Defining \"unknown\" parameters R0_D = 5 # Delta reproduction number R0_O = 8 # Omicron reproduction number rho_D = 0.2 # Probability of reporting a Delta case rho_O = 0.1 # Probability of reporting an Omicron case epsilon = 1 / 180 # Rate of immune waning omega = 0.65 # Percentage reduction in transmission due to interventions beta_D = ( R0_D * gamma_D ) / ( 1 - rho_D ) # Delta transmission rate beta_O = ( R0_O * gamma_O ) / ( 1 - rho_O ) # Omicron transmission rate Like the function simulate_data_single_var in chapter 2, simulate_data_multi_var takes as input our model parameters, starting values and time steps. This time we also need to tell the model when to start and end interventions and when to seed the Omicron variant. The model equations are defined in models/model2_deSolve.R . multi_var_sim_data = simulate_data_multi_var ( immunity = immunity_mv , n_inf_D = n_inf_D , n_inf_O = n_inf_O , rho_D = rho_D , rho_O = rho_O , beta_D = beta_D , beta_O = beta_O , epsilon = epsilon , omega = omega , nu = nu , gamma_O = gamma_O , gamma_D = gamma_D , sigma_O = sigma_O , sigma_D = sigma_D , ts = 1 : length ( all_dates_mv ), time_int_start = which ( all_dates_mv == date_int [ 1 ]), time_int_end = which ( all_dates_mv == date_int [ 2 ]), time_seed_O = which ( all_dates_mv == date_seed_O ) ) We can then plot the reported incidence with noise for the Delta and Omicron variants. multi_var_sim_inc = calc_sim_incidence_multi_var ( ODE_data = multi_var_sim_data , all_dates = all_dates_mv , date_fit_D = date_fit_D , date_fit_O = date_fit_O , rho_D = rho_D , rho_O = rho_O , sigma_D = sigma_D , sigma_O = sigma_O ) multi_var_sim_inc [[ 2 ]] # Plot As we are assuming that incidence between July 2021 - October 2021 is Delta and that incidence between October 2021 and December 2021 is Omicron, all other data are \"NA\" which we need to discard: # Removing missing data y_D = multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise )] y_O = multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise )] Fitting the multivariant model in Stan The multivariate SEIQRS model using Euler's method is coded up in model2_Euler_V1.stan , in the models folder. Spend some time looking over the model to check everything is clear. The variables for storing the outputs of the E, I, Q compartments are now 2D matrices, where the rows are the each time step at which we solve the model and the columns are the variants. Once you are happy with the model, we can fit it to the data: stan_fit_m2_EU1 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 6 , # amount to reduce time step, nu = nu ), model = m2_EU1 , n_var = 2 , model_no = 2 , n_iter = 400 , n_warmup = 200 ) ## Warning: The largest R-hat is NA, indicating chains have not mixed. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#r-hat ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#bulk-ess ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#tail-ess ## Time difference of 8.191365 mins Stan is providing us with a series of warnings that the chains have not mixed and that our posterior distributions are unreliable. To investigate this further, run diagnostics on the model as before: m2_EU1_diag = diagnose_stan_fit ( stan_fit_m2_EU1 , # pars = c ( \"beta[1]\" , \"rho[1]\" , \"rho[2]\" , \"beta[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"epsilon\" , \"omega\" )) m2_EU1_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.174278594 0.032742915 0.086212251 2.076230820 2.126329648 ## rho[1] 0.201609983 0.012991698 0.030939623 0.167216827 0.184687568 ## rho[2] 0.126246817 0.003388824 0.014708580 0.103874931 0.116838378 ## beta[2] 3.971081625 1.781548465 2.210453651 2.271054659 2.402496851 ## R_0[1] 5.026515710 0.010703291 0.027965750 4.957186757 5.017956338 ## R_0[2] 14.417304447 6.391065805 7.932560673 8.433757470 8.816767533 ## epsilon 0.005681398 0.001027253 0.001328556 0.004372203 0.004714769 ## omega 0.686398775 0.043428414 0.058106890 0.620262206 0.645499375 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.150393516 2.187886913 2.404599547 6.932714 1.195066 ## rho[1] 0.192530698 0.205612432 0.285419766 5.671503 1.235327 ## rho[2] 0.123385478 0.132640129 0.163287402 18.838378 1.102571 ## beta[2] 2.491639868 6.536477611 8.006769192 1.539457 6.311293 ## R_0[1] 5.031984652 5.042884379 5.058545954 6.826817 1.173300 ## R_0[2] 9.071625754 23.593396160 28.833707087 1.540566 6.206673 ## epsilon 0.004959327 0.007003534 0.008489794 1.672649 3.119356 ## omega 0.660125727 0.732646287 0.815256899 1.790224 2.430118 The warnings and diagnostic plots all show the model has failed to converge. Looking at the trace plot, it seems the model is converging on the parameters specific to Delta. Conversely, for the parameters relating to Omicron, the model is exploring two different regions of the posterior distribution. To help diagnose the problem, we can look at the lp (the log posterior) to try and understand whether the chains are exploring parameter values that are equally likely. Note, that as the lp_ is the log density up to a constant , it is not the same as the log likelihood and should not be used to compare models, as the constant from different models are likely to be different. Therefore, the is only useful as a rough indicator for comparing the log posterior of chains within the same model. If a model is non-identifiable it means that two values of a parameter are equally likely, for instance because there are two modes in the posterior distribution. In this instance, we would expect to see chains exploring different regions of parameter space and obtaining similar estimates of the log posterior. Conversely, if we see that chains are exploring different parameter values with different log probabilities it suggests one or more of the chains may be stuck in a local mode. Q3: Looking at the trace plots, do you think the model is non-identifiable or that one or more of the chains are stuck in a local mode? A3: From the trace plot, we can see that chains 1 and 2 are exploring a more probable region of parameter values (i.e., they have a high log probability). If we plot the model fit against the data, we can see that the model is able to recreate the Delta incidence but only partly captures the Omicron transmission dynamics: plot_model_fit_multi_var ( stan_fit_m2_EU1 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) To explore this further, we can even plot the model fit for each chain separately. This allows us to confirm that the chains with a high log posterior are indeed exploring parameter values that are able to capture the transmission dynamics: As expected, chains 1 and 2 are able to capture the transmission dynamics of Omicron, whilst chain 3 peaks too early. This makes sense, given that this chain was exploring much higher values of the Omicron R_0 . Improving the Stan model From the above diagnostics we can see that the model is having problems converging. One option is to run the model for more iterations, e.g, 2000 iterations with the first 1000 discarded as burn in. In this instance, the model still fails to converge (you can test this if you like, it takes ~30 minutes to run). Alternatively, we can take failure to converge as a sign that our model needs improving. In practice it is often likely that our model is missing some key component of the data generating process. In that instance, we would need to revisit the assumptions underlying our model structure and fixed parameter values in order to extend and improve our model. However, as we simulated the data we know that this is not the case. Instead, lets revisit our parameter priors. For \\epsilon , the rate that immunity wanes against Omicron, the model is exploring two models. The first is ~0.005 and the second is ~0.0075, corresponding to immunity last on average for 200 days and 130 days respectively. Based on the diagnostics we ran, we know that an average duration of immunity around 200 days is more likely. We originally assumed \\epsilon \\sim ND(0.003,0.001) : eps_prior = rnorm ( 100000 , 0.003 , 0.001 ) quantile ( eps_prior , probs = c ( 0.025 , 0.25 , 0.5 , 0.75 , 0.975 )) ## 2.5% 25% 50% 75% 97.5% ## 0.001030631 0.002324570 0.003002029 0.003671811 0.004967465 In isolation, this prior supports parameter values between 0.001-0.005, or immunity lasting 250-1000 days, and yet in our model the sampler is stuck in a local mode exploring values of immunity <150 days. Clearly, our prior is not regularising our model in the way that we had hoped. Lets try relaxing the prior on \\epsilon to see if that helps: \\epsilon \\sim Exponential(5) . model2_Euler_V2.stan is exactly the same as model2_Euler_V1.stan but with the updated prio. We will also increase the frequency with which we solve the ODEs from 6 times per day to 10 times per day, to improve accuracy. stan_fit_m2_EU2 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 10 , # amount to reduce time step, nu = nu ), model = m2_EU2 , n_var = 2 , model_no = 2 ) ## Time difference of 19.98115 mins This time, we received no warnings and the diagnostics all look good: m2_EU2_diag = diagnose_stan_fit ( stan_fit_m2_EU2 , # pars = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" )) m2_EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.116521884 9.899071e-04 0.0269706926 2.067661028 2.097787454 ## beta[2] 2.319350471 5.139249e-03 0.1024861769 2.131684601 2.248085267 ## rho[1] 0.188317783 3.325335e-04 0.0092349010 0.171366430 0.181847303 ## rho[2] 0.115291630 4.347656e-04 0.0090079647 0.099126602 0.108939300 ## R_0[1] 4.981323338 4.041932e-04 0.0119813757 4.957105925 4.973470936 ## R_0[2] 8.553193796 1.482954e-02 0.3023531775 7.980951894 8.344190297 ## omega 0.644320641 5.484722e-04 0.0168800694 0.610813948 0.633733466 ## epsilon 0.005078499 1.653904e-05 0.0003368983 0.004422272 0.004848714 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.116432248 2.133809321 2.175968276 742.3272 1.0010011 ## beta[2] 2.320265733 2.385751498 2.542435142 397.6778 1.0132085 ## rho[1] 0.188335445 0.194204472 0.207661324 771.2475 1.0012060 ## rho[2] 0.115026089 0.121291680 0.134161125 429.2824 1.0127609 ## R_0[1] 4.981861544 4.989864744 5.003023951 878.6892 0.9997183 ## R_0[2] 8.557859890 8.747650458 9.194714836 415.6939 1.0123018 ## omega 0.644341053 0.655534903 0.677306322 947.1947 0.9991738 ## epsilon 0.005053239 0.005293894 0.005769865 414.9321 1.0125417 The model fit is also good: plot_model_fit_multi_var ( stan_fit_m2_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) Finally, we can compare the parameter estimates to the true values: compare_param_est ( parameter_names = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" ), true_param_values = c ( beta_D , beta_O , rho_D , rho_O , R0_D , R0_O , omega , epsilon ), param_values1 = m2_EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], model_names = c ( \"EU\" ) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] ## ## [[7]] ## ## [[8]] The model is broadly able to capture all the parameter values. As the is strong correlation between the parameters values, we might say they are weakly identified, as the posterior distribution mode is a ridge (see the pairs plot). Nevertheless, with sensible priors we are still able to capture the parameter values and obtain a sufficient sample size (see n_eff), indicating that results are unbiased and can be trusted. Model extensions Note, these extensions don't have solutions, and there isn't a single, correct way to approach them. The challanges are more open ended and are provided in case you would like to explore this topic further! 1. Parameter values, priors and likelihoods As discussed throughout the tutorial, there are many choices to made during the model fitting process. These include which parameter values to fix and which to estimate, which priors to use and which likelihood to use. Challenge: Refit the model Swap assuming the likelihood follows a Poisson distribution, rather than a Negative Binomial distribution Challenge: As discussed above, there is a some non-identifiability in the model. One way to address this is fix one of the parameter values. Refit the model fixing one or more of the parameter values. How does this change the parameter estimates? Alternatively, What happens if you try estimating more parameter values? For instance, try estimating the \\gamma and/or the \\sigma parameters. Does the model still converge? Are the estimated parameter values less accurate? Challenge: We have shown that our model can be sensitive to the choice of prior. We fit the model assuming improper, flat priors. Does the model still converge? Can you find a set of priors that result in divergent transitions? 2. Missing data A common problem in epidemiological modelling is missing data. We are frequently using secondary data, which was not collected for the purposes of our study. When modelling multivariate pathogens (e.g., SARS-CoV-2, Influenza, Dengue), we often do not know what variant or serotype someone was infected with, as this is not routinely collected information. For instance, most positive COVID-19 samples are not sequenced, so we do not know which variant they are infected with. In this example, we made the simplifying assumption that only a single variant was circulating at any time. However, this is clearly incorrect. Instead, we could couple genomic surveillance data, for instance that reported in GISAID , to the reported epidemiological incidence to recreate the variant specific incidences, by assuming the variant-specific prevalence in GISAID is proportional to its reported incidence: y_Y = y_{tot} \\frac{x_Y}{n} Where y_Y is the variant specific reported incidence, y_{tot} is the total reported incidence, x_Y is the number of sequences positive for variant Y and n is the number of samples sequenced. A limitation of genomic surveillance, is that it is often spatiotemporally sparse. Even for SARS-CoV-2, which has had more thorough surveillance than most other infectious diseases, there may be months for which now genomic surveillance was done. For instance, say that no genomic surveillance was undertaken in Gauteng for 1 weeks in June and October respectively. Therefore, for those time period we would have missing data for the variant-specific incidence of Delta and Omicron: ggplot ( multi_var_sim_inc_missing_data , aes ( x = date , y = rep_inc_D_noise )) + geom_line () + geom_line ( aes ( y = rep_inc_O_noise ), color = \"red\" ) Whereas in R, we can account for missing data as \"NA\", in Stan missing data cannot be included. Therefore, if we want to fit the model to incidence data where date for certain dates are missing, we need to include an array where we index the dates to be fit. This is similar to seeding the model 1 month prior to fitting, we passed an index to the Stan model telling it at which time point to start fitting the model. Challenge: Save model2_Euler_V2.stan as a new model and extend it to fit to the incidence data in multi_var_sim_inc_missing_data*, accounting for the missing data. * 3. Pre-symptomatic transmission There is evidence that SARS-CoV-2 transmission occurs prior to the onset of symptoms [3], which we do not account for in our model. Challenge: First draw out a compartmental model which allows for pre-symptomatic infectiousness. Assume that the average period from exposure to SARS-CoV-2 to the onset of Viraemia is fixed at 1.31 days [3] (so you do not need to estimate any additional parameters). Next, save model2_deSolve.R as a new model and extend it to include pre-symptomatic infectiousness. How does it change the transmission dynamics of the outbreak? Fianlly, save model2_Euler_V2.stan* as a new model and modify it to include pre-symptomatic infectiousness. * References (1) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Grant R, Charmet T, Schaeffer L, et al. Impact of SARS-CoV-2 Delta variant on incubation, transmission settings and vaccine effectiveness: Results from a nationwide case-control study in France. Lancet Reg Health Eur 2022; 13: 100278 (5) Menni C, Valdes AM, Polidori L, et al. Symptom prevalence, duration, and risk of hospital admission in individuals infected with SARS-CoV-2 during periods of omicron and delta variant dominance: a prospective observational study from the ZOE COVID Study. Lancet 2022; 399(10335): 1618-24.","title":"Chapter 3:fitting a single strain model in Stan"},{"location":"chapter_3_solutions/#a-multivariant-model","text":"In this chapter, we are going to fit a multivariate model to capture the dynamics of both the Delta and Omicron VOC's in Gauteng. This means fitting to the incidence data observed during the third wave, driven by Delta, and the fourth wave, driven by Omicron. We will assume that between July 2021 - October 2021 the incidence data is Delta, whilst between October 2021 and December 2021 the incidence data is Omicron ^. As before, we will seed both variants 1 month before fitting to the data. That means we seed Delta in May and we seed Omicron in September. ^Note that these dates are not quite in line with the observed waves in Gauteng. In order to reduce memory usage and the time taken to fit the models in Stan we have assumed shorter waves and a reduce time period over which to model. The flow diagram of the multivariate model is shown in the following figure: Let subscript Y refer to the virus variant ( D = Delta, O = Omicron). Susceptible individuals ( S compartment) are infected at rate \\lambda_Y = \\beta_Y \\frac{I_{t0}} {S_{t0}} . Following infection individuals are latent with the virus ( E compartments) for an average of c \\frac{1}{\\sigma} days. After incubating the virus, a proportion \\rho_Y of individuals are detected, reported and enter isolation ( Q compartments). The remaining proportion become infectious ( I compartments) and contribute to the transmission of SARS-CoV-2. The infectious period lasts on average \\frac{1}{\\gamma} days, and then individuals recover and test negative ( R compartment). Susceptible individuals are also vaccinated and enter the R compartment directly at rate \\nu . Once recovered, immunity to the Omicron variant wanes at a rate of \\epsilon ( S_O compartment) and individuals are infected at a rate of \\lambda_O .","title":"A multivariant model"},{"location":"chapter_3_solutions/#initial-conditions","text":"As before, we will assume a single infectious individual seeds both the Delta and Omicron variants. We need redefine the number of recovered individuals, as we are now looking prior to the third wave. A sero-suvery in Gauteng reported a seroprevalence of 19% in at the end of January 2021 [1], so we will assume that R_{t0} = N * 0.19 and S_{t0} = N -R_{t0} . We will assume that the E , Q and S_O compartments are all 0 at t_0 .","title":"Initial conditions"},{"location":"chapter_3_solutions/#model-parameters","text":"As before, we will fix \\sigma and \\gamma using estimates from the literature, but we will assume they are variant-specific. For Omicron these we assume an average latent period \\frac{1}{\\sigma_D} of 3.03 days [2] and an average infectious period \\frac{1}{\\gamma_D} of 4.17 days [3]. FOr Delta, we will assume an average latent period \\frac{1}{\\sigma_O} 4.3 days [4] and an infectious period an average infectious period \\frac{1}{\\gamma_O} of 2.9 days [3]. We are also going to fix the rate of vaccination, assuming a constant per capita rate of vaccination of \\nu = 0.001 . We are going to estimate the variant-specific transmission rates \\beta_Y , the variant-specific reporting probability, \\rho_Y and the rate of immune waning \\epsilon . Q1: Why might we want to assume a variant specific reporting probability? A1: There is a lot of evidence that Omicron is milder than Delta[5]. Individuals with infected with the Omicron variant are therefore less likely to have symptoms and test, so we expect increased underreporting of Omicron. During the third wave, driven by Delta, interventions were introduced across South Africa between 15-06-21 and 13-09-2021. We will use our model to also estimate the impact of these interventions on transmission. Let \\omega be the percentage reduction in transmission due to interventions. We model this impact on transmission as follows: \\beta' = \\beta * (1-\\omega) Finally, we are also going to estimate the over-dispersion parameter \\kappa , introduced in the previous chapters.","title":"Model parameters"},{"location":"chapter_3_solutions/#likelihood-and-priors","text":"As before we are going to assume a beta prior for the reporting probabilities: \\rho_Y \\sim Beta(2,8) , a normal distribution prior for the transmission rates: \\beta_Y \\sim ND(2.2,1) and an exponential distribution for the overdispersion parameter prior: \\kappa \\sim exp(0.01) . As a starting point, lets say that we fairly certain a SARS-CoV-2 infection or vaccination provides immunity for a year, and assume the following prior: \\epsilon \\sim ND(0.003,0.001) . Q2: Given what we know about the impact of interventions on transmission, what prior should we assume for \\omega ? A2: We don't know very much about \\omega except that it is bound between 0 and 1. So let's assume \\omega \\sim Beta(1,1) . Finally, we need to define our likelihood functions. As before, we assume that SARS-CoV-2 reported incidence is overdispersed and assume a Negative Binomial distribution: y_Y \\sim NegBin(\\mu_Y, \\kappa) Note, this time we have two likelihood functions, one for each variant. As before, we reconstruct the reported incidence from the model \\mu_Y as the rate of entry into the Q compartment: \\mu_Y = \\rho_Y \\sigma_Y E_Y . Including multiple likelihoods in Stan is easy, we just define them on separate lines and Stan will sum them automatically to calculate the overall model likelihood.","title":"Likelihood and priors"},{"location":"chapter_3_solutions/#assumptions","text":"No pre-symptomatic transmission. All reported incidence is dichotomously assumed to be either the Delta or Omicron variants, with no over variants in circulation. All tested individuals isolate with 100% compliance.","title":"Assumptions"},{"location":"chapter_3_solutions/#simulating-multivariant-data","text":"Defining key dates: # Date we start fitting the incidence to Delta date_fit_D = as.Date.character ( \"01-06-2021\" , format = \"%d-%m-%Y\" ) # Date we start fitting the incidence data to Omicron date_fit_O = as.Date.character ( \"01-10-2021\" , format = \"%d-%m-%Y\" ) # Date we seed Delta (1 month before we fit) date_seed_D = as.Date.character ( \"01-05-2021\" , format = \"%d-%m-%Y\" ) # Date we seed D (1 month before we fit) date_seed_O = as.Date.character ( \"01-09-2021\" , format = \"%d-%m-%Y\" ) # Date interventions date_int = as.Date.character ( c ( \"15-06-2021\" , \"13-09-2021\" ), format = \"%d-%m-%Y\" ) # Final data of modelling period end_date = as.Date.character ( \"01-01-2022\" , format = \"%d-%m-%Y\" ) # All dates of modelling period all_dates_mv = seq.Date ( from = date_seed_D , to = end_date , by = \"days\" ) # model times As we are simulating data again, we need to define both the estimated and fixed parameters: # Define variables n_pop = 15810388 # Population immunity_mv = 0.19 # Percentage of the population with immunity n_inf_D = 1 # Initial Delta seed n_inf_O = 1 # Initial Omicron seed # Defining fixed parameters gamma_O = 1 / 4.17 # Omicron recovery rate gamma_D = 1 / 2.9 # Delta recovery rate sigma_O = 1 / 3.03 # Omicron latent rate sigma_D = 1 / 4.3 # Delta latent rate nu = 0.002 # Vaccination rate # Defining \"unknown\" parameters R0_D = 5 # Delta reproduction number R0_O = 8 # Omicron reproduction number rho_D = 0.2 # Probability of reporting a Delta case rho_O = 0.1 # Probability of reporting an Omicron case epsilon = 1 / 180 # Rate of immune waning omega = 0.65 # Percentage reduction in transmission due to interventions beta_D = ( R0_D * gamma_D ) / ( 1 - rho_D ) # Delta transmission rate beta_O = ( R0_O * gamma_O ) / ( 1 - rho_O ) # Omicron transmission rate Like the function simulate_data_single_var in chapter 2, simulate_data_multi_var takes as input our model parameters, starting values and time steps. This time we also need to tell the model when to start and end interventions and when to seed the Omicron variant. The model equations are defined in models/model2_deSolve.R . multi_var_sim_data = simulate_data_multi_var ( immunity = immunity_mv , n_inf_D = n_inf_D , n_inf_O = n_inf_O , rho_D = rho_D , rho_O = rho_O , beta_D = beta_D , beta_O = beta_O , epsilon = epsilon , omega = omega , nu = nu , gamma_O = gamma_O , gamma_D = gamma_D , sigma_O = sigma_O , sigma_D = sigma_D , ts = 1 : length ( all_dates_mv ), time_int_start = which ( all_dates_mv == date_int [ 1 ]), time_int_end = which ( all_dates_mv == date_int [ 2 ]), time_seed_O = which ( all_dates_mv == date_seed_O ) ) We can then plot the reported incidence with noise for the Delta and Omicron variants. multi_var_sim_inc = calc_sim_incidence_multi_var ( ODE_data = multi_var_sim_data , all_dates = all_dates_mv , date_fit_D = date_fit_D , date_fit_O = date_fit_O , rho_D = rho_D , rho_O = rho_O , sigma_D = sigma_D , sigma_O = sigma_O ) multi_var_sim_inc [[ 2 ]] # Plot As we are assuming that incidence between July 2021 - October 2021 is Delta and that incidence between October 2021 and December 2021 is Omicron, all other data are \"NA\" which we need to discard: # Removing missing data y_D = multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_D_noise )] y_O = multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise [ ! is.na ( multi_var_sim_inc [[ 1 ]] $ rep_inc_O_noise )]","title":"Simulating multivariant data"},{"location":"chapter_3_solutions/#fitting-the-multivariant-model-in-stan","text":"The multivariate SEIQRS model using Euler's method is coded up in model2_Euler_V1.stan , in the models folder. Spend some time looking over the model to check everything is clear. The variables for storing the outputs of the E, I, Q compartments are now 2D matrices, where the rows are the each time step at which we solve the model and the columns are the variants. Once you are happy with the model, we can fit it to the data: stan_fit_m2_EU1 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 6 , # amount to reduce time step, nu = nu ), model = m2_EU1 , n_var = 2 , model_no = 2 , n_iter = 400 , n_warmup = 200 ) ## Warning: The largest R-hat is NA, indicating chains have not mixed. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#r-hat ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#bulk-ess ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. ## Running the chains for more iterations may help. See ## https://mc-stan.org/misc/warnings.html#tail-ess ## Time difference of 8.191365 mins Stan is providing us with a series of warnings that the chains have not mixed and that our posterior distributions are unreliable. To investigate this further, run diagnostics on the model as before: m2_EU1_diag = diagnose_stan_fit ( stan_fit_m2_EU1 , # pars = c ( \"beta[1]\" , \"rho[1]\" , \"rho[2]\" , \"beta[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"epsilon\" , \"omega\" )) m2_EU1_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.174278594 0.032742915 0.086212251 2.076230820 2.126329648 ## rho[1] 0.201609983 0.012991698 0.030939623 0.167216827 0.184687568 ## rho[2] 0.126246817 0.003388824 0.014708580 0.103874931 0.116838378 ## beta[2] 3.971081625 1.781548465 2.210453651 2.271054659 2.402496851 ## R_0[1] 5.026515710 0.010703291 0.027965750 4.957186757 5.017956338 ## R_0[2] 14.417304447 6.391065805 7.932560673 8.433757470 8.816767533 ## epsilon 0.005681398 0.001027253 0.001328556 0.004372203 0.004714769 ## omega 0.686398775 0.043428414 0.058106890 0.620262206 0.645499375 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.150393516 2.187886913 2.404599547 6.932714 1.195066 ## rho[1] 0.192530698 0.205612432 0.285419766 5.671503 1.235327 ## rho[2] 0.123385478 0.132640129 0.163287402 18.838378 1.102571 ## beta[2] 2.491639868 6.536477611 8.006769192 1.539457 6.311293 ## R_0[1] 5.031984652 5.042884379 5.058545954 6.826817 1.173300 ## R_0[2] 9.071625754 23.593396160 28.833707087 1.540566 6.206673 ## epsilon 0.004959327 0.007003534 0.008489794 1.672649 3.119356 ## omega 0.660125727 0.732646287 0.815256899 1.790224 2.430118 The warnings and diagnostic plots all show the model has failed to converge. Looking at the trace plot, it seems the model is converging on the parameters specific to Delta. Conversely, for the parameters relating to Omicron, the model is exploring two different regions of the posterior distribution. To help diagnose the problem, we can look at the lp (the log posterior) to try and understand whether the chains are exploring parameter values that are equally likely. Note, that as the lp_ is the log density up to a constant , it is not the same as the log likelihood and should not be used to compare models, as the constant from different models are likely to be different. Therefore, the is only useful as a rough indicator for comparing the log posterior of chains within the same model. If a model is non-identifiable it means that two values of a parameter are equally likely, for instance because there are two modes in the posterior distribution. In this instance, we would expect to see chains exploring different regions of parameter space and obtaining similar estimates of the log posterior. Conversely, if we see that chains are exploring different parameter values with different log probabilities it suggests one or more of the chains may be stuck in a local mode. Q3: Looking at the trace plots, do you think the model is non-identifiable or that one or more of the chains are stuck in a local mode? A3: From the trace plot, we can see that chains 1 and 2 are exploring a more probable region of parameter values (i.e., they have a high log probability). If we plot the model fit against the data, we can see that the model is able to recreate the Delta incidence but only partly captures the Omicron transmission dynamics: plot_model_fit_multi_var ( stan_fit_m2_EU1 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) To explore this further, we can even plot the model fit for each chain separately. This allows us to confirm that the chains with a high log posterior are indeed exploring parameter values that are able to capture the transmission dynamics: As expected, chains 1 and 2 are able to capture the transmission dynamics of Omicron, whilst chain 3 peaks too early. This makes sense, given that this chain was exploring much higher values of the Omicron R_0 .","title":"Fitting the multivariant model in Stan"},{"location":"chapter_3_solutions/#improving-the-stan-model","text":"From the above diagnostics we can see that the model is having problems converging. One option is to run the model for more iterations, e.g, 2000 iterations with the first 1000 discarded as burn in. In this instance, the model still fails to converge (you can test this if you like, it takes ~30 minutes to run). Alternatively, we can take failure to converge as a sign that our model needs improving. In practice it is often likely that our model is missing some key component of the data generating process. In that instance, we would need to revisit the assumptions underlying our model structure and fixed parameter values in order to extend and improve our model. However, as we simulated the data we know that this is not the case. Instead, lets revisit our parameter priors. For \\epsilon , the rate that immunity wanes against Omicron, the model is exploring two models. The first is ~0.005 and the second is ~0.0075, corresponding to immunity last on average for 200 days and 130 days respectively. Based on the diagnostics we ran, we know that an average duration of immunity around 200 days is more likely. We originally assumed \\epsilon \\sim ND(0.003,0.001) : eps_prior = rnorm ( 100000 , 0.003 , 0.001 ) quantile ( eps_prior , probs = c ( 0.025 , 0.25 , 0.5 , 0.75 , 0.975 )) ## 2.5% 25% 50% 75% 97.5% ## 0.001030631 0.002324570 0.003002029 0.003671811 0.004967465 In isolation, this prior supports parameter values between 0.001-0.005, or immunity lasting 250-1000 days, and yet in our model the sampler is stuck in a local mode exploring values of immunity <150 days. Clearly, our prior is not regularising our model in the way that we had hoped. Lets try relaxing the prior on \\epsilon to see if that helps: \\epsilon \\sim Exponential(5) . model2_Euler_V2.stan is exactly the same as model2_Euler_V1.stan but with the updated prio. We will also increase the frequency with which we solve the ODEs from 6 times per day to 10 times per day, to improve accuracy. stan_fit_m2_EU2 = run_stan_models ( list_data = list ( n_var = 2 , # no. variants n_ts = length ( all_dates_mv ), # no. time steps n_pop = n_pop , # population n_recov = round ( immunity_mv * n_pop ), # recovered population I0 = c ( n_inf_D , n_inf_O ), # Seeds y_D = y_D , # Delta reported incidence (data to fit to) y_O = y_O , # Omicron reported incidence (data to fit to) n_data_D = length ( y_D ), # no. data n_data_O = length ( y_O ), # no. data sigma = c ( sigma_D , sigma_O ), # latent rates gamma = c ( gamma_D , gamma_O ), # recovery rate time_seed_O = # index to seed Omicron which ( all_dates_mv == date_seed_O ), time_fit_D = which ( all_dates_mv == date_fit_D ), # index to fit Delta time_fit_O = which ( all_dates_mv == date_fit_O ), # index to fit Omicron time_int_start = which ( all_dates_mv == date_int [ 1 ]), # index to start interventions time_int_end = which ( all_dates_mv == date_int [ 2 ]), # index to end interventions scale_time_step = 10 , # amount to reduce time step, nu = nu ), model = m2_EU2 , n_var = 2 , model_no = 2 ) ## Time difference of 19.98115 mins This time, we received no warnings and the diagnostics all look good: m2_EU2_diag = diagnose_stan_fit ( stan_fit_m2_EU2 , # pars = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" )) m2_EU2_diag ## $`markov chain trace plots` ## ## $`univariate marginal posterior distributions` ## ## $`summary statistics of parameters` ## mean se_mean sd 2.5% 25% ## beta[1] 2.116521884 9.899071e-04 0.0269706926 2.067661028 2.097787454 ## beta[2] 2.319350471 5.139249e-03 0.1024861769 2.131684601 2.248085267 ## rho[1] 0.188317783 3.325335e-04 0.0092349010 0.171366430 0.181847303 ## rho[2] 0.115291630 4.347656e-04 0.0090079647 0.099126602 0.108939300 ## R_0[1] 4.981323338 4.041932e-04 0.0119813757 4.957105925 4.973470936 ## R_0[2] 8.553193796 1.482954e-02 0.3023531775 7.980951894 8.344190297 ## omega 0.644320641 5.484722e-04 0.0168800694 0.610813948 0.633733466 ## epsilon 0.005078499 1.653904e-05 0.0003368983 0.004422272 0.004848714 ## 50% 75% 97.5% n_eff Rhat ## beta[1] 2.116432248 2.133809321 2.175968276 742.3272 1.0010011 ## beta[2] 2.320265733 2.385751498 2.542435142 397.6778 1.0132085 ## rho[1] 0.188335445 0.194204472 0.207661324 771.2475 1.0012060 ## rho[2] 0.115026089 0.121291680 0.134161125 429.2824 1.0127609 ## R_0[1] 4.981861544 4.989864744 5.003023951 878.6892 0.9997183 ## R_0[2] 8.557859890 8.747650458 9.194714836 415.6939 1.0123018 ## omega 0.644341053 0.655534903 0.677306322 947.1947 0.9991738 ## epsilon 0.005053239 0.005293894 0.005769865 414.9321 1.0125417 The model fit is also good: plot_model_fit_multi_var ( stan_fit_m2_EU2 , variable_model = \"lambda_days\" , variable_data = \"rep_inc_D_noise\" , data = multi_var_sim_inc [[ 1 ]]) Finally, we can compare the parameter estimates to the true values: compare_param_est ( parameter_names = c ( \"beta[1]\" , \"beta[2]\" , \"rho[1]\" , \"rho[2]\" , \"R_0[1]\" , \"R_0[2]\" , \"omega\" , \"epsilon\" ), true_param_values = c ( beta_D , beta_O , rho_D , rho_O , R0_D , R0_O , omega , epsilon ), param_values1 = m2_EU2_diag [[ 3 ]][, c ( 1 , 4 , 8 )], model_names = c ( \"EU\" ) ) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] ## ## [[6]] ## ## [[7]] ## ## [[8]] The model is broadly able to capture all the parameter values. As the is strong correlation between the parameters values, we might say they are weakly identified, as the posterior distribution mode is a ridge (see the pairs plot). Nevertheless, with sensible priors we are still able to capture the parameter values and obtain a sufficient sample size (see n_eff), indicating that results are unbiased and can be trusted.","title":"Improving the Stan model"},{"location":"chapter_3_solutions/#model-extensions","text":"Note, these extensions don't have solutions, and there isn't a single, correct way to approach them. The challanges are more open ended and are provided in case you would like to explore this topic further!","title":"Model extensions"},{"location":"chapter_3_solutions/#1-parameter-values-priors-and-likelihoods","text":"As discussed throughout the tutorial, there are many choices to made during the model fitting process. These include which parameter values to fix and which to estimate, which priors to use and which likelihood to use. Challenge: Refit the model Swap assuming the likelihood follows a Poisson distribution, rather than a Negative Binomial distribution Challenge: As discussed above, there is a some non-identifiability in the model. One way to address this is fix one of the parameter values. Refit the model fixing one or more of the parameter values. How does this change the parameter estimates? Alternatively, What happens if you try estimating more parameter values? For instance, try estimating the \\gamma and/or the \\sigma parameters. Does the model still converge? Are the estimated parameter values less accurate? Challenge: We have shown that our model can be sensitive to the choice of prior. We fit the model assuming improper, flat priors. Does the model still converge? Can you find a set of priors that result in divergent transitions?","title":"1. Parameter values, priors and likelihoods"},{"location":"chapter_3_solutions/#2-missing-data","text":"A common problem in epidemiological modelling is missing data. We are frequently using secondary data, which was not collected for the purposes of our study. When modelling multivariate pathogens (e.g., SARS-CoV-2, Influenza, Dengue), we often do not know what variant or serotype someone was infected with, as this is not routinely collected information. For instance, most positive COVID-19 samples are not sequenced, so we do not know which variant they are infected with. In this example, we made the simplifying assumption that only a single variant was circulating at any time. However, this is clearly incorrect. Instead, we could couple genomic surveillance data, for instance that reported in GISAID , to the reported epidemiological incidence to recreate the variant specific incidences, by assuming the variant-specific prevalence in GISAID is proportional to its reported incidence: y_Y = y_{tot} \\frac{x_Y}{n} Where y_Y is the variant specific reported incidence, y_{tot} is the total reported incidence, x_Y is the number of sequences positive for variant Y and n is the number of samples sequenced. A limitation of genomic surveillance, is that it is often spatiotemporally sparse. Even for SARS-CoV-2, which has had more thorough surveillance than most other infectious diseases, there may be months for which now genomic surveillance was done. For instance, say that no genomic surveillance was undertaken in Gauteng for 1 weeks in June and October respectively. Therefore, for those time period we would have missing data for the variant-specific incidence of Delta and Omicron: ggplot ( multi_var_sim_inc_missing_data , aes ( x = date , y = rep_inc_D_noise )) + geom_line () + geom_line ( aes ( y = rep_inc_O_noise ), color = \"red\" ) Whereas in R, we can account for missing data as \"NA\", in Stan missing data cannot be included. Therefore, if we want to fit the model to incidence data where date for certain dates are missing, we need to include an array where we index the dates to be fit. This is similar to seeding the model 1 month prior to fitting, we passed an index to the Stan model telling it at which time point to start fitting the model. Challenge: Save model2_Euler_V2.stan as a new model and extend it to fit to the incidence data in multi_var_sim_inc_missing_data*, accounting for the missing data. *","title":"2. Missing data"},{"location":"chapter_3_solutions/#3-pre-symptomatic-transmission","text":"There is evidence that SARS-CoV-2 transmission occurs prior to the onset of symptoms [3], which we do not account for in our model. Challenge: First draw out a compartmental model which allows for pre-symptomatic infectiousness. Assume that the average period from exposure to SARS-CoV-2 to the onset of Viraemia is fixed at 1.31 days [3] (so you do not need to estimate any additional parameters). Next, save model2_deSolve.R as a new model and extend it to include pre-symptomatic infectiousness. How does it change the transmission dynamics of the outbreak? Fianlly, save model2_Euler_V2.stan* as a new model and modify it to include pre-symptomatic infectiousness. *","title":"3. Pre-symptomatic transmission"},{"location":"chapter_3_solutions/#references","text":"(1) Mutevedzi PC, Kawonga M, Kwatra G, et al. Estimated SARS-CoV-2 infection rate and fatality risk in Gauteng Province, South Africa: a population-based seroepidemiological survey. Int J Epidemiol 2022; 51(2): 404-17. (2) Tanaka H, Ogata T, Shibata T, et al. Shorter Incubation Period among COVID-19 Cases with the BA.1 Omicron Variant. Int J Environ Res Public Health 2022; 19(10). (3) Lavezzo E, Franchin E, Ciavarella C, et al. Suppression of a SARS-CoV-2 outbreak in the Italian municipality of Vo\u2019. Nature 2020; 584(7821): 425-9. (4) Grant R, Charmet T, Schaeffer L, et al. Impact of SARS-CoV-2 Delta variant on incubation, transmission settings and vaccine effectiveness: Results from a nationwide case-control study in France. Lancet Reg Health Eur 2022; 13: 100278 (5) Menni C, Valdes AM, Polidori L, et al. Symptom prevalence, duration, and risk of hospital admission in individuals infected with SARS-CoV-2 during periods of omicron and delta variant dominance: a prospective observational study from the ZOE COVID Study. Lancet 2022; 399(10335): 1618-24.","title":"References"}]}